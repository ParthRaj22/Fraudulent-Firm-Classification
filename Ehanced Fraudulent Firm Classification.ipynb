{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit = pd.read_csv('audit_risk.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the number of NAs in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sector_score      0\n",
      "LOCATION_ID       0\n",
      "PARA_A            0\n",
      "Score_A           0\n",
      "Risk_A            0\n",
      "PARA_B            0\n",
      "Score_B           0\n",
      "Risk_B            0\n",
      "TOTAL             0\n",
      "numbers           0\n",
      "Score_B.1         0\n",
      "Risk_C            0\n",
      "Money_Value       1\n",
      "Score_MV          0\n",
      "Risk_D            0\n",
      "District_Loss     0\n",
      "PROB              0\n",
      "RiSk_E            0\n",
      "History           0\n",
      "Prob              0\n",
      "Risk_F            0\n",
      "Score             0\n",
      "Inherent_Risk     0\n",
      "CONTROL_RISK      0\n",
      "Detection_Risk    0\n",
      "Audit_Risk        0\n",
      "Risk              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(audit.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Trial Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = pd.read_csv('trial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sector_score     0\n",
      "LOCATION_ID      0\n",
      "PARA_A           0\n",
      "SCORE_A          0\n",
      "PARA_B           0\n",
      "SCORE_B          0\n",
      "TOTAL            0\n",
      "numbers          0\n",
      "Marks            0\n",
      "Money_Value      1\n",
      "MONEY_Marks      0\n",
      "District         0\n",
      "Loss             0\n",
      "LOSS_SCORE       0\n",
      "History          0\n",
      "History_score    0\n",
      "Score            0\n",
      "Risk             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(trial.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill NA Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial['Money_Value']=trial['Money_Value'].fillna(trial['Money_Value'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit['Money_Value']=audit['Money_Value'].fillna(audit['Money_Value'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sector_score      float64\n",
       "LOCATION_ID        object\n",
       "PARA_A            float64\n",
       "Score_A           float64\n",
       "Risk_A            float64\n",
       "PARA_B            float64\n",
       "Score_B           float64\n",
       "Risk_B            float64\n",
       "TOTAL             float64\n",
       "numbers           float64\n",
       "Score_B.1         float64\n",
       "Risk_C            float64\n",
       "Money_Value       float64\n",
       "Score_MV          float64\n",
       "Risk_D            float64\n",
       "District_Loss       int64\n",
       "PROB              float64\n",
       "RiSk_E            float64\n",
       "History             int64\n",
       "Prob              float64\n",
       "Risk_F            float64\n",
       "Score             float64\n",
       "Inherent_Risk     float64\n",
       "CONTROL_RISK      float64\n",
       "Detection_Risk    float64\n",
       "Audit_Risk        float64\n",
       "Risk                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sector_score     float64\n",
       "LOCATION_ID       object\n",
       "PARA_A           float64\n",
       "SCORE_A            int64\n",
       "PARA_B           float64\n",
       "SCORE_B            int64\n",
       "TOTAL            float64\n",
       "numbers          float64\n",
       "Marks              int64\n",
       "Money_Value      float64\n",
       "MONEY_Marks        int64\n",
       "District           int64\n",
       "Loss               int64\n",
       "LOSS_SCORE         int64\n",
       "History            int64\n",
       "History_score      int64\n",
       "Score            float64\n",
       "Risk               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial.dtypes #scorea and scoreb(make float),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial['SCORE_A']=trial['SCORE_A'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial['SCORE_B']=trial['SCORE_B'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if the Audit data has outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bplot1=[audit['PARA_A'],audit['Score_A'],audit['Risk_A'],audit['PARA_B'],audit['Score_B'],audit['Risk_B'],audit['TOTAL']]\n",
    "bplot2=[audit['numbers'],audit['Score_B.1'],audit['Risk_C'],audit['Money_Value'],audit['Score_MV'],audit['Risk_D'],audit['District_Loss']]\n",
    "bplot3=[audit['PROB'],audit['RiSk_E'],audit['History'],audit['Prob'],audit['Risk_F'],audit['Score'],audit['Inherent_Risk']]\n",
    "bplot4=[audit['CONTROL_RISK'],audit['Detection_Risk'],audit['Audit_Risk'],audit['Risk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig ,ax= plt.subplots(figsize = (15,5))\n",
    "bp1=ax.boxplot(bplot1)\n",
    "\n",
    "bp3=ax.boxplot(bplot3)\n",
    "#bp4=ax.boxplot(bplot4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig ,ax= plt.subplots(figsize = (15,5))\n",
    "bp2=ax.boxplot(bplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig ,ax= plt.subplots(figsize = (15,5))\n",
    "bp3=ax.boxplot(bplot3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3cAAAEyCAYAAABZOSngAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFwpJREFUeJzt3X2MZld9H/Dvb2fXjGNTzMsSUa/DUsVKJxopgYyA2quoC2kEJIr5IyisaGLZU1mRYEqKpUA6fzRuZSm2moAxEsjKuhgFDUYkElaEGyEYFI3UUGYTFy/etLZwDFtcvIiXOES77MvpH3O9WePFXu8z7N3nzOcjjZ57zz3P3N8j7fXj75xzz63WWgAAAJhu28YuAAAAgMkJdwAAAB0Q7gAAADog3AEAAHRAuAMAAOiAcAcAANAB4Q4AAKADwh0AAEAHnjPcVdXdVfVEVR08o+0lVfXZqnp4eH3x0F5V9cGqeqSqvlxVrznjPdcP/R+uqut/PB8HAABga6rW2rN3qPrFJP+Q5GOttfmh7fYk326t/UFVvS/Ji1tr762qtyRZSvKWJK9Lckdr7XVV9ZIk60kWkrQkB5L8QmvtO8927pe97GVt9+7dE31AAACAaXXgwIFvtdZ2nkvf7c/VobX2l1W1+4ear0vyr4fte5J8Icl7h/aPtY3E+FdVdUVVvWLo+9nW2reTpKo+m+RNSVae7dy7d+/O+vr6uXwOAACA7lTVY+fa93zvufvJ1trjSTK8vnxovzLJ18/od3ho+1Htz1BVN1XVelWtHzly5DzLAwAA2Fo2e0GVOktbe5b2Zza2dldrbaG1trBz5zmNPgIAAGx55xvuvjlMt8zw+sTQfjjJVWf025XkG8/SDgAAwCY433B3X5KnVry8Psmnz2j/rWHVzNcn+d4wbfMvkvxyVb14WFnzl4c2AAAANsFzLqhSVSvZWBDlZVV1OMl/SvIHST5ZVYtJvpbkbUP3z2RjpcxHkvxjkhuSpLX27ar6L0m+NPT7z08trgIAAMDknvNRCGNaWFhoVssEAAC2qqo60FpbOJe+m72gCgAAACMQ7gCAqbOyspL5+fnMzMxkfn4+KyvP+uhcgC3hOe+5AwC4mKysrGR5eTn79+/Pnj17sra2lsXFxSTJvn37Rq4OYDzuuQMApsr8/HzuvPPO7N2793Tb6upqlpaWcvDgwRErA9h8z+eeO+EOAJgqMzMzOXr0aHbs2HG67fjx45mdnc3JkydHrAxg81lQBQDo1tzcXNbW1p7Wtra2lrm5uZEqArg4CHcAwFRZXl7O4uJiVldXc/z48ayurmZxcTHLy8tjlwYwKguqAABT5alFU5aWlnLo0KHMzc3l1ltvtZgKsOW55w4AAOAi5Z47AACALUa4AwAA6IBwBwAA0AHhDgAAoAPCHQAAQAeEOwAAgA4IdwAAAB0Q7gAAADog3AEAAHRAuAMAAOiAcAcAANAB4Q4AAKADwh0AAEAHhDsAAIAOCHcAAAAdEO4AAAA6INwBAAB0QLgDAADogHAHAADQAeEOAACgA8IdAABAB4Q7AACADgh3AAAAHRDuAAAAOiDcAQAAdEC4AwAA6IBwBwAA0AHhDgAAoAPCHQAAQAeEOwAAgA4IdwAAAB0Q7gAAADog3AEAAHRAuAMAAOjAROGuqv5DVX2lqg5W1UpVzVbVq6rqi1X1cFXdW1WXDH1fMOw/MhzfvRkfAAAAgAnCXVVdmeTfJ1lorc0nmUny9iS3JXl/a+3qJN9Jsji8ZTHJd1prP53k/UM/AAAANsGk0zK3J7m0qrYn+Ykkjyd5Q5JPDcfvSfLWYfu6YT/D8TdWVU14fgAAADJBuGut/d8k/zXJ17IR6r6X5ECS77bWTgzdDie5cti+MsnXh/eeGPq/9Id/b1XdVFXrVbV+5MiR8y0PAABgS5lkWuaLszEa96ok/zzJZUnefJau7am3PMuxf2po7a7W2kJrbWHnzp3nWx4AAMCWMsm0zF9K8mhr7Uhr7XiSP0tyTZIrhmmaSbIryTeG7cNJrkqS4fiLknx7gvMDAAAwmCTcfS3J66vqJ4Z7596Y5KEkq0l+fehzfZJPD9v3DfsZjn++tfaMkTsAAACev0nuuftiNhZG+eskDw6/664k703ynqp6JBv31O0f3rI/yUuH9vcked8EdQMAAHCGupgHzxYWFtr6+vrYZQAAAIyiqg601hbOpe+kj0IAAADgIiDcAQAAdEC4AwAA6IBwBwAA0AHhDgAAoAPCHQAAQAeEOwAAgA4IdwAAAB0Q7gAAADog3AEAAHRAuAMAAOiAcAcAANAB4Q4AAKADwh0AAEAHhDsAAIAOCHcAAAAdEO4AAAA6INwBAAB0QLgDAADogHAHAADQAeEOAACgA8IdAABAB4Q7AACADgh3AAAAHRDuAAAAOiDcAQAAdEC4AwAA6IBwBwAA0AHhDgAAoAPCHQAAQAeEOwAAgA4IdwAAAB0Q7gAAADog3AEAAHRAuAMAAOiAcAcAANAB4Q4AAKADwh0AAEAHhDsAAIAOCHcAAAAdEO4AAAA6INwBAAB0YKJwV1VXVNWnqupvq+pQVf2rqnpJVX22qh4eXl889K2q+mBVPVJVX66q12zORwAAAGDSkbs7kvz31tq/TPJzSQ4leV+Sz7XWrk7yuWE/Sd6c5Orh56YkH57w3AAAAAzOO9xV1T9L8otJ9idJa+0HrbXvJrkuyT1Dt3uSvHXYvi7Jx9qGv0pyRVW94rwrBwAA4LRJRu7+RZIjSf5bVf1NVf1xVV2W5Cdba48nyfD68qH/lUm+fsb7Dw9tT1NVN1XVelWtHzlyZILyAAAAto5Jwt32JK9J8uHW2quTfD//NAXzbOosbe0ZDa3d1VpbaK0t7Ny5c4LyAAAAto5Jwt3hJIdba18c9j+VjbD3zaemWw6vT5zR/6oz3r8ryTcmOD8AAACD8w53rbX/l+TrVfUzQ9MbkzyU5L4k1w9t1yf59LB9X5LfGlbNfH2S7z01fRMAAIDJbJ/w/UtJPl5VlyT5apIbshEYP1lVi0m+luRtQ9/PJHlLkkeS/OPQFwAAgE0wUbhrrT2QZOEsh954lr4tyTsnOR8AAABnN+lz7gAAALgICHcAAAAdEO4AAAA6INwBAAB0QLgDAADogHAHAADQAeEOAACgA8IdAABAB4Q7AACADgh3AAAAHRDuAAAAOiDcAQAAdEC4AwAA6IBwBwAA0AHhDgAAoAPCHQAAQAeEOwAAgA4IdwAAAB0Q7gAAADog3AEAAHRAuAMAAOiAcAcAANAB4Q4AAKADwh0AAEAHhDsAAIAOCHcAAAAdEO4AAAA6INwBAAB0QLgDAADogHAHAADQAeEOAACgA8IdAABAB4Q7AACADgh3AAAAHRDuAAAAOiDcAQAAdEC4AwAA6IBwBwAA0AHhDgAAoAPCHQAAQAeEOwAAgA4IdwAAAB2YONxV1UxV/U1V/fmw/6qq+mJVPVxV91bVJUP7C4b9R4bjuyc9NwAAABs2Y+Tu3UkOnbF/W5L3t9auTvKdJItD+2KS77TWfjrJ+4d+AAAAbIKJwl1V7UryK0n+eNivJG9I8qmhyz1J3jpsXzfsZzj+xqE/AAAAE5p05O4DSX43yalh/6VJvttaOzHsH05y5bB9ZZKvJ8lw/HtDfwAAACZ03uGuqn41yROttQNnNp+lazuHY2f+3puqar2q1o8cOXK+5QEAAGwpk4zcXZvk16rq75J8IhvTMT+Q5Iqq2j702ZXkG8P24SRXJclw/EVJvv3Dv7S1dldrbaG1trBz584JygMAANg6zjvctdZ+r7W2q7W2O8nbk3y+tfaOJKtJfn3odn2STw/b9w37GY5/vrX2jJE7AAAAnr8fx3Pu3pvkPVX1SDbuqds/tO9P8tKh/T1J3vdjODcAAMCWtP25uzy31toXknxh2P5qkteepc/RJG/bjPMBAADwdD+OkTsAAAAuMOEOAACgA8IdAABAB4Q7AACADgh3AAAAHRDuAAAAOiDcAQAAdEC4AwAA6IBwBwAA0AHhDgAAoAPCHQAAQAeEOwAAgA4IdwAAAB0Q7gAAADog3AEAAHRAuAMAAOiAcAcAANAB4Q4AAKADwh0AAEAHhDsAAIAOCHcAAAAdEO4AAAA6INwBAAB0QLgDAADogHAHAADQAeEOAACgA8IdAABAB4Q7AACADgh3AAAAHRDuAAAAOiDcAQAAdEC4AwAA6IBwBwAA0AHhDgAAoAPCHQAAQAeEOwAAgA4IdwAAAB0Q7gCAqbOyspL5+fnMzMxkfn4+KysrY5cEMLrtYxcAAPB8rKysZHl5Ofv378+ePXuytraWxcXFJMm+fftGrg5gPNVaG7uGH2lhYaGtr6+PXQYAcBGZn5/PnXfemb17955uW11dzdLSUg4ePDhiZQCbr6oOtNYWzqmvcAcATJOZmZkcPXo0O3bsON12/PjxzM7O5uTJkyNWBrD5nk+4c88dADBV5ubmsra29rS2tbW1zM3NjVQRwMXBPXcAwFRZXl7Ob/zGb+Syyy7LY489lle+8pX5/ve/nzvuuGPs0gBGdd4jd1V1VVWtVtWhqvpKVb17aH9JVX22qh4eXl88tFdVfbCqHqmqL1fVazbrQwAAW1NVjV0CwEVjkmmZJ5Lc3FqbS/L6JO+sqp9N8r4kn2utXZ3kc8N+krw5ydXDz01JPjzBuQGALerWW2/Nvffem0cffTQnT57Mo48+mnvvvTe33nrr2KUBjOq8w11r7fHW2l8P208mOZTkyiTXJbln6HZPkrcO29cl+Vjb8FdJrqiqV5x35QDAlnTo0KHs2bPnaW179uzJoUOHRqoI4OKwKQuqVNXuJK9O8sUkP9laezzZCIBJXj50uzLJ18942+Gh7Yd/101VtV5V60eOHNmM8gCAjlhQBeDsJg53VXV5kj9N8juttb9/tq5naXvGcxhaa3e11hZaaws7d+6ctDwAoDPLy8tZXFzM6upqjh8/ntXV1SwuLmZ5eXns0gBGNdFqmVW1IxvB7uOttT8bmr9ZVa9orT0+TLt8Ymg/nOSqM96+K8k3Jjk/ALD17Nu3L0mytLSUQ4cOZW5uLrfeeuvpdoCt6rzDXW0sT7U/yaHW2h+dcei+JNcn+YPh9dNntL+rqj6R5HVJvvfU9E0AgOdj3759whzAD5lk5O7aJL+Z5MGqemBo+4/ZCHWfrKrFJF9L8rbh2GeSvCXJI0n+MckNE5wbAACAM5x3uGutreXs99ElyRvP0r8leef5ng8AAIAfbVNWywQAAGBcwh0AAEAHhDsAAIAOCHcAAAAdEO4AgKmzsrKS+fn5zMzMZH5+PisrK2OXBDC6iR5iDgBwoa2srGR5eTn79+/Pnj17sra2lsXFxSTx7DtgS6uNJxRcnBYWFtr6+vrYZQAAF5H5+fnceeed2bt37+m21dXVLC0t5eDBgyNWBrD5qupAa23hnPoKdwDANJmZmcnRo0ezY8eO023Hjx/P7OxsTp48OWJlAJvv+YQ799wBAFNlbm4ut9xyy9PuubvlllsyNzc3dmkAoxLuAICpsnfv3tx222258cYb8+STT+bGG2/Mbbfd9rRpmgBbkWmZAMBUmZ+fz9VXX537778/x44dywte8IK8+c1vzsMPP+yeO6A7pmUCAN166KGH8sADD+T+++/PD37wg9x///154IEH8tBDD41dGsCoPAoBAJgql1xySa699tosLS3l0KFDmZuby7XXXpvHH3987NIARiXcAQBT5dixY1lZWcnOnTtz6tSpfOtb38rKykpOnTo1dmkAozItEwCYKtu3b8+ll16aSy+9NNu2bTu9vX27v1kDW5twBwBMlRMnTuSFL3xh7r777hw9ejR33313XvjCF+bEiRNjlwYwKuEOAJg6N9xwQ5aWljI7O5ulpaXccMMNY5cEMDrzFwCAqbJr16589KMfzcc//vHs2bMna2trecc73pFdu3aNXRrAqIzcAQBT5fbbb8+JEydy4403ZnZ2NjfeeGNOnDiR22+/fezSAEYl3AEAU2Xfvn254447ctlllyVJLrvsstxxxx3Zt2/fyJUBjKtaa2PX8CMtLCy09fX1scsAAAAYRVUdaK0tnEtfI3cAwNRZWVnJ/Px8ZmZmMj8/n5WVlbFLAhidBVUAgKmysrKS5eXl7N+///SCKouLi0liaiawpZmWCQBMlfn5+dx5553Zu3fv6bbV1dUsLS3l4MGDI1YGsPmez7RM4Q4AmCozMzM5evRoduzYcbrt+PHjmZ2dzcmTJ0esDGDzuecOAOjW3Nxcrrnmmmzbti1VlW3btuWaa67J3Nzc2KUBjEq4AwCmyrZt27K+vp7LL78827Zty+WXX5719fVs2+Z/a4CtzX8FAYCp8uCDD2bHjh05evRoTp06dXqK5oMPPjh2aQCjslomADB1Tp48mVOnTiXZuN/OqB2AkTsAYAqdOnUqs7OzSZLZ2dnTQQ9gKxPuAICptGPHjmzbtu1pq2YCbGWmZQIAU+nJJ5982ivAVmfkDgAAoAPCHQAAQAeEOwAAgA4IdwAAAB0Q7gAAADog3AEAAHRAuAMAAOiAcAcAANAB4Q4AAKADwh3nZWlpKbOzs6mqzM7OZmlpaeySAABgS7vg4a6q3lRV/7uqHqmq913o8zO5paWlfOhDH8qxY8eSJMeOHcuHPvQhAQ8AAEZUrbULd7KqmST/J8m/SXI4yZeS7GutPXS2/gsLC219ff2C1ce5qaofeexC/nsCYGvyPQRsJVV1oLW2cC59t/+4i/khr03ySGvtq0lSVZ9Icl2Ss4Y7Lm5nfoE+2xctAFvbhfyO+HGcS2AEpsWFHrn79SRvaq39u2H/N5O8rrX2rjP63JTkpiT5qZ/6qV947LHHLlh9o/n9F41dwdb1+98buwI2g2toPK6hPriGxuU66oPraDydX0MX88jd2f6c9rR02Vq7K8ldyca0zAtR1Oim7B/kU38V/cM//MP89m//dj7ykY/k5ptvTuKvm4xkyq4huOhM4TV0thE630GMagqvI/pzocPd4SRXnbG/K8k3LnANbJKbb775dKgDgAtJkAN4pgu9WuaXklxdVa+qqkuSvD3JfRe4Bib0o75QfdECAMB4LujIXWvtRFW9K8lfJJlJcndr7SsXsgY2hyAHAAAXlws9LTOttc8k+cyFPi8AAEDPLvhDzAEAANh8wh0AAEAHhDsAAIAOCHcAAAAdEO4AAAA6INwBAAB0QLgDAADoQF3MD6OuqiNJHhu7Dp7Vy5J8a+wiYIq5hmAyriGYnOvo4vbK1trOc+l4UYc7Ln5Vtd5aWxi7DphWriGYjGsIJuc66odpmQAAAB0Q7gAAADog3DGpu8YuAKacawgm4xqCybmOOuGeOwAAgA4YuQMAAOiAcAcAANAB4Y7zUlV3V9UTVXVw7FpgGlXVVVW1WlWHquorVfXusWuCaVJVs1X1P6vqfw3X0C1j1wTTqKpmqupvqurPx66FyQl3nK+PJnnT2EXAFDuR5ObW2lyS1yd5Z1X97Mg1wTQ5luQNrbWfS/LzSd5UVa8fuSaYRu9OcmjsItgcwh3npbX2l0m+PXYdMK1aa4+31v562H4yG1+sV45bFUyPtuEfht0dw49V4uB5qKpdSX4lyR+PXQubQ7gDGFlV7U7y6iRfHLcSmC7DdLIHkjyR5LOtNdcQPD8fSPK7SU6NXQibQ7gDGFFVXZ7kT5P8Tmvt78euB6ZJa+1ka+3nk+xK8tqqmh+7JpgWVfWrSZ5orR0YuxY2j3AHMJKq2pGNYPfx1tqfjV0PTKvW2neTfCHuBYfn49okv1ZVf5fkE0neUFV/Mm5JTEq4AxhBVVWS/UkOtdb+aOx6YNpU1c6qumLYvjTJLyX523GrgunRWvu91tqu1truJG9P8vnW2r8duSwmJNxxXqpqJcn/SPIzVXW4qhbHrgmmzLVJfjMbfyl9YPh5y9hFwRR5RZLVqvpyki9l4547S7kDW1q1ZmEpAACAaWfkDgAAoAPCHQAAQAeEOwAAgA4IdwAAAB0Q7gAAADog3AEAAHRAuAMAAOjA/wd7Cn08SFfKjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig ,ax= plt.subplots(figsize = (15,5))\n",
    "bp4=ax.boxplot(bplot4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove outliers in audit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many Variables have extremely big outliers which can adversely affect the modelling and prediction. We will first convert the data to normal distribution and store in a temporary variable. We will then record the rows in which data points are 5 standard deviations away from mean(outliers). We will delete these rows from the data file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(776, 27)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.67046481 0.30480033 1.42984618 ...        nan 0.14112307 1.24268351]\n",
      " [0.67046481 0.43173627 0.86976136 ...        nan 0.17228042 0.80471013]\n",
      " [0.67046481 0.34187176 0.86976136 ...        nan 0.17748711 0.80471013]\n",
      " ...\n",
      " [1.45599165 0.38944709 0.86976136 ...        nan 0.17796327 0.80471013]\n",
      " [1.45599165 0.39649529 0.86976136 ...        nan 0.17804608 0.80471013]\n",
      " [1.45599165 0.43173627 0.86976136 ...        nan 0.17792186 0.80471013]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parth\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:2253: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (a - mns) / sstd\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "z=np.abs(stats.zscore(audit.iloc[:,np.r_[0,2:27]]))\n",
    "print(z) #Warning occurs because some of the columns have standard deviation 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parth\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in greater\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "outlier =list((np.where(z > 5.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=set(outlier[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows to delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "delrows =list(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_dt=audit.drop(delrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(729, 27)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit_dt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove 100% Skewed Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100% skewed data columns in essence means that the entire column has the same value. Naturally this does not provide any variation or information to the model. Therefore we delete these columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sector_score  is---->   27.16 % skewed \n",
      "LOCATION_ID  is---->   9.74 % skewed \n",
      "PARA_A  is---->   20.16 % skewed \n",
      "Score_A  is---->   55.28 % skewed \n",
      "Risk_A  is---->   20.16 % skewed \n",
      "PARA_B  is---->   36.76 % skewed \n",
      "Score_B  is---->   69.55 % skewed \n",
      "Risk_B  is---->   36.76 % skewed \n",
      "TOTAL  is---->   12.07 % skewed \n",
      "numbers  is---->   93.14 % skewed \n",
      "Score_B.1  is---->   93.14 % skewed \n",
      "Risk_C  is---->   93.14 % skewed \n",
      "Money_Value  is---->   44.72 % skewed \n",
      "Score_MV  is---->   76.82 % skewed \n",
      "Risk_D  is---->   44.86 % skewed \n",
      "District_Loss  is---->   85.05 % skewed \n",
      "PROB  is---->   100.00 % skewed \n",
      "RiSk_E  is---->   85.05 % skewed \n",
      "History  is---->   95.75 % skewed \n",
      "Prob  is---->   95.75 % skewed \n",
      "Risk_F  is---->   95.75 % skewed \n",
      "Score  is---->   39.78 % skewed \n",
      "Inherent_Risk  is---->   7.13 % skewed \n",
      "CONTROL_RISK  is---->   81.34 % skewed \n",
      "Detection_Risk  is---->   100.00 % skewed \n",
      "Audit_Risk  is---->   7.13 % skewed \n",
      "Risk  is---->   64.33 % skewed \n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(0,len(audit_dt.columns)):\n",
    "    print(audit_dt.columns.values[i],' is---->   {:,.2f}'.format(audit_dt.iloc[:,i].value_counts(normalize=True).values[0]*100), '% skewed ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_dt.drop(['PROB'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_dt.drop(['Detection_Risk'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(729, 25)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit_dt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Outliers in Trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Everything 5 Standard deviation away from mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(776, 18)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.67046481 0.30480033 1.42984618 ... 0.24656792 0.35250258 0.77246865]\n",
      " [0.67046481 0.43173627 0.86976136 ... 0.24656792 0.81850259 1.29455091]\n",
      " [0.67046481 0.34187176 0.86976136 ... 0.24656792 0.81850259 1.29455091]\n",
      " ...\n",
      " [1.45599165 0.38944709 0.86976136 ... 0.24656792 0.81850259 1.29455091]\n",
      " [1.45599165 0.39649529 0.86976136 ... 0.24656792 0.81850259 1.29455091]\n",
      " [1.45599165 0.43173627 0.86976136 ... 0.24656792 0.81850259 1.29455091]]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "z=np.abs(stats.zscore(trial.iloc[:,np.r_[0,2:18]]))\n",
    "print(z) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier =list((np.where(z > 5.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=set(outlier[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "delrows =list(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(729, 18)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_dt=trial.drop(delrows)\n",
    "trial_dt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove 100% Skewed Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sector_score  is---->   27.16 % skewed \n",
      "LOCATION_ID  is---->   9.74 % skewed \n",
      "PARA_A  is---->   20.16 % skewed \n",
      "SCORE_A  is---->   55.28 % skewed \n",
      "PARA_B  is---->   36.76 % skewed \n",
      "SCORE_B  is---->   69.55 % skewed \n",
      "TOTAL  is---->   12.07 % skewed \n",
      "numbers  is---->   93.14 % skewed \n",
      "Marks  is---->   93.14 % skewed \n",
      "Money_Value  is---->   44.72 % skewed \n",
      "MONEY_Marks  is---->   76.82 % skewed \n",
      "District  is---->   85.05 % skewed \n",
      "Loss  is---->   100.00 % skewed \n",
      "LOSS_SCORE  is---->   100.00 % skewed \n",
      "History  is---->   95.75 % skewed \n",
      "History_score  is---->   95.75 % skewed \n",
      "Score  is---->   39.78 % skewed \n",
      "Risk  is---->   60.22 % skewed \n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(trial_dt.columns)):\n",
    "    print(trial_dt.columns.values[i],' is---->   {:,.2f}'.format(trial_dt.iloc[:,i].value_counts(normalize=True).values[0]*100), '% skewed ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_dt.drop(['Loss'], axis=1, inplace = True)\n",
    "trial_dt.drop(['LOSS_SCORE'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(729, 16)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_dt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge two datasets into one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use common columns to merge the two data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_use = trial_dt.columns.intersection(audit_dt.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sector_score', 'LOCATION_ID', 'PARA_A', 'PARA_B', 'TOTAL', 'numbers',\n",
       "       'Money_Value', 'History', 'Score', 'Risk'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_dt=trial_dt.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_dt=audit_dt.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(audit_dt,trial_dt,how='inner',left_on=('Sector_score', 'LOCATION_ID', 'PARA_A', 'PARA_B', 'TOTAL', 'numbers',\n",
    "       'Money_Value', 'History', 'Score', 'Risk'), right_on=('Sector_score', 'LOCATION_ID', 'PARA_A', 'PARA_B', 'TOTAL', 'numbers',\n",
    "       'Money_Value', 'History', 'Score', 'Risk'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Audit data we have variables 'Score_A' and 'Score_B'. When we multiply these two columns by 10 we get 'SCORE_A' and 'SCORE_B' \n",
    "in trial dataset. We drop 'SCORE_A' and 'SCORE_B' because they provide the same information as 'Score_A' and 'Score_B' from\n",
    "Audit data set. It is redudant to keep them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['SCORE_A','SCORE_B'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting the duplicate entries as they are redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 537 entries, 0 to 536\n",
      "Data columns (total 29 columns):\n",
      "Sector_score     537 non-null float64\n",
      "LOCATION_ID      537 non-null object\n",
      "PARA_A           537 non-null float64\n",
      "Score_A          537 non-null float64\n",
      "Risk_A           537 non-null float64\n",
      "PARA_B           537 non-null float64\n",
      "Score_B          537 non-null float64\n",
      "Risk_B           537 non-null float64\n",
      "TOTAL            537 non-null float64\n",
      "numbers          537 non-null float64\n",
      "Score_B.1        537 non-null float64\n",
      "Risk_C           537 non-null float64\n",
      "Money_Value      537 non-null float64\n",
      "Score_MV         537 non-null float64\n",
      "Risk_D           537 non-null float64\n",
      "District_Loss    537 non-null int64\n",
      "RiSk_E           537 non-null float64\n",
      "History          537 non-null int64\n",
      "Prob             537 non-null float64\n",
      "Risk_F           537 non-null float64\n",
      "Score            537 non-null float64\n",
      "Inherent_Risk    537 non-null float64\n",
      "CONTROL_RISK     537 non-null float64\n",
      "Audit_Risk       537 non-null float64\n",
      "Risk             537 non-null int64\n",
      "Marks            537 non-null int64\n",
      "MONEY_Marks      537 non-null int64\n",
      "District         537 non-null int64\n",
      "History_score    537 non-null int64\n",
      "dtypes: float64(21), int64(7), object(1)\n",
      "memory usage: 125.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(537, 29)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove one variable out of Highly Correlated variable pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove one variable out of the 100% correlated variable pairs. Doing so we are getting rid of the redudandant variable \n",
    "which serves no purpose in modelling. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat= (data.corr().abs())\n",
    "highcorr=np.where(corrmat>=0.999999999999999)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  8,  9, 10, 11, 12, 13, 14, 14,\n",
       "        14, 15, 15, 15, 16, 16, 17, 17, 18, 18, 19, 20, 21, 22, 23, 24, 24,\n",
       "        25, 26, 26, 26, 27, 27], dtype=int64),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 24,  9, 10, 11, 12, 13, 14, 15,\n",
       "        26, 14, 15, 26, 16, 27, 17, 18, 17, 18, 19, 20, 21, 22, 23,  8, 24,\n",
       "        25, 14, 15, 26, 16, 27], dtype=int64))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highcorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "highcorr=set([(corrmat.columns[x],corrmat.columns[y]) for x,y in zip(*highcorr) if x!=y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "highcorr=list(highcorr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the variable pairs that are 100% correlated with each other and therefore provide the same information to model. \n",
    "It is perfectly safe to delete one variable out of the pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RiSk_E     District ------> 1.0\n",
      "Risk_F     Prob ------> 1.0\n",
      "History     History_score ------> 0.9999999999999999\n",
      "Marks     numbers ------> 0.9999999999999999\n",
      "District     RiSk_E ------> 1.0\n",
      "RiSk_E     District_Loss ------> 1.0\n",
      "District_Loss     RiSk_E ------> 1.0\n",
      "District     District_Loss ------> 1.0\n",
      "numbers     Marks ------> 0.9999999999999999\n",
      "District_Loss     District ------> 1.0\n",
      "History_score     History ------> 0.9999999999999999\n",
      "Prob     Risk_F ------> 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in highcorr:\n",
    "    print(i[0],'   ',i[1],'------>',data[i[0]].corr(data[i[1]]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Risk_F','District_Loss','District','Marks','History_score'],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 537 entries, 0 to 536\n",
      "Data columns (total 24 columns):\n",
      "Sector_score     537 non-null float64\n",
      "LOCATION_ID      537 non-null object\n",
      "PARA_A           537 non-null float64\n",
      "Score_A          537 non-null float64\n",
      "Risk_A           537 non-null float64\n",
      "PARA_B           537 non-null float64\n",
      "Score_B          537 non-null float64\n",
      "Risk_B           537 non-null float64\n",
      "TOTAL            537 non-null float64\n",
      "numbers          537 non-null float64\n",
      "Score_B.1        537 non-null float64\n",
      "Risk_C           537 non-null float64\n",
      "Money_Value      537 non-null float64\n",
      "Score_MV         537 non-null float64\n",
      "Risk_D           537 non-null float64\n",
      "RiSk_E           537 non-null float64\n",
      "History          537 non-null int64\n",
      "Prob             537 non-null float64\n",
      "Score            537 non-null float64\n",
      "Inherent_Risk    537 non-null float64\n",
      "CONTROL_RISK     537 non-null float64\n",
      "Audit_Risk       537 non-null float64\n",
      "Risk             537 non-null int64\n",
      "MONEY_Marks      537 non-null int64\n",
      "dtypes: float64(20), int64(3), object(1)\n",
      "memory usage: 104.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(537, 24)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sector_score', 'LOCATION_ID', 'PARA_A', 'Score_A', 'Risk_A',\n",
       "       'PARA_B', 'Score_B', 'Risk_B', 'TOTAL', 'numbers', 'Score_B.1',\n",
       "       'Risk_C', 'Money_Value', 'Score_MV', 'Risk_D', 'RiSk_E', 'History',\n",
       "       'Prob', 'Score', 'Inherent_Risk', 'CONTROL_RISK', 'Audit_Risk',\n",
       "       'Risk', 'MONEY_Marks'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried converting the location ID to one-hot-vectors and then run the model for prediction, doing so our accuracy dipped \n",
    "by approximately 5%  for almost every algorithm. Therefore we decided to drop the 'LOCATION_ID'. Doing so we could attain better accuracy score in prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.concat([data, pd.get_dummies(data['LOCATION_ID'], prefix='LOCID')], axis=1)\n",
    "data.drop(['LOCATION_ID'], axis=1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('data.csv','w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(data)\n",
    "    \n",
    "csvfile.close()\n",
    "\n",
    "data.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing for Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Risk']\n",
    "X=data.drop(['Risk','Audit_Risk'],axis=1, inplace=False)\n",
    "#X=data.drop(['Risk'],axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dt, X_test_dt, y_train, y_test = train_test_split(X,y,random_state=0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector_score</th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>Score_A</th>\n",
       "      <th>Risk_A</th>\n",
       "      <th>PARA_B</th>\n",
       "      <th>Score_B</th>\n",
       "      <th>Risk_B</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>numbers</th>\n",
       "      <th>Score_B.1</th>\n",
       "      <th>...</th>\n",
       "      <th>Money_Value</th>\n",
       "      <th>Score_MV</th>\n",
       "      <th>Risk_D</th>\n",
       "      <th>RiSk_E</th>\n",
       "      <th>History</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Score</th>\n",
       "      <th>Inherent_Risk</th>\n",
       "      <th>CONTROL_RISK</th>\n",
       "      <th>MONEY_Marks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.89</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.508</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500</td>\n",
       "      <td>6.68</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>8.574</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.83</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.966</td>\n",
       "      <td>4.83</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.554</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.89</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.74</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.548</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.80</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.480</td>\n",
       "      <td>10.80</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>11.75</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.050</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>17.530</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.416</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sector_score  PARA_A  Score_A  Risk_A  PARA_B  Score_B  Risk_B  TOTAL  \\\n",
       "0          3.89    4.18      0.6   2.508    2.50      0.2   0.500   6.68   \n",
       "1          3.89    0.00      0.2   0.000    4.83      0.2   0.966   4.83   \n",
       "2          3.89    0.51      0.2   0.102    0.23      0.2   0.046   0.74   \n",
       "3          3.89    0.00      0.2   0.000   10.80      0.6   6.480  10.80   \n",
       "4          3.89    0.00      0.2   0.000    0.08      0.2   0.016   0.08   \n",
       "\n",
       "   numbers  Score_B.1     ...       Money_Value  Score_MV  Risk_D  RiSk_E  \\\n",
       "0      5.0        0.2     ...              3.38       0.2   0.676     0.4   \n",
       "1      5.0        0.2     ...              0.94       0.2   0.188     0.4   \n",
       "2      5.0        0.2     ...              0.00       0.2   0.000     0.4   \n",
       "3      6.0        0.6     ...             11.75       0.6   7.050     0.4   \n",
       "4      5.0        0.2     ...              0.00       0.2   0.000     0.4   \n",
       "\n",
       "   History  Prob  Score  Inherent_Risk  CONTROL_RISK  MONEY_Marks  \n",
       "0        0   0.2    2.4          8.574           0.4            2  \n",
       "1        0   0.2    2.0          2.554           0.4            2  \n",
       "2        0   0.2    2.0          1.548           0.4            2  \n",
       "3        0   0.2    4.4         17.530           0.4            6  \n",
       "4        0   0.2    2.0          1.416           0.4            2  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sector_score     0\n",
      "PARA_A           0\n",
      "Score_A          0\n",
      "Risk_A           0\n",
      "PARA_B           0\n",
      "Score_B          0\n",
      "Risk_B           0\n",
      "TOTAL            0\n",
      "numbers          0\n",
      "Score_B.1        0\n",
      "Risk_C           0\n",
      "Money_Value      0\n",
      "Score_MV         0\n",
      "Risk_D           0\n",
      "RiSk_E           0\n",
      "History          0\n",
      "Prob             0\n",
      "Score            0\n",
      "Inherent_Risk    0\n",
      "CONTROL_RISK     0\n",
      "MONEY_Marks      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Scaler= MinMaxScaler()\n",
    "X_train = Scaler.fit_transform(X_train_dt)\n",
    "X_test = Scaler.transform(X_test_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MinMaxScaler perserves the shape of orginal distribution. It doesn't change the information embedded in the orginal data. Since we already removed the outliers 4 standard deviations away from mean in the previous step, we wanted to preserve the remaining far values and variance in data as it is to better predict the unknown data set with its variances. Standard scaler simply brings the mean of variables to zero with standard deviation 1 thereby changing the original distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier - Hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter grid:\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_neighbors': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]}\n",
    "print(\"Parameter grid:\\n{}\".format(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_neighbors': 1}\n",
      "Best cross-validation score: 1.00\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "score=[]\n",
    "for i in range(len(grid_search.grid_scores_)):\n",
    "    score.append(grid_search.grid_scores_[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'K')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig ,ax= plt.subplots(figsize = (15,5))\n",
    "plt.plot(range(0,20), score, c = 'g', label = 'Cross Validation Score')\n",
    "#plt.plot(range(1,20), test_score_list, c = 'b', label = 'Test Score')\n",
    "plt.legend(loc = 3)\n",
    "plt.grid(True)\n",
    "plt.xlabel('K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(1)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'C': 0.1, 'gamma': 5}\n",
      "Best score:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_rbf = SVC(kernel='rbf', random_state=0,probability=True)\n",
    "#model param\n",
    "grid_param = {'C':[0.01, 0.1, 1, 10, 100], \n",
    "             'gamma': [0.01, 0.1, 1, 5, 10, 100]}\n",
    "\n",
    "#grid model\n",
    "grid_search = GridSearchCV(svc_rbf, grid_param, cv = 5, n_jobs  = -1)\n",
    "\n",
    "#train grid model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Best params: ', grid_search.best_params_)\n",
    "print('Best score: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=[]\n",
    "c_range = [0.01, 0.1, 1, 10, 100]\n",
    "g_range = [0.01, 0.1, 1, 5, 10, 100]\n",
    "\n",
    "for x in c_range:\n",
    "    for g in g_range:\n",
    "        index.append((x,g))\n",
    "        \n",
    "score=[]\n",
    "for i in range(len(grid_search.grid_scores_)):\n",
    "    score.append(grid_search.grid_scores_[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'C and Gamma')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig ,ax= plt.subplots(figsize = (15,5))\n",
    "plt.plot(range(len(index)), score, c = 'g', label = 'Cross Validation Score')\n",
    "plt.legend(loc = 3)\n",
    "plt.grid(True)\n",
    "plt.xticks(range(len(index)), index, rotation=90)\n",
    "plt.xlabel(r'C and Gamma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=5, kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=0, shrinking=True, tol=0.001,\n",
       "  verbose=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_rbf = SVC(kernel='rbf', random_state=0,C=0.1,gamma=5,probability=True)\n",
    "svc_rbf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'C': 1, 'penalty': 'l1'}\n",
      "Best score:  0.9975124378109452\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "#model param\n",
    "grid_param = {'penalty':['l1','l2'], \n",
    "             'C': [0.1,1,10,50,100,150]}\n",
    "\n",
    "#grid model\n",
    "grid_search = GridSearchCV(logreg, grid_param, cv = 5, n_jobs  = -1)\n",
    "\n",
    "#train grid model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Best params: ', grid_search.best_params_)\n",
    "print('Best score: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=[]\n",
    "penalty = ['l1','l2']\n",
    "C = [0.1,1,10,50,100,150]\n",
    "\n",
    "for c in C:\n",
    "    for p in penalty:\n",
    "        index.append((c,p))\n",
    "        \n",
    "score=[]\n",
    "for i in range(len(grid_search.grid_scores_)):\n",
    "    score.append(grid_search.grid_scores_[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Penalty and C')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3oAAAFmCAYAAAA72OixAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xt8j/X/x/Hn2zbG5lDGnA8VlZBsCDklpdIB5ZCQviwiKXJIMUQnJaUTklA5VUQoyZzDphHJIZUccqZtzGx7//7Yh9/sMwzbrs8+e9xvt918Ptf1vq7reb0Me3lfn+sy1loBAAAAALxHHqcDAAAAAAAyF40eAAAAAHgZGj0AAAAA8DI0egAAAADgZWj0AAAAAMDL0OgBAAAAgJeh0QMAAAAAL0OjBwAAAABehkYPAAAAALyMr9MBLkdQUJCtUKGC0zHcxMXFKSAgwOkYHoWauKMm7qhJ+qiLO2rijpq4oybuqIk7apI+6uLOU2sSFRV12Fpb7FLjclSjV6FCBUVGRjodw01ERIQaN27sdAyPQk3cURN31CR91MUdNXFHTdxRE3fUxB01SR91ceepNTHG/J2RcVy6CQAAAABehkYPAAAAALwMjR4AAAAAeBkaPQAAAADwMjR6AAAAAOBlaPQAAAAAwMvQ6AEAAACAl6HRAwAAAAAvQ6MHAAAAAF7G1+kAQG5w5OQRRR+PVmM1djoKPNiZpDP6euvXWr9/vXZE7XA6jkfZtn8bNUmDmrijJu6oiTtqkj7q4i7xv8Qc/bMbjR6QDZ6Y+4Tmb5+vbb7bNPbescrrk9fpSPAwB+MOqs2sNlr297KUBdudzeORqIk7auKOmrijJu6oSfqoy3nal22vHurhdIwrRqMHZLH1e9dr/vb5qhxYWR9FfaRNBzdp1qOzVKpgKaejwUOs37terWa20uGTh/XpQ58q4ECA6tWt53Qsj7J6zWpqkgY1cUdN3FETd9QkfdTF3S/rfnE6wlWh0QOyWPiycF2b/1q9fevbiisZpy5zuyhkfIhmPzpb9cvVdzoeHDbpl0l6+runVSKwhFY9uUo1S9ZURESEShcq7XQ0j1IsXzFqkgY1cUdN3FETd9QkfdTF3Q7fnH0pKzdjAbLQ2j1rtWDHAvWr208BvgFqc0sbre26VgF+AWr8WWN9sP4DWWudjgkHJCQlqMf8Hvrft/9Tg/INFBkWqZolazodCwAAeAkaPSALhS8LV9H8RdWrdq9zy6oWr6r13dbr7uvvVs8FPfXkt08qPjHewZTIbvti9qnx5Mb6KOoj9a/XXws7LFRQgSCnYwEAAC9CowdkkTX/rNGinYv0Qr0XVDBfwfPWXZP/Gs1rP08vN3xZk6Mnq8GnDbT7xG6HkiI7rdq9SiHjQ7TpwCbNeGSGXm/2unzzcBU9AADIXDR6QBYJXxauoAJB6lm7Z7rr85g8Gt5kuOa0naNth7cpZHyIlv65NJtTIrtYa/XB+g/U+LPGCswbqJ+7/qw2t7RxOhYAAPBSNHpAFlj9z2r98McP6l+vvwLzBl507EM3PaR13dYpqECQmk1tprfXvM3n9rxMfGK8nvz2SfVc0FN3X3+31ndbr6rFqzodCwAAeDEaPSALDI0YquIBxfV0raczNP6moJu0tutaPXjjg+r7Q191+LqD4hLisjglssPuE7t1x6Q7NDl6soY0HKJ57eepiH8Rp2MBAAAvR6MHZLKVu1fqx10/qn+9/grIG5Dh7QrlK6TZbWZr5J0jNX3zdNWbVE+7ju3KwqTIakv/XKqQ8SHafmS75rabq2FNhimP4a9dAACQ9fiJA8hkQyOGKjggWD1q9bjsbfOYPHqxwYta0GGBdp/YrdDxoVq0c1EWpERWstbq7TVvq9nUZipWoJjWd1uvB2980OlYAAAgF6HRAzLR8r+X66c/f9KA+gNUwK/AFe+n+Q3NFdktUmUKldF9n9+nUStG8bm9HCIuIU6Pff2Y+v7QVw/d9JDWdl2rG4NudDoWAADIZWj0gEw0NGKoSgSWUPfQ7le9r+uvvV5r/rdGbau21eCfBqv1zNaKOR2TCSmRVf44+ofqTaqnGZtnaNSdozT70dluj9YAAADIDjR6QCaJ+CtCEX9FaGD9gcrvlz9T9hmQN0BftPpCb939lr7d9q3qTKyjbYe3Zcq+kbkW7Vyk0Amh+ufEP1rQYYEGNRgkY4zTsQAAQC5FowdkAmuthkYMVcnAkgoLCcvUfRtj9Hzd57W442IdOnlItSfW1rfbvs3UY+DKWWs1asUo3ff5fSpXuJwiwyLV/IbmTscCAAC5HI0ekAmW/rVUy/9erkF3DMq02by0mlRsoqiwKFW6tpIemv6QhiwdomSbnCXHQsbEnI5R65mtNfinwWpXtZ1WP7la111zndOxAAAAaPSAq3V2Nq90wdLqFtItS49VrnA5reiyQk/UeEIjlo/QA18+oOPxx7P0mEjftsPbzs2uvn332/q81eeX9TgNAACArESjB1ylJX8u0crdKzXojkHy9/XP8uPl98uvSQ9O0vv3va8f/vhBtSbU0uaDm7P8uPh/c3+fq1oTaunwycNa3HGxnqv7HJ/HAwAAHoVGD7gKZ2fzyhQqo641u2bbcY0xerrW01raealiE2J1+8TbNXPLzGw7fm6VbJM1ZOkQPTzjYd0YdKOiwqLUpGITp2MBAAC4odEDrsLiXYu1+p/VevGOF5XPN1+2H/+OcncoKixK1YOrq+3sthqweIASkxOzPUducDz+uB748gGNWD5CXWp00YouK1SucDmnYwEAAKSLRg+4Qmdn88oWKqsnb3vSsRylCpZSxBMR6h7SXW+sfkP3fn6vDp887Fgeb7T54GaFjg/V4j8W64P7PtAnD36SLZfpAgAAXCkaPeAKff/H9/p5z88a3GCwI7N5qeX1yasPW3yoTx78RMv/Xq7Q8aH6Zf8vjmbyFjO3zFSdiXUUdyZOSzsvVY9aPfg8HgAA8Hg0esAVODubV75weXW5rYvTcc558rYntaLLCiXZJNWbVE9TN051OlKOlZicqP6L+6vt7LaqUaKGosKiVL9cfadjAQAAZAiNHnAFFu5cqHV712lwg8HK65PX6TjnqV26tqLColSndB11mtNJzy58VmeSzjgdK0c5fPKwmk9rrjdXv6keoT20tPNSlSpYyulYAAAAGUajB1yms7N5FYpU0BM1nnA6TrqKBxTX4o6L1adOH7277l3dNfUuHYg94HSsHGHD/g0KHR+qlbtX6pMHP9EH93/gcc08AADApWSo0TPGNDfGbDPG7DTGDExnfXljzBJjzCZjTIQxpkyqda8bYza7vtqmWj7ZGPOnMSba9VUjc04JyFrf7fhOkfsi9VKDl+Tn4+d0nAvy8/HTmOZjNK3lNK3fu14h40O0ds9ap2N5tKkbp6r+pPpKskla0WWFozfZAQAAuBqXbPSMMT6S3pd0r6QqktobY6qkGTZa0hRrbXVJwyW96tr2fkk1JdWQVEfSC8aYQqm2e8FaW8P1FX3VZwNkMWutwiPCdd0116nTrZ2cjpMhHap30Or/rVZen7xqOLmhJkRNcDqSxzmTdEa9F/ZWpzmddHuZ2xUVFqVapWs5HQsAAOCKZWRGr7akndbaXdbaBEnTJT2UZkwVSUtcr5emWl9F0jJrbaK1Nk7SRknNrz424Ix52+cpan+Ux8/mpVWjRA1FhkWqcYXGCpsfpqfmPaXTiaedjuURDsQeUNMpTfXeuvf03O3PaXHHxSoeUNzpWAAAAFfFWGsvPsCYRyQ1t9Z2db3vKKmOtbZXqjFfSFprrR1rjGkl6StJQZJCJA2V1ExSAUnrJL1vrX3LGDNZUl1Jp5XSJA601rr95GmMCZMUJknBwcEh06dPv7ozzgKxsbEKDAx0OoZH8caaWGv11IanFJcYpym1p8jH+FzW9p5QkySbpEl/TtIX/3yhKgWrKPyWcBXLV8yxPE7X5Lf/ftPQLUMVkxijfpX76a7guxzLkprTdfFE1MQdNXFHTdxRE3fUJH3UxZ2n1qRJkyZR1trQSw601l70S9Kjkiamet9R0ntpxpSS9LWkXySNlbRHUmHXusGSoiUtlvS5pGddy0tKMpLySfpM0pBLZQkJCbGeaOnSpU5H8DjeWJNvtn5jFS47+ZfJV7S9J9Vk9pbZNmBkgA1+M9gu/2u5YzmcrMn4yPE274i8tuI7FW30/mjHcqTHk75XPAU1cUdN3FETd9TEHTVJH3Vx56k1kRRpL9E3WWszdOnmHkllU70vI2lfmmZxn7W2lbX2NldjJ2vtCdevI23KZ/CauRq7Ha7l+11ZT0v6VCmXiAIeKdkmKzwiXJWuraQO1Ts4Heeqta7SWuu6rVOhfIV055Q79d7a987+p43XO514WmHzwhQ2P0yNKzRWZFikbi1xq9OxAAAAMlVGGr31kioZYyoaY/JKaifp29QDjDFBxpiz+xokaZJruY8xpqjrdXVJ1SX94Hpf0vWrkfSwpM1XfzpA1pjz+xxtPLBRLzd8Wb55fJ2OkymqFKui9d3W694b7lXvRb31xNwndOrMKadjZam9/+1Vo8mNNGHDBA26Y5AWPLZA1+a/1ulYAAAAme6SP7FaaxONMb0kfS/JR9Ika+0WY8xwpUwbfiupsaRXjTFW0nJJPV2b+0lakdLL6T9Jj1trE13rPjfGFFPKLF+0pO6Zd1pA5jk7m1e5aGW1r9be6TiZqrB/Yc1pN0cjlo1Q+LJwbT64WV+3+Vrli5R3OlqmW/H3Cj0661HFnYnT7Ednq3WV1k5HAgAAyDIZmpqw1i6QtCDNsiGpXs+WNDud7eKVcufN9PZ552UlBRzy9dav9evBXzWt5TSvmc1LLY/Jo6GNhyqkVIg6fN1BIeNDNOORGWp6XVOno2UKa63GrRun5394XhWLVNRPnX9SlWLp/rUEAADgNTL0wHQgt0q2yRq2bJhuCrpJ7aq2czpOlmpRuYUiu0UqODBYd0+7W2+uejPHf27v1JlT6jyns3ov6q17b7hX67utp8kDAAC5Ao0ecBGzf5utzQc3a0jDIfLJc3mPU8iJKhWtpLVd16rVza3U/8f+avdVO8UlxDkd64r8dfwv1Z9UX1M3TdWwxsM0p90cFfYv7HQsAACAbEGjB1xAUnKShi0bppuDblabW9o4HSfbBOYN1MxHZuq1pq9p9m+zdfsnt2vn0Z1Ox7osP+76UaHjQ7Xr2C7Naz9PQxoNUR7DX3cAACD34Ccf4AJm/TZLvx36TUMbDc0Vs3mpGWM04I4BWtRhkfbF7FOtCbW0YMeCS2/oMGut3lz1pu6Zdo+CA4O1vtt6tajcwulYAAAA2Y5GD0jH2dm8W4rdokdvedTpOI5pdn0zRXaLVIUiFdTiixYasWyEkm2y07HSFZsQq3ZftVP/H/ur1c2ttLbrWlUqWsnpWAAAAI6g0QPSMWPLDP1++HcNbTQ011/yV/Gailr15Co9Vu0xDYkYolYzWum/0/85Hes8O4/uVN1P6mr2b7P1+l2va+YjMxWYN9DpWAAAAI7J3T/BAulISk7S8GXDVa14NZ615lLAr4Cmtpyqd+55R/O3z1ftCbW19dBWp2NJkhbsWKBaE2ppX8w+LeqwSP3r95fr2Z0AAAC5Fo0ekMaXm7/UtiPbmM1LwxijZ29/Vks6LdHRU0dVe2JtfbP1G8fyJNtkjVg2Qi2+aKEKRSooslukml3fzLE8AAAAnoSfYoFUEpMTNXzZcFUPrq6WN7d0Oo5HalShkTY8tUFVilVRq5mtNHjJYCUlJ2VrhhPxJ9RqRisNiRiiDtU7aNWTq1TxmorZmgEAAMCT0egBqXzx6xfacXSHwhuFM5t3EWUKldGyJ5bpf7f9T6NWjlKLL1vo2Klj2XLsrYe2qs7EOpq/fb7GNh+rKQ9PUQG/AtlybAAAgJyCn2QBl8TkRI1YPkI1StTQwzc97HQcj+fv668JD0zQR/d/pCW7lih0Qqg2HdiUpcf8Zus3qj2xto7FH9OSTkvUu05vPo8HAACQDho9wGXapmnaeXSnwhuF0zxkkDFGT4U+pWVPLNOpM6dU95O6mr55eqYfJyk5SYOXDFarma1UpVgVRYVFqVGFRpl+HAAAAG9BowdIOpN0RiOWj1DNkjX14I0POh0nx6lbtq6iwqJ0W4nb1P6r9ur3Qz8lJidmyr6PnjqqFl+20KiVo9T1tq5a9sQylSlUJlP2DQAA4K1o9ABJUzdN1a5ju5jNuwolC5bUT51/Us9aPfXWmrd0z7R7dCju0FXtc9OBTao1oZaW7Fqij1t8rAkPTpC/r38mJQYAAPBeNHrI9c4kndEry19RaKlQtajcwuk4OVpen7wad984TX5oslbtXqXQCaGK2hd1Rfuavnm66n5SV/GJ8Vr2xDKFhYRlcloAAADvRaOHXO+zjZ/pz+N/MpuXiTrX6KxVT66SJNWfVF+ToydneNvE5ET1/b6v2n/VXjVL1lRUWJTqlq2bRUkBAAC8E40ecrWEpAS9svwV1S5dW/dVus/pOF4lpFSIIrtFqn65+uoyt4t6LeilhKSEi25zKO6Q7p56t97++W31qtVLSzotUYnAEtmUGAAAwHvQ6CFXmxw9WX+f+JvZvCxSLKCYvn/8e/Wt21fvr39fd352p/6N/TfdsVH7ohQyPkSr/1mtyQ9N1nv3vae8PnmzOTEAAIB3oNFDrpWQlKCRK0aqTuk6an5Dc6fjeC3fPL4affdofdn6S/3y7y+q+XFNrflnzXljJkdPVv1J9WWM0aonV6lzjc4OpQUAAPAONHrItSb9Mkm7T+zWsMbDmM3LBu2qttOa/61Rfr/8ajS5kT6O/Fhnks+o53c91WVuF9UvV1+R3SIVUirE6agAAAA5nq/TAQAnnE48rZErRqpumbq6+/q7nY6Ta1QPrq713darw9cd1P277iqer7gOnj6ofnX76dW7XpVvHv5KAgAAyAzM6CFX+uSXT7Tnvz3M5jng2vzXan77+RrcYLBOJ5/Wl62/1Jt3v0mTBwAAkIn4yQq5TnxivEatGKX6ZevrruvucjpOruSTx0ev3PmKmpqmalK1idNxAAAAvA6NHnKdiRsmam/MXn328GfM5jmM+gMAAGQNLt1ErhKfGK9XV76qBuUa6M6KdzodBwAAAMgSzOghVxkfNV77YvZpWstpzCYBAADAazGjh1zj1JlTenXlq2pUvpGaVORzYQAAAPBezOgh1/g46mP9G/uvpree7nQUAAAAIEsxo4dc4eSZk3pt5WtqUqGJGlVo5HQcAAAAIEsxo4dc4aPIj3Qg7oBmPTrL6SgAAABAlmNGD14vLiFOr696XU0rNlWD8g2cjgMAAABkORo9eL0PIz/UwbiDGtZ4mNNRAAAAgGxBowevFpcQpzdWvaFm1zVT/XL1nY4DAAAAZAsaPXi199e/r0MnDzGbBwAAgFyFRg9eKzYhVm+uflP3XH+P6pat63QcAAAAINvQ6MFrjVs3TodPHmY2DwAAALkOjR68UszpGL25+k3de8O9qlOmjtNxAAAAgGxFowev9N6693T01FGFNw53OgoAAACQ7Wj04HX+O/2fRq8erfsr3a/apWs7HQcAAADIdjR68Drvrn1Xx+KPMZsHAACAXItGD17lRPwJvbXmLT1Q+QGFlgp1Og4AAADgCBo9eJWxa8fqePxxZvMAAACQq9HowWscjz+ut9e8rYdufEg1S9Z0Og4AAADgGBo9eI13fn5HJ06fYDYPAAAAuR6NHrzCsVPHNObnMWp5U0vVKFHD6TgAAACAo2j04BXG/DxG/53+j9k8AAAAQBls9IwxzY0x24wxO40xA9NZX94Ys8QYs8kYE2GMKZNq3evGmM2ur7apllc0xqw1xuwwxswwxuTNnFNCbnP01FG98/M7an1za1UPru50HAAAAMBxl2z0jDE+kt6XdK+kKpLaG2OqpBk2WtIUa211ScMlvera9n5JNSXVkFRH0gvGmEKubV6XNMZaW0nSMUn/u/rTQW709pq3FZMQo6GNhjodBQAAAPAIGZnRqy1pp7V2l7U2QdJ0SQ+lGVNF0hLX66Wp1leRtMxam2itjZO0UVJzY4yRdKek2a5xn0l6+MpPA7nVkZNHNHbtWD1a5VFVC67mdBwAAADAIxhr7cUHGPOIpObW2q6u9x0l1bHW9ko15gtJa621Y40xrSR9JSlIUoikoZKaSSogaZ1SZgc/k/SztfYG1/ZlJS201lZN5/hhksIkKTg4OGT69OlXd8ZZIDY2VoGBgU7H8CjZVZMJuyboy3++1Cehn6hiQMUsP97V4PvEHTVJH3VxR03cURN31MQdNXFHTdJHXdx5ak2aNGkSZa0NvdQ43wzsy6SzLG132E/SOGPME5KWS9orKdFa+4Mxppak1ZIOSVojKTGD+0xZaO14SeMlKTQ01DZu3DgDkbNXRESEPDGXk7KjJodPHta3a75Vm1vaqMv9XbL0WJmB7xN31CR91MUdNXFHTdxRE3fUxB01SR91cZfTa5KRSzf3SCqb6n0ZSftSD7DW7rPWtrLW3iZpsGvZCdevI621Nay1zZTS4O2QdFhSEWOM74X2CVzK6NWjFZcQpyGNhjgdBQAAAPAoGWn01kuq5LpLZl5J7SR9m3qAMSbIGHN2X4MkTXIt9zHGFHW9ri6puqQfbMr1okslPeLaprOkuVd7Msg9DsUd0rh149SuajtVKZb23kAAAABA7nbJRs9amyipl6TvJW2VNNNau8UYM9wY86BrWGNJ24wx2yUFSxrpWu4naYUx5jelXH75uGt/kjRA0vPGmJ2Sikr6JJPOCbnAm6vf1KnEU8zmAQAAAOnIyGf0ZK1dIGlBmmVDUr2erf+/g2bqMfFKufNmevvcpZQ7egKX5WDcQb2//n21r9peNwXd5HQcAAAAwONk6IHpgCd5Y9Ubik+MZzYPAAAAuAAaPeQo/8b+qw/Wf6AO1TqoctHKTscBAAAAPBKNHnKUN1a9oYSkBL3c8GWnowAAAAAei0YPOcb+mP36MPJDPV79cVUqWsnpOAAAAIDHotFDjvH6qtd1JukMs3kAAADAJdDoIUfYF7NPH0V+pE63dtL1117vdBwAAADAo9HoIUd4beVrSrJJeqnhS05HAQAAADwejR483t7/9mp81Hh1vrWzrrvmOqfjAAAAAB6PRg8e79WVrzKbBwAAAFwGGj14tH9O/KMJGyaoS40uqlCkgtNxAAAAgByBRg8e7dWVr8paq8ENBjsdBQAAAMgxaPTgsXaf2K2JGybqydueVPki5Z2OAwAAAOQYNHrwWKNWjJIkvdjgRYeTAAAAADkLjR480t/H/9akXyapa82uKle4nNNxAAAAgByFRg8eaeSKkTLGMJsHAAAAXAEaPXicP4/9qU+jP1W3mt1UplAZp+MAAAAAOQ6NHjzOyBUj5WN8NOiOQU5HAQAAAHIkGj14lF3Hdmly9GSFhYSpdKHSTscBAAAAciQaPXiUV5a/Ij8fPw28Y6DTUQAAAIAci0YPHmPn0Z2asnGKngp5SqUKlnI6DgAAAJBj0ejBY5ydzRtQf4DTUQAAAIAcjUYPHmHHkR2aummqeoT2UMmCJZ2OAwAAAORoNHrwCCOWj1A+n3zM5gEAAACZgEYPjtt2eJs+//VzPV3raQUHBjsdBwAAAMjxaPTguBHLR8jf11/96/d3OgoAAADgFWj04KjfD/+uLzd/qZ61eqp4QHGn4wAAAABegUYPjhq+bLjy++bXC/VecDoKAAAA4DVo9OCY3w79pumbp6tX7V4qFlDM6TgAAACA16DRg2OGLxuugLwB6levn9NRAAAAAK9CowdHbDm4RTO3zNQztZ9RUIEgp+MAAAAAXoVGD44YtmyYAvMGqm/dvk5HAQAAALwOjR6y3a8HftWs32apd53eKlqgqNNxAAAAAK9Do4dsN2zZMBXKV0jP133e6SgAAACAV6LRQ7ba+O9GfbX1Kz1b51ldm/9ap+MAAAAAXolGD9lq2LJhKpyvsJ67/TmnowAAAABei0YP2Sb632h98/s36nN7H12T/xqn4wAAAABei0YP2SY8IlyF8xVWn9v7OB0FAAAA8Go0esgWG/Zv0Nxtc/V83edVxL+I03EAAAAAr0ajh2wRHhGuIv5F9GydZ52OAgAAAHg9Gj1kuch9kZq3fZ761u2rwv6FnY4DAAAAeD0aPWS58IhwXZv/WvWu09vpKAAAAECuQKOHLLVu7zp9t+M79a3bV4XyFXI6DgAAAJAr0OghS4VHhKto/qJ6pvYzTkcBAAAAcg0aPWSZn/f8rIU7F6pfvX4qmK+g03EAAACAXINGD1kmPCJcQQWC1Kt2L6ejAAAAALkKjR6yxJYTW/T9H9/rhXovKDBvoNNxAAAAgFwlQ42eMaa5MWabMWanMWZgOuvLG2OWGGM2GWMijDFlUq17wxizxRiz1RjzrjHGuJZHuPYZ7foqnnmnBadN/nuyihUopp61ejodBQAAAMh1LtnoGWN8JL0v6V5JVSS1N8ZUSTNstKQp1trqkoZLetW1bT1J9SVVl1RVUi1JjVJt18FaW8P1dfBqTwaeYdXuVYo8Fqn+9fsrIG+A03EAAACAXCcjM3q1Je201u6y1iZImi7poTRjqkha4nq9NNV6K8lfUl5J+ST5STpwtaHhuZJtsgb8OEDX+F2jHqE9nI4DAAAA5ErGWnvxAcY8Iqm5tbar631HSXWstb1SjflC0lpr7VhjTCtJX0kKstYeMcaMltRVkpE0zlo72LVNhKSikpJc41+x6YQxxoRJCpOk4ODgkOnTp1/lKWe+2NhYBQbyOTRJmr9/vt7a/pZ6l++tlhVaOh3Ho/B94o6apI+6uKMm7qiJO2rijpq4oybpoy7uPLUmTZo0ibLWhl5qnG8G9mXSWZa2IesnaZwx5glJyyXtlZRojLlB0s2Szn5mb7ExpqG1drlSLtvca4wpqJRGr6OkKW4Hsna8pPGSFBoaahs3bpyByNkrIiJCnpgru/0b+69avt9SjSs01sPlHqYmafB94o6apI+6uKMm7qiJO2rijpq4oybpoy7ucnpNMnLp5h5JZVO9LyNpX+oB1tp91tpW1trbJA12LTshqaWkn621sdbaWEkLJd3uWr/X9WtK3fQAAAAgAElEQVSMpC+UcokocrA+i/ro5JmT+uj+j+S65w4AAAAAB2Sk0VsvqZIxpqIxJq+kdpK+TT3AGBNkjDm7r0GSJrle75bUyBjja4zxU8qNWLa63ge5tvWT1ELS5qs/HThl4Y6FmrFlhgY3GKwbg250Og4AAACQq12y0bPWJkrqJel7SVslzbTWbjHGDDfGPOga1ljSNmPMdknBkka6ls+W9IekXyVtlLTRWjtPKTdm+d4Ys0lStFIu9ZyQaWeFbBWXEKce3/XQTUE3aUD9AU7HAQAAAHK9jHxGT9baBZIWpFk2JNXr2Upp6tJulyTpqXSWx0kKudyw8EzhEeH6+8TfWv7EcuXzzed0HAAAACDXy9AD04EL+WX/Lxrz8xh1q9lNDco3cDoOAAAAANHo4SokJScpbH6YggoE6fW7Xnc6DgAAAACXDF26CaRn3LpxitwXqS9bf6lr8l/jdBwAAAAALszo4YrsPrFbg38arHtvuFdtb2nrdBwAAAAAqdDo4bJZa9VrQS9ZWX1w/wc8Mw8AAADwMFy6icv29davNW/7PL3Z7E1VKFLB6TgAAAAA0mBGD5flRPwJPbPwGdUoUUN9bu/jdBwAAAAA6WBGD5flxSUv6kDcAc1tN1e+efj2AQAAADwRM3rIsDX/rNGHkR/qmdrPqFbpWk7HAQAAAHABNHrIkDNJZxQ2P0ylC5XWiCYjnI4DAAAA4CK49g4ZMnr1aG0+uFlz281VwXwFnY4DAAAA4CKY0cMl7Ty6U8OWDVPrm1vrwRsfdDoOAAAAgEug0cNFWWvVfX535fPNp3fvfdfpOAAAAAAygEs3cVHTNk3Tkj+X6P373lepgqWcjgMAAAAgA5jRwwUdPnlYz//wvG4vc7u6h3Z3Og4AAACADKLRwwX1+6Gfjscf1/gW45XH8K0CAAAA5BT89I50/fTnT/ps42d6od4LqhZczek4AAAAAC4DjR7cxCfGq/v87rr+muv1csOXnY4DAAAA4DJxMxa4Gbl8pHYc3aHFHRcrv19+p+MAAAAAuEzM6OE8Ww5u0WurXlPH6h1113V3OR0HAAAAwBWg0cM5yTZZYfPDVDhfYb1191tOxwEAAABwhbh0E+dMiJqg1f+s1qcPfapiAcWcjgMAAADgCjGjB0nS/pj9GvDjADWp0ESdb+3sdBwAAAAAV4FGD5KkZxc9q/jEeH3U4iMZY5yOAwAAAOAq0OhB323/TrN+m6WXGr6kykUrOx0HAAAAwFWi0cvlYhNi9fSCp1WlWBX1r9/f6TgAAAAAMgE3Y8nlhi4dqt0ndmtFlxXK65PX6TgAAAAAMgEzerlY1L4ovbP2HT0V8pTuKHeH03EAAAAAZBIavVwqMTlRYfPDVDyguF676zWn4wAAAADIRFy6mUu9t/Y9bdi/QTMemaEi/kWcjgMAAAAgEzGjlwv9ffxvvbz0Zd1X6T49WuVRp+MAAAAAyGQ0ermMtVY9F/SUldUH933AM/MAAAAAL8Slm7nM7N9m67sd3+mtu99S+SLlnY4DAAAAIAswo5eLHI8/rt6LeqtmyZrqXae303EAAAAAZBFm9HKRQT8O0sG4g5rffr588/BbDwAAAHgrZvRyiVW7V+mjqI/0bJ1nFVIqxOk4AAAAALIQjV4ukJCUoLD5YSpXuJyGNxnudBwAAAAAWYzr93KBN1e9qd8O/aZ57ecpMG+g03EAAAAAZDFm9LzcjiM7NGL5CD1a5VG1qNzC6TgAAAAAsgGNnhez1uqp+U/J39dfY5uPdToOAAAAgGzCpZtebMrGKVr611J9eP+HKlmwpNNxAAAAAGQTZvS81OGTh9X3h76qV7aewkLCnI4DAAAAIBvR6Hmpvj/01X+n/9P4FuOVx/DbDAAAAOQmdABe6MddP2rKxinqX7+/bil+i9NxAAAAAGQzGj0vc+rMKXWf3103XHuDBjcY7HQcAAAAAA7gZixe5pXlr+iPY3/ox44/Kr9ffqfjAAAAAHBAhmb0jDHNjTHbjDE7jTED01lf3hizxBizyRgTYYwpk2rdG8aYLcaYrcaYd40xxrU8xBjzq2uf55bjym0+uFlvrH5DnW/trKbXNXU6DgAAAACHXLLRM8b4SHpf0r2Sqkhqb4ypkmbYaElTrLXVJQ2X9Kpr23qS6kuqLqmqpFqSGrm2+VBSmKRKrq/mV3syuVmyTVbYvDAVzldYo+8e7XQcAAAAAA7KyIxebUk7rbW7rLUJkqZLeijNmCqSlrheL0213kryl5RXUj5JfpIOGGNKSipkrV1jrbWSpkh6+KrOJJf7OPJjrdmzRm/f87aCCgQ5HQcAAACAgzLS6JWW9E+q93tcy1LbKKm163VLSQWNMUWttWuU0vjtd319b63d6tp+zyX2iQzaF7NPA5cMVNOKTdWxeken4wAAAABwmEmZULvIAGMelXSPtbar631HSbWttc+kGlNK0jhJFSUtV0rTd4ukYpLGSmrrGrpY0gBJpyS9aq29y7V9A0n9rbUPpHP8MKVc4qng4OCQ6dOnX/HJZpXY2FgFBgY6dvzwLeFac3SNJoVOUun8ntEvO10TT0RN3FGT9FEXd9TEHTVxR03cURN31CR91MWdp9akSZMmUdba0EuNy8hdN/dIKpvqfRlJ+1IPsNbuk9RKkowxgZJaW2tPuJq0n621sa51CyXdLmmqaz8X3GeqfY+XNF6SQkNDbePGjTMQOXtFRETIqVzzts3TsmXLNPLOkerQoIMjGdLjZE08FTVxR03SR13cURN31MQdNXFHTdxRk/RRF3c5vSYZuXRzvaRKxpiKxpi8ktpJ+jb1AGNMkDHm7L4GSZrker1bUiNjjK8xxk8pN2LZaq3dLynGGHO7626bnSTNzYTzyVViE2LVc0FP3VLsFvWr18/pOAAAAAA8xCUbPWttoqRekr6XtFXSTGvtFmPMcGPMg65hjSVtM8ZslxQsaaRr+WxJf0j6VSmf49torZ3nWtdD0kRJO11jFmbKGeUiL//0sv757x+Nf2C88vrkdToOAAAAAA+RoQemW2sXSFqQZtmQVK9nK6WpS7tdkqSnLrDPSKU8cgFXIHJfpN5d9656hPZQvbL1nI4DAAAAwINk6IHp8CyJyYnqNq+bggOC9WrTV52OAwAAAMDDZGhGD55l7M9jFf1vtGY9OkuF/Qs7HQcAAACAh2FGL4f56/hfGhIxRC0qt1Drm1tfegMAAAAAuQ6NXg5irdXT3z0tI6P373tfKTcsBQAAAIDzcelmDjJzy0wt3LlQY+4Zo3KFyzkdBwAAAICHYkYvhzh26pieXfSsQkqG6JnazzgdBwAAAIAHY0Yvhxj440AdOnlICzoskE8eH6fjAAAAAPBgzOjlACt3r9T4DeP13O3PqWbJmk7HAQAAAODhaPQ83OnE0wqbF6byhctrWONhTscBAAAAkANw6aaHe2PVG9p6eKu+e+w7BeQNcDoOAAAAgByAGT0Ptv3Ido1cMVJtbmmj+yrd53QcAAAAADkEjZ6HstbqqflPyd/XX2Obj3U6DgAAAIAchEs3PdTk6MmK+CtCH7f4WCUCSzgdBwAAAEAOwoyeBzoUd0j9FvdT/bL11bVmV6fjAAAAAMhhaPQ80PM/PK+Y0zEa/8B45TH8FgEAAAC4PHQRHmbxH4s1bdM0DbxjoKoUq+J0HAAAAAA5EI2eBzl55qS6f9ddlYtW1osNXnQ6DgAAAIAcipuxeJARy0Zo17Fd+qnTT/L39Xc6DgAAAIAcihk9D7HpwCaNXjNaT9R4Qk0qNnE6DgAAAIAcjEbPAyQlJylsXpiK+BfR6GajnY4DAAAAIIfj0k0P8FHkR1q7d62mtpyqogWKOh0HAAAAQA7HjJ7D9v63V4OWDFKz65qpQ7UOTscBAAAA4AVo9BzWe1FvnUk+ow/v/1DGGKfjAAAAAPACXLrpoLm/z9XXW7/Wq01f1fXXXu90HAAAAABeghk9h8ScjlGvhb1UrXg19a3b1+k4AAAAALwIM3oOeemnl7T3v72a9egs+fn4OR0HAAAAgBdhRs8B6/au03vr3lOP0B66vcztTscBAAAA4GVo9LLZmaQzCpsXppIFS2pU01FOxwEAAADghbh0M5u98/M72nhgo75q85UK+xd2Og4AAAAAL8SMXjb689ifGhoxVA/e+KBa3tTS6TgAAAAAvBSNXjax1urpBU/LJ4+Pxt07jmfmAQAAAMgyXLqZTaZvnq5FOxdpbPOxKlu4rNNxAAAAAHgxZvSywdFTR9Xn+z6qVaqWetbq6XQcAAAAAF6OGb1sMGDxAB05eUTfP/69fPL4OB0HAAAAgJdjRi+LLf97uSb+MlHP3f6capSo4XQcAAAAALkAjV4WOp14WmHzwlShSAWFNw53Og4AAACAXIJLN7PQaytf07Yj27Sww0IF5A1wOg4AAACAXIIZvSzy++HfNWrlKLWr2k7Nb2judBwAAAAAuUiOn9E7c+aM9uzZo/j4eMcyFC5cWFu3bj333srqQOwBzbtrnkoVLHXeutwibU1yAn9/f5UpU0Z+fn5ORwEAAACuSo5v9Pbs2aOCBQuqQoUKjj2EPCYmRgULFjz3/lDcIZ08cVLlC5dXsYBijmRyWtqaeDprrY4cOaI9e/aoYsWKTscBAAAArkqOv3QzPj5eRYsWdazJS+tM0hnt+W+PAvMGKqhAkNNxkEHGGBUtWtTRmWEAAAAgs+T4Rk+SxzR5kvTPf/8o2SarfOHyHpULl8bvFwAAALyFVzR6nuJE/AkdPXVUJQJLKL9ffqfjAAAAAMilaPQywYEDB9S2bVtVvamq2jZpq67tumr79u1Zesy//vpLZcqUUXJy8nnLa9SooXXr1l1wu8mTJ6tXr16SpI8++khTpkxJd99Vq1a95PG/+OKLc+8jIyPVu3fvyzmFC5o0aZKqVaum6tWrq2rVqpo7d26m7BcAAADILXL8zVicZq3VY489ppbtW+qFMS/oxqI36o+tf+jAgQOqXLnyuXFJSUny8fHJtONWqFBBZcuW1YoVK9SoUSNJ0u+//66YmBjVrl07Q/vo3r37FR//bKP32GOPSZJCQ0MVGhp6xfs7a8+ePRo5cqQ2bNigwoULKzY2VocOHbqqfWZ27QEAAABP51WNXp9FfRT9b3Sm7rNGiRp6p/k7F1y/dOlS+fj6qFnbZgoqEKSC+QqqRo0akqSIiAgNGzZMJUuWVHR0tH777Te9/fbbmjRpkiSpa9eu6tOnj+Li4tSmTRvt2bNHSUlJevnll9W2bVsNHDhQ3377rXx9fXX33Xdr9OjR5x27ffv2mj59+rlGb/r06Wrfvr0kad68eXrllVeUkJCgokWL6vPPP1dwcPB524eHhyswMFD9+vVTVFSUnnzySRUoUEB33HHHuTF//fWXOnbsqLi4OEnSuHHjVK9ePQ0cOFBbt25VjRo11LlzZ912220aPXq05s+fr6NHj6pTp07avXu3ChQooPHjx6t69eoKDw/X7t27tWvXLu3evVt9+vRxmwU8ePCgChYsqMDAQElSYGDgudc7d+5U9+7ddejQIfn4+GjWrFm67rrr1L9/fy1cuFDGGL300ktq27ZturWfNm2a3n33XSUkJKhOnTr64IMPaAABAADglbyq0XPCr7/+qhuq3iDfPL4qU6iM2/p169Zp8+bNqlixoqKiovTpp59q7dq1staqTp06atSokXbt2qVSpUrpu+++kySdOHFCR48e1TfffKPff/9dxhgdP37cbd9t2rTRbbfdpvfee0++vr6aMWOGZs2aJUm644479PPPP8sYo4kTJ+qNN97QW2+9dcHz6NKli9577z01atRIL7zwwrnlxYsX1+LFi+Xv768dO3aoffv2ioyM1GuvvXausZNSmtqzhg4dqurVq2v+/Pn66aef1KlTJ0VHpzTgv//+u5YuXaqYmBjdeOON6tGjx3nPrbv11lsVHBysihUrqmnTpmrVqpUeeOABSVKHDh00cOBAtWzZUvHx8UpOTtbXX3+t6Ohobdy4UYcPH1atWrXUsGFDt9pv3bpVM2bM0KpVq+Tn56enn35an3/+uTp16pSh32cAAAAgJ8lQo2eMaS5prCQfSROtta+lWV9e0iRJxSQdlfS4tXaPMaaJpDGpht4kqZ21do4xZrKkRpJOuNY9Ya29qum4i828ZZXYhFgl2SSVLVRWvnncy1m7du1zz2VbuXKlWrZsqYCAAElSq1attGLFCjVv3lz9+vXTgAED1KJFCzVo0ECJiYny9/dX165ddf/996tFixZu+y5RooRuueUWLVmyRMHBwfLz8zv32bo9e/aobdu22r9/vxISEi76bLgTJ07o+PHj52YGO3bsqIULF0pKeSB9r169FB0dLR8fnwx99nDlypX67LPPJEl33nmnjhw5ohMnUn6b77//fuXLl0/58uVT8eLFdeDAAZUp8/8Nso+PjxYtWqT169dryZIleu655xQVFaW+fftq7969atmypaSUh5ufPVb79u3l4+Oj4OBgNWrUSOvXr1ehQoXOq/2SJUsUFRWlWrVqSZJOnTql4sWLX/JcAAAAgJzokjdjMcb4SHpf0r2Sqkhqb4ypkmbYaElTrLXVJQ2X9KokWWuXWmtrWGtrSLpT0klJP6Ta7oWz66+2yXNCsk1WUIUgbd+8XdfmvzbdMWebOinl83zpqVy5sqKiolStWjUNGjRIw4cPl6+vr9atW6fWrVtrzpw5at68ebrbnr18M/Vlm5L0zDPPqFevXvr111/18ccfX/T5cNbaCz5aYMyYMQoODtbGjRsVGRmphISEC+7nYud5dv/58uU7t8zHx0eJiYnpjq1du7YGDRqk6dOn66uvvrpg7S60XHKvfefOnRUdHa3o6Ght27ZN4eHhlzwXAAAAICfKyF03a0vaaa3dZa1NkDRd0kNpxlSRtMT1emk66yXpEUkLrbUnrzSsp8lj8qjTw51kz1hNnDjx3PL169dr2bJlbuMbNmyoOXPm6OTJk4qLi9M333yjBg0aaN++fSpQoIAef/xx9evXTxs2bFBsbKxOnDih++67T++88865Sx/Tat26tRYsWKAZM2aoXbt255afOHFCpUuXlqRzs2sXUqRIERUuXFgrV66UJH3++efn7adkyZLKkyePpk6dqqSkJElSwYIFFRMTk+7+GjZsqJkzZ0pKuaQzKChIhQoVumiGs/bt26cNGzacex8dHa3y5curUKFCKlOmjObMmSNJOn36tE6ePKmGDRtqxowZSkpK0qFDh7R8+fJ0b0bTtGlTzZ49WwcPHpQkHT16VH///XeGMgEAAAA5TUYu3Swt6Z9U7/dIqpNmzEZJrZVyeWdLSQWNMUWttUdSjWkn6e002400xgxRSpM40Fp7Ou3BjTFhksIkKTg4+LzPgklS4cKFL9hwZJdpU6dp8ODBGjVqlPz9/VWuXDm99tpr2r9/vxITE8/lq1Spktq3b3/u7pSdOnXSDTfcoB9//FEvv/yy8uTJI19fX40ZM0b79+9Xu3btdPr0aVlrNWrUqHTP08fHR6GhoTp48KCCgoLOjRkwYIAeeeQRlSxZUrVq1VJSUpJiYmIUHx+vhIQExcTE6PTp0/Lz81NMTIzGjRunHj16KH/+/GratKmSk5MVExOjTp06qWPHjpo+fboaNmyogIAAxcTEqGLFijLGqFq1anrsscd06623njvXvn37qkePHqpatary58+vDz74wO14kpScnKzY2NjzzuvYsWN67rnntH//fvn7+ysoKEhjxoxRTEyMPvzwQ/Xp00cvvfSS/Pz89Nlnn+muu+7SsmXLVK1aNRljNGzYMAUEBOjkyZPn1b5s2bIaPHiw7rrrLiUnJ8vPz0+jR4/WtdeePxMbHx/v9j2WWWJjY7Ns3zkVNUkfdXFHTdxRE3fUxB01cUdN0kdd3OX0mpiLXfomScaYRyXdY63t6nrfUVJta+0zqcaUkjROUkVJy5XS9N1irT3hWl9S0iZJpay1Z1It+1dSXknjJf1hrR1+sSyhoaE2MjLyvGVbt27VzTffnOETzgoxMTEqWLCgoxk8TU6tSVZ+P0VERKhx48ZZsu+cipqkj7q4oybuqIk7auKOmrijJumjLu48tSbGmChr7SWfa5aRGb09ksqmel9G0r7UA6y1+yS1ch04UFLrs02eSxtJ35xt8lzb7He9PG2M+VRSvwxkAQAAAABcQkY+o7deUiVjTEVjTF6lXIL5beoBxpggY8zZfQ1Syh04U2sv6cs025R0/WokPSxp8+XHBwAAAACkdclGz1qbKKmXpO8lbZU001q7xRgz3BjzoGtYY0nbjDHbJQVLGnl2e2NMBaXMCKa9O8nnxphfJf0qKUjSK1d6Epe6/BTICL6PAAAA4C0y9Bw9a+0CSQvSLBuS6vVsSbMvsO1fSrmhS9rld15O0Avx9/fXkSNHVLRo0Qs+IgC4FGutjhw5cu75fAAAAEBOlqFGz5OVKVNGe/bs0aFDhxzLEB8fT4OQRk6sib+//3kPbwcAAAByqhzf6Pn5+alixYqOZoiIiNBtt93maAZPQ00AAAAA52TkZiwAAAAAgByERg8AAAAAvAyNHgAAAAB4GZOTbilvjDkk6W+nc6QjSNJhp0N4GGrijpq4oybpoy7uqIk7auKOmrijJu6oSfqoiztPrUl5a22xSw3KUY2epzLGRFprQ53O4UmoiTtq4o6apI+6uKMm7qiJO2rijpq4oybpoy7ucnpNuHQTAAAAALwMjR4AAAAAeBkavcwx3ukAHoiauKMm7qhJ+qiLO2rijpq4oybuqIk7apI+6uIuR9eEz+gBAAAAgJdhRg8AAAAAvAyNHgAAAAB4GRq9q2CMCTDG+Didw9NQFwAAnMe/x+6oCXITPqN3GYwxeSS1k9RBUi1JpyXlk3RI0gJJ4621O5xL6AzqcmHGmFBJDSSVknRK0mZJP1prjzoazEHU5HzGmDJK+fOTtibfSVporU12MJ4jqIk7apI+6nI+/j12R00uzhhzjf7/z85fue3PTHq8qSY0epfBGLNM0o+S5krafPY33hhzraQmkh6T9I21dppzKbMfdXFnjHlCUm9Jf0qKknRQkr+kypLqK+UHkZettbudypjdqIk7Y8ynkkpLmi8pUufXpImkEEkDrbXLHQuZzaiJO2qSPurijn+P3VETd8aYwpJ6SmovKa9Sml5/ScGSfpb0gbV2qXMJs5+31oRG7zIYY/ystWeudoy3oS7ujDE9JU2y1p66wPoakopaa5dkbzLnUBN3xpiq1trNF1mfV1I5a+3ObIzlKGrijpqkj7q4499jd9TEnTFmsaQpkuZZa4+nWRciqaOkX621nziRzwneWhMaPQAAAADwMr5OB8hJjDF/SrKSDllr6zidx1NQF3fGmCGul7HW2rcdDeMhqIk7Y8xSpfzZOWqtfcTpPJ6AmrijJumjLu7499gdNXFnjCnneplkrd3raBgP4a01YUYPyALGmM6ul6estTMdDeMhqIk7Y0x518ska+0eR8N4CGrijpqkj7oAV8b1nySSdIT/JEnhrTWh0cskxpibrLW/O53DSeld426MCbLWHnYqEwAA4OcUfkZBbsRz9DLPD04HcIoxpokxZo+kfcaYH4wxFVKtzrV1uRBjzHinMzjBGONjjHnKGDPCGFM/zbqXnMrlqYwxvzqdwQnGmLLGmOnGmBXGmBeNMX6p1s1xMpsnyq3fJxLfK1cgV/57zM8ol8cY08zpDE4xxhQyxlyfzvLqTuTJDHxG7zIYY9690CpJRbIzi4d5Q9I91totxphHJC025v/au/dYy8r6jOPfpwwjF2EQLJeWQimlxtbKxThMbCXAlBSsCBhQG+kIJVJrSmOttpRgxEaptReJIpdEyqASJAjqBEpBBAcaHG4DqOUiKbRYBRWjXAoUHJ7+sdaBM/vd+8zZzLDfddZ+PsnJ2bPWOvv8zpO1Z6/fftd6l/7I9hqabKZOO23z0FXAmyZZS4ecC2wF3Ax8StJq2+9v170V+Gi1yiqR9NZRq4CdJ1lLh/wLcCnNdNYnAKslHW77J8Duc/5kT2U/GSn7yoAcpwyVY5TxnAfstsGtekbS24AzgB+1HxodZ/uWdvVKYL9atW2MNHrjOR74S5qbbQ76wwnX0iWLbf8HgO0vSbobuEzSyTQXQE+jHwP/zfpvIm7/vWOViupbavu1AJLOBM6SdBnNa2da32wvBi5k+OtkiwnX0hW/aPuc9vFJko4Frpf0Fqb3/5PsJ8NlXynlOKWUY5QBklaNWgXsMMlaOuQU4HW2H5K0FPi8pFNsX8YCPkZJozeeW2hutnnj4ApJp02+nM54VtLOth8GaD81W05zE9tiCHxK3A8sH3bzb0nfq1BPFyyeeWD758CJ7Uyc1wIvr1ZVXd8C/nHYvcAk/V6Ferpgc0lb2H4awPYXJD0MXAVsXbe0arKfDJd9pZTjlFKOUUpvBI4FnhhYLmDp5MvphM1sPwRg+2ZJBwGXS9qVBfyBQK7RG8/RwB3DVtjeY8K1dMnJwE6zF7QzoB0IfLxGQR1wBvCKEes+MclCOuRWSYfOXmD7b4HzgV+tUlF97wMeG7HuqEkW0iGfBdabAt32NcAxwMibY/dc9pPhsq+UcpxSyjFKaQ3wpO3VA1/fAO6tXFstj8++Pq9t+g4EjgB+q1ZRGyuzbkZERERExNSStDdN83vfwPLNgbfZvrBOZRsnjd4Y2tnNhgUmwDPXH02b5FKaY/IEANpzvqdKMilJ+jRznBJi+88nWE4nzDGZBDC1mWQ/GSL7Sinvx6VkEtMs1+iN5821C+io5FI6fI51BqauqSGZDHNr7QI66LbaBXRQ9pPhsq+U8n5cSiYDJD3O3M3vthMuqbq+ZpIRvYiIiIiIiJ7JiN4YJD1A0+3/2Pb+G9p+WiSXkqQV7cOnbF9StZiOSCYlSefTvHYetf0XtevpgmRSSibDJZdS3o9LySSmWTDntzIAAAooSURBVBq9MUzxjFVzSi5DzWTyeNUquiWZlFa235+pWUTHrGy/J5MXrGy/J5P1rWy/J5dW3o9LyaSU5rfU10xy6mZERERERETP5D56ERERERERPZNGLyIiIiIiomfS6EVERERERPRMGr1NQNI1kq6UlHu1zJJcSpKOkNSbi3w3hWRSknS6pL+WtEPtWroimZSSyXDJpZT341IyiWmQRm/TWAGcCuxeu5COSS6l/YFTJV1Zu5AOSSalm4GfA5+sXUiHJJNSMhkuuZTyflxKJgMk3d1+/VntWrpioWeSWTcjIiIiekbS9oBt/7R2LV2RTDasHQlfZvuK2rV0xULOJI3eJiLpStuH1a6ja5JLSdIhtr9Wu44umdZMJC0CTgCOAn6J5h4+PwC+Cpxn+9mK5VWRTErJZLjkUpK0G/AJYDnwM0DAtsC1wMm2/6tedXUkk9Ek7QT8Mu1rx/YPK5dUXd8ySaM3Bkn7jVoFXG57l0nW0xXJZTySHrS9W+06umRaM5F0Ec2BxwXA/7SLdwXeBWxv++21aqslmZSSyXDJpSTpm8AZwJdsr2uXbQYcA7zP9rKa9dWQTEqS9gHOAZYA328X70rzenqv7bW1aqulr5mk0RuDpHXAapoGZtAy21tOuKROSC4lSatGrQIOtr31JOvpgmRSknSv7VeNWPdd278x6ZpqSyalZDJccilJus/2XuOu67NkUpJ0B/Antm8aWL4MONf23nUqq6evmSyqXcACczfNTnDf4ApJ36tQT1ckl9IbgWOBJwaWC1g6+XI6IZmUfirpGOBS288BSPoFmk+ap/UakmRSSibDJZfSbZLOohnlnHn//RWaUc7bq1VVVzIpbT3Y0ADYXiNp6j50bfUykzR64zmN0TOVnjTBOrrmNJLLoDXAk7ZXD66QdG+FerogmZTeAfw9cJakmQPT7YDr2nXTKJmUBjMRzelF05wJJJdhVtBct/gRmuuMRHNa6yrgvIp11ZRMSldKugL4HOs3vyuAf6tWVV29zCSnbkZEdEA7q5dsP1K7lq5IJqVkMlxyiRiPpMOAIxhofm3/a9XCKupjJmn0NhFJ+y3UCzVfStOaiyR5Ay+u+WzTJ8lkPNM6E+lckklD0h7AvsBdtu+pXU9XJJf1ZiI9klkzBzLdM5Emk5hauWH6pvOntQvoqGnN5TpJJ7XTOj9P0mJJB0u6gOb6gGmSTMYzracUzWUqM5H0lVmPj6CZFv5wYJWk42rVVVtyGerzwD40pym+CfiD9vHewBcq1lVTMhkg6bWzHm8u6VRJqySdLmmrmrXV0tdMMqIX8RKQtAXwx8A7gT1opufdAtgMuBr4jO076lU4ecmklJlIS8mkJOl22/u2j28E3mn7AUmvBL6+UGeD21jJpZSZSEvJpCRpre392sf/BOwAnE8z6rmD7RU166uhr5lkMpYxSVoCHMr6w/9X2f5Z1cIqSy7rs/00cBbNJAGbA68EnprWPCCZjJCZSEvJpDT7E9lFth8AsP2IpOcq1dQFyaWUmUhLyaQ0+3ZYy4HX235W0vXAnZVqqq2XmaTRG4OkFcCHaUYfZm6meBBwuqSP2P5cteIqSi5za8//f6h2HV2STJ6XmUhLyaS0t6THaA5EXiZpZ9sPS1pMMyI+rZJLKbPWlpJJaYmko2gu4XrZzHWKti1pWk/162UmOXVzDO1Bxv6DIxCSXgHcNI3D/5BcIiJqkLQd8Grb36xdS5ckl0ZmIi0lk4ak8wcWnWz7h5J2Bi60vbxGXTX1NZM0emOQ9F2aodxHB5YvAW61vVedyupKLhEvTmYiLSWTUjIZLrmMJ7PWlpJJ9F1m3RzPx4C1ks6WdEr7dQ6wtl03rZJLxIuTmUhLyaSUTIZLLuOZyllrNyCZDJB0SO0aumYhZ5IRvTG1pyP+PuvfTPEq29N6QS+QXCJejMxEWkompWQyXHIpZdbaUjIZj6QHbe+24S2nx0LOJI3eGHKayHDJJWLjZSbSUjIpJZPhkkujnWxk1Ky1F9veafJV1ZVMSml+S33NJLNujuc6SZcCX7X94MzCdoav36U5ReQ6YGWd8qpJLhEbKTORlpJJKZkMl1yel1lrS8mklNvYlHqZSRq98RxKc5rIRZJmThPZkuZax6uBT07baSKt5BIREVGZ7cPmWHfAJGvpimQyVJrfUi8zyambL1JOExkuuURERNSRSylKySSmWWbdfJFsP2v7oTQz60suERER1WQm0lIyGSBJm2KbPulrJhnRi4iIiOiBzERaSiYlSd8ANji3gu2VVQqsoK+ZpNGLiIiI6JlcSlFKJo00v6W+ZpJGLyIiIiJiCqX5LfUpkzR6ERERERERPZPJWCIiIiIiInomjV5ERERERETPpNGLiIgFQdI6SXdI+o6kSyRttYmf/zhJZ7aPj5T0m5vy+efx+1dKOnrEug9Iuqf92++UtGKStUVExMKTRi8iIhaKp2zvY/s1wDPAe17C33UkMNFGbxRJ7wEOAZa2f/sBwIK7n1NERExWGr2IiFiIbgB+HUDSsZJubkf7zpW0Wbv8CUkfa0fA1kjaqV1+uKSbJN0u6ZqZ5TMkvQF4C/AP7XPuKWntrPV7SbptsCBJ75Z0S/v7Lp0ZcWxH6j4l6UZJ98+M2qlxpqS7JF0B7Djibz0FeK/txwBsP2r7go2LLyIi+i6NXkRELCiSFgGHAd+W9Grg7cDv2N4HWEdzHySArYE1tvcGrgfe3S7/d2CZ7X2BLwJ/Nfv5bd8IrAI+2I4g/ifwqKR92k2OB1YOKe0y269vf9/dwAmz1u1Cc9PdNwMfb5cdBbwK+O22tjcM+Vu3AbZpa4iIiJi3RbULiIiImKctJc3csPYG4DzgROB1wC2SALYEftRu8wxwefv4NprTHwF2BS6WtAuwGHhgHr/7s8Dxkt5P01guHbLNayR9FNgOeDlw1ax1X7H9HHDXrBHEA4CLbK8DfiDp2iHPKSD3QYqIiLGl0YuIiIXiqXbU7nlqursLbP/NkO2f9Qs3i13HC+95nwb+2fYqSQcCp83jd18KfBi4FrjN9k+GbLMSONL2nZKOAw6cte7/Zpc96/GcTZztxyT9r6Rfs33/POqMiIgAcupmREQsbF8Hjpa0I4Ck7SXtvoGfWQJ8v338rhHbPA5sM/MP20/TjNCdDZw/4me2AR6StDkvnD46l+uBd0jarB1dPGjEdn8HfEbStgCStpV04jyePyIiplgavYiIWLBs3wWcClwt6VvA12iuh5vLacAlkm4AHhmxzReBD7YTtuzZLruQZgTu6hE/8yHgpraGe+ZR/peB+4Bv0zSQq0dsdzZwHc3pqd9pt3tyHs8fERFTTC+c1RIRERGjSPoAsMT2h2rXEhERsSG5Ri8iImIDJH0Z2BM4uHYtERER85ERvYiIiIiIiJ7JNXoRERERERE9k0YvIiIiIiKiZ9LoRURERERE9EwavYiIiIiIiJ5JoxcREREREdEz/w/LNFMsNw3bHAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig ,ax= plt.subplots(figsize = (15,5))\n",
    "plt.plot(range(len(index)), score, c = 'g', label = 'Cross Validation Score')\n",
    "plt.legend(loc = 3)\n",
    "plt.grid(True)\n",
    "plt.xticks(range(len(index)), index, rotation=90)\n",
    "plt.xlabel(r'Penalty and C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(penalty='l2', C=1, random_state=0)\n",
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 1.0\n",
      "KNeighborsClassifier 1.0\n",
      "SVC 1.0\n",
      "VotingClassifier 1.0\n"
     ]
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(estimators=[('lr', logreg), ('knn', knn), ('svc', svc_rbf)], voting='hard')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (logreg, knn, svc_rbf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier - Soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 1.0\n",
      "KNeighborsClassifier 1.0\n",
      "SVC 1.0\n",
      "VotingClassifier 1.0\n"
     ]
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(estimators=[('lr', logreg), ('knn', knn), ('svc', svc_rbf)], voting='soft')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (logreg, knn, svc_rbf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from  sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'max_depth': 1}\n",
      "Best score:  0.9975124378109452\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dtree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "#model param\n",
    "grid_param = {'max_depth':[1,2,3,4,5,6]}\n",
    "\n",
    "#grid model\n",
    "grid_search = GridSearchCV(dtree, grid_param, cv = 5, n_jobs  = -1)\n",
    "\n",
    "#train grid model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Best params: ', grid_search.best_params_)\n",
    "print('Best score: ', grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.00\n",
      "Test score: 1.00\n",
      "Prediction Accuracy: 1.000\n",
      "Confusion matrix:\n",
      "[[63  0]\n",
      " [ 0 72]]\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier(max_depth=1,random_state=0)\n",
    "bag= BaggingClassifier(dtree, n_estimators=500,max_samples=100, bootstrap=True, random_state=0)\n",
    "bag.fit(X_train, y_train)\n",
    "y_pred = bag.predict(X_test)\n",
    "print('Train score: {:.2f}'.format(bag.score(X_train, y_train)))\n",
    "print('Test score: {:.2f}'.format(bag.score(X_test, y_test)))\n",
    "print('Prediction Accuracy: {:.3f}'.format(accuracy_score(y_test, y_pred)))\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC Kernel Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'C': 1}\n",
      "Best score:  1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svc_lin = SVC(kernel='linear', C=x)\n",
    "\n",
    "#model param\n",
    "grid_param = {'C':[1,10,100,200,300]}\n",
    "\n",
    "#grid model\n",
    "grid_search = GridSearchCV(svc_lin, grid_param, cv = 5, n_jobs  = -1)\n",
    "\n",
    "#train grid model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Best params: ', grid_search.best_params_)\n",
    "print('Best score: ', grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.00\n",
      "Test score: 1.00\n",
      "Prediction Accuracy: 1.000\n",
      "Confusion matrix:\n",
      "[[63  0]\n",
      " [ 0 72]]\n"
     ]
    }
   ],
   "source": [
    "svc_lin = SVC(kernel='linear', C=1)\n",
    "bag= BaggingClassifier(svc_lin, n_estimators=500,max_samples=100, bootstrap=True, random_state=0)\n",
    "bag.fit(X_train, y_train)\n",
    "y_pred = bag.predict(X_test)\n",
    "print('Train score: {:.2f}'.format(bag.score(X_train, y_train)))\n",
    "print('Test score: {:.2f}'.format(bag.score(X_test, y_test)))\n",
    "print('Prediction Accuracy: {:.3f}'.format(accuracy_score(y_test, y_pred)))\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameter: 1 - From previous GridSearchCV in Hard Voting Classifier Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: 0.9975124378109452\n",
      "Test scores: 1.0\n",
      "Confusion matrix:\n",
      "[[63  0]\n",
      " [ 0 72]]\n",
      "Prediction Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(1)\n",
    "bag= BaggingClassifier(knn, n_estimators=500,max_samples=100, bootstrap=False, random_state=0)\n",
    "bag.fit(X_train, y_train)\n",
    "print(\"Train scores: {}\".format(bag.score(X_train, y_train)))\n",
    "print(\"Test scores: {}\".format(bag.score(X_test, y_test)))\n",
    "pred = bag.predict(X_test)\n",
    "\n",
    "confusion = confusion_matrix(y_test, pred)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))\n",
    "\n",
    "print('Prediction Accuracy: {:.3f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameter: 1 - From previous GridSearchCV in Hard Voting Classifier Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.00\n",
      "Test score: 1.00\n",
      "Prediction Accuracy: 1.000\n",
      "Confusion matrix:\n",
      "[[63  0]\n",
      " [ 0 72]]\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier(max_depth=1, random_state=0)\n",
    "bag= BaggingClassifier(dtree, n_estimators=500,max_samples=100, bootstrap=False, random_state=0)\n",
    "bag.fit(X_train, y_train)\n",
    "y_pred = bag.predict(X_test)\n",
    "print('Train score: {:.2f}'.format(bag.score(X_train, y_train)))\n",
    "print('Test score: {:.2f}'.format(bag.score(X_test, y_test)))\n",
    "print('Prediction Accuracy: {:.3f}'.format(accuracy_score(y_test, y_pred)))\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameter: 1 - From previous GridSearchCV in Hard Voting Classifier Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.00\n",
      "Test score: 1.00\n",
      "Prediction Accuracy: 1.000\n",
      "Confusion matrix:\n",
      "[[63  0]\n",
      " [ 0 72]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5, random_state=0)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "scorestrain=np.mean(cross_val_score(ada_clf, X_train, y_train, cv=5))\n",
    "scorestest=np.mean(cross_val_score(ada_clf, X_test, y_test, cv=5))\n",
    "print('Train score: {:.2f}'.format(scorestrain))\n",
    "print('Test score: {:.2f}'.format(scorestest))\n",
    "y_pred = ada_clf.predict(X_test)\n",
    "print('Prediction Accuracy: {:.3f}'.format(accuracy_score(y_test, y_pred)))\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.00\n",
      "Test score: 1.00\n",
      "Prediction Accuracy: 1.000\n",
      "Confusion matrix:\n",
      "[[63  0]\n",
      " [ 0 72]]\n"
     ]
    }
   ],
   "source": [
    "svc=SVC(kernel='linear',C=10, probability=True)\n",
    "\n",
    "ada_clf=AdaBoostClassifier(base_estimator=svc,n_estimators=10,learning_rate=0.5, random_state=0, algorithm=\"SAMME.R\")\n",
    "ada_clf.fit(X_train,y_train)\n",
    "scorestrain=np.mean(cross_val_score(ada_clf, X_train, y_train, cv=5))\n",
    "scorestest=np.mean(cross_val_score(ada_clf, X_test, y_test, cv=5))\n",
    "print('Train score: {:.2f}'.format(scorestrain))\n",
    "print('Test score: {:.2f}'.format(scorestest))\n",
    "y_pred = ada_clf.predict(X_test)\n",
    "print('Prediction Accuracy: {:.3f}'.format(accuracy_score(y_test, y_pred)))\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 1}\n",
      "Best score:  0.9975124378109452\n"
     ]
    }
   ],
   "source": [
    "gbrt = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "#model param\n",
    "grid_param = {'learning_rate':[1,0.5,0.25,0.1,0.05], 'max_depth':[1,2,3,4,5], 'n_estimators':[1,5,10,20,30]}\n",
    "\n",
    "#grid model\n",
    "grid_search = GridSearchCV(gbrt, grid_param, cv = 5, n_jobs  = -1)\n",
    "\n",
    "#train grid model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Best params: ', grid_search.best_params_)\n",
    "print('Best score: ', grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.00\n",
      "Test score: 1.00\n",
      "Prediction Accuracy: 1.000\n",
      "Confusion matrix:\n",
      "[[63  0]\n",
      " [ 0 72]]\n"
     ]
    }
   ],
   "source": [
    "gbrt = GradientBoostingClassifier(max_depth=1, learning_rate=1, n_estimators=1, random_state=0)\n",
    "gbrt.fit(X_train,y_train)\n",
    "scorestrain=np.mean(cross_val_score(gbrt, X_train, y_train, cv=5))\n",
    "scorestest=np.mean(cross_val_score(gbrt, X_test, y_test, cv=5))\n",
    "print('Train score: {:.2f}'.format(scorestrain))\n",
    "print('Test score: {:.2f}'.format(scorestest))\n",
    "y_pred = gbrt.predict(X_test)\n",
    "print('Prediction Accuracy: {:.3f}'.format(accuracy_score(y_test, y_pred)))\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca=PCA(n_components=0.95)\n",
    "pca.fit(X_train)\n",
    "X_train_reduced=pca.transform(X_train)\n",
    "X_test_reduced=pca.transform(X_test)\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78535712, 0.16771047, 0.14880166, 0.12508276, 0.09578634,\n",
       "       0.07598451, 0.05887186, 0.03682949])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing results from the previous project file to check if PCA worsens or gives better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>PCA</th>\n",
       "      <th>CrossValTrain</th>\n",
       "      <th>CrossValTest</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.992593</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC_RBF</td>\n",
       "      <td>without</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC_Linear</td>\n",
       "      <td>without</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC_Poly</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>without</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model      PCA  CrossValTrain  CrossValTest  Accuracy\n",
       "0           LinearSVC  without       0.992500      1.000000       100\n",
       "1  LogisticRegression  without       0.992500      0.992593       100\n",
       "2                 KNN  without       0.992500      0.970370       100\n",
       "3             SVC_RBF  without       0.997512      1.000000       100\n",
       "4          SVC_Linear  without       1.000000      1.000000       100\n",
       "5            SVC_Poly  without       0.992537      1.000000       100\n",
       "6        DecisionTree  without       0.997512      1.000000       100"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv('ClassificationResults.csv')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result=pd.DataFrame(index=['TrainSc','TestSc','CrossValTr','CrossValTs','Accuracy'], columns=[\"Without PCA\",\"With PCA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinearSVC with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[63  0]\n",
      " [ 0 72]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>PCA</th>\n",
       "      <th>CrossValTrain</th>\n",
       "      <th>CrossValTest</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>with</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.992593</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC_RBF</td>\n",
       "      <td>without</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC_Linear</td>\n",
       "      <td>without</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC_Poly</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>without</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model      PCA  CrossValTrain  CrossValTest  Accuracy\n",
       "0           LinearSVC  without       0.992500      1.000000       100\n",
       "1           LinearSVC     with       0.992500      1.000000       100\n",
       "2  LogisticRegression  without       0.992500      0.992593       100\n",
       "3                 KNN  without       0.992500      0.970370       100\n",
       "4             SVC_RBF  without       0.997512      1.000000       100\n",
       "5          SVC_Linear  without       1.000000      1.000000       100\n",
       "6            SVC_Poly  without       0.992537      1.000000       100\n",
       "7        DecisionTree  without       0.997512      1.000000       100"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(random_state=0)\n",
    "clf.fit(X_train_reduced,y_train)\n",
    "\n",
    "scorestrain=(cross_val_score(clf, X_train_reduced, y_train,cv=3)).mean()\n",
    "scorestest=(cross_val_score(clf, X_test_reduced, y_test,cv=3)).mean()\n",
    "pred = clf.predict(X_test_reduced)\n",
    "Accuracy=statistics.mean(y_test==pred)*100\n",
    "\n",
    "confusion = confusion_matrix(y_test, pred)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))\n",
    "\n",
    "\n",
    "line = pd.DataFrame({'Model':\"LinearSVC\" , 'PCA': \"with\", 'CrossValTrain': scorestrain,'CrossValTest':scorestest,'Accuracy':Accuracy}, index=[0.5])\n",
    "results=results.append(line, ignore_index=False)\n",
    "results = results.sort_index().reset_index(drop=True)\n",
    "results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For LinearSVC, PCA gives exactly the same results in predicting risk. Both cases exhibit 100% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[63  0]\n",
      " [ 0 72]]\n"
     ]
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_test, pred)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression With/Without PCA (Best Parameters taken from previous project file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'C': 1, 'penalty': 'l1'}\n",
      "Best score:  0.9975124378109452\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "#model param\n",
    "grid_param = {'penalty':['l1','l2'], \n",
    "             'C': [0.1,1,10,50,100,150]}\n",
    "\n",
    "#grid model\n",
    "grid_search = GridSearchCV(logreg, grid_param, cv = 5, n_jobs  = -1)\n",
    "\n",
    "#train grid model\n",
    "grid_search.fit(X_train_reduced, y_train)\n",
    "\n",
    "print('Best params: ', grid_search.best_params_)\n",
    "print('Best score: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(penalty='l1', C=1, random_state=0)\n",
    "logreg.fit(X_train_reduced,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[63  0]\n",
      " [ 0 72]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>PCA</th>\n",
       "      <th>CrossValTrain</th>\n",
       "      <th>CrossValTest</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>with</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.992593</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.985185</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC_RBF</td>\n",
       "      <td>without</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC_Linear</td>\n",
       "      <td>without</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC_Poly</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>without</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model      PCA  CrossValTrain  CrossValTest  Accuracy\n",
       "0           LinearSVC  without       0.992500      1.000000       100\n",
       "1           LinearSVC     with       0.992500      1.000000       100\n",
       "2  LogisticRegression  without       0.992500      0.992593       100\n",
       "3  LogisticRegression     with       0.992500      0.985185       100\n",
       "4                 KNN  without       0.992500      0.970370       100\n",
       "5             SVC_RBF  without       0.997512      1.000000       100\n",
       "6          SVC_Linear  without       1.000000      1.000000       100\n",
       "7            SVC_Poly  without       0.992537      1.000000       100\n",
       "8        DecisionTree  without       0.997512      1.000000       100"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorestrain=(cross_val_score(logreg, X_train_reduced, y_train,cv=3)).mean()\n",
    "scorestest=(cross_val_score(logreg, X_test_reduced, y_test,cv=3)).mean()\n",
    "pred = logreg.predict(X_test_reduced)\n",
    "Accuracy=statistics.mean(y_test==pred)*100\n",
    "\n",
    "confusion = confusion_matrix(y_test, pred)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))\n",
    "\n",
    "line = pd.DataFrame({'Model':\"LogisticRegression\" , 'PCA': \"with\", 'CrossValTrain': scorestrain,'CrossValTest':scorestest,'Accuracy':Accuracy}, index=[2.5])\n",
    "results=results.append(line, ignore_index=False)\n",
    "results = results.sort_index().reset_index(drop=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For LogisticRegression, PCA gives slightly worse test score but results in same Accuracy (100%). It is clear that in this case, no matter how small, the models suffers from loss of variation(information) in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN:Best Parameter Search for Reduced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter grid:\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]}\n",
      "Best parameters: {'n_neighbors': 1}\n",
      "Best cross-validation score: 1.00\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_neighbors': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]}\n",
    "print(\"Parameter grid:\\n{}\".format(param_grid))\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, return_train_score=True)\n",
    "grid_search.fit(X_train_reduced, y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[63  0]\n",
      " [ 0 72]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>PCA</th>\n",
       "      <th>CrossValTrain</th>\n",
       "      <th>CrossValTest</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>with</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.992593</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.985185</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>with</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC_RBF</td>\n",
       "      <td>without</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC_Linear</td>\n",
       "      <td>without</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVC_Poly</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>without</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model      PCA  CrossValTrain  CrossValTest  Accuracy\n",
       "0           LinearSVC  without       0.992500      1.000000       100\n",
       "1           LinearSVC     with       0.992500      1.000000       100\n",
       "2  LogisticRegression  without       0.992500      0.992593       100\n",
       "3  LogisticRegression     with       0.992500      0.985185       100\n",
       "4                 KNN  without       0.992500      0.970370       100\n",
       "5                 KNN     with       0.997512      1.000000       100\n",
       "6             SVC_RBF  without       0.997512      1.000000       100\n",
       "7          SVC_Linear  without       1.000000      1.000000       100\n",
       "8            SVC_Poly  without       0.992537      1.000000       100\n",
       "9        DecisionTree  without       0.997512      1.000000       100"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(1)\n",
    "knn.fit(X_train_reduced, y_train)\n",
    "scorestrain=(cross_val_score(knn, X_train_reduced, y_train,cv=3)).mean()\n",
    "scorestest=(cross_val_score(knn, X_test_reduced, y_test,cv=3)).mean()\n",
    "pred = knn.predict(X_test_reduced)\n",
    "Accuracy=statistics.mean(y_test==pred)*100\n",
    "\n",
    "confusion = confusion_matrix(y_test, pred)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))\n",
    "\n",
    "line = pd.DataFrame({'Model':\"KNN\" , 'PCA': \"with\", 'CrossValTrain': scorestrain,'CrossValTest':scorestest,'Accuracy':Accuracy}, index=[4.5])\n",
    "results=results.append(line, ignore_index=False)\n",
    "results = results.sort_index().reset_index(drop=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For KNN, PCA gives slightly better testing and training score and results in same Accuracy (100%). This may be due to eliminating insignificant predictors in the dataset. The significant predictors in the PCA dataset are enough to classify the neigboring datapoints to either class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC RBF with best parameter search for Reduced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'C': 0.1, 'gamma': 5}\n",
      "Best score:  1.0\n"
     ]
    }
   ],
   "source": [
    "svc_rbf = SVC(kernel='rbf', random_state=0,probability=True)\n",
    "#model param\n",
    "grid_param = {'C':[0.01, 0.1, 1, 10, 100], \n",
    "             'gamma': [0.01, 0.1, 1, 5, 10, 100]}\n",
    "\n",
    "#grid model\n",
    "grid_search = GridSearchCV(svc_rbf, grid_param, cv = 5, n_jobs  = -1)\n",
    "\n",
    "#train grid model\n",
    "grid_search.fit(X_train_reduced, y_train)\n",
    "\n",
    "print('Best params: ', grid_search.best_params_)\n",
    "print('Best score: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[63  0]\n",
      " [ 0 72]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>PCA</th>\n",
       "      <th>CrossValTrain</th>\n",
       "      <th>CrossValTest</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>with</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.992593</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.985185</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>with</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC_RBF</td>\n",
       "      <td>without</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC_RBF</td>\n",
       "      <td>with</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVC_Linear</td>\n",
       "      <td>without</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVC_Poly</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>without</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model      PCA  CrossValTrain  CrossValTest  Accuracy\n",
       "0            LinearSVC  without       0.992500      1.000000       100\n",
       "1            LinearSVC     with       0.992500      1.000000       100\n",
       "2   LogisticRegression  without       0.992500      0.992593       100\n",
       "3   LogisticRegression     with       0.992500      0.985185       100\n",
       "4                  KNN  without       0.992500      0.970370       100\n",
       "5                  KNN     with       0.997512      1.000000       100\n",
       "6              SVC_RBF  without       0.997512      1.000000       100\n",
       "7              SVC_RBF     with       1.000000      1.000000       100\n",
       "8           SVC_Linear  without       1.000000      1.000000       100\n",
       "9             SVC_Poly  without       0.992537      1.000000       100\n",
       "10        DecisionTree  without       0.997512      1.000000       100"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_rbf = SVC(kernel='rbf', gamma=5,C=0.1)\n",
    "svc_rbf.fit(X_train_reduced,y_train)\n",
    "\n",
    "scorestrain=(cross_val_score(svc_rbf, X_train_reduced, y_train,cv=3)).mean()\n",
    "scorestest=(cross_val_score(svc_rbf, X_test_reduced, y_test,cv=3)).mean()\n",
    "pred = svc_rbf.predict(X_test_reduced)\n",
    "Accuracy=statistics.mean(y_test==pred)*100\n",
    "\n",
    "confusion = confusion_matrix(y_test, pred)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))\n",
    "\n",
    "line = pd.DataFrame({'Model':\"SVC_RBF\" , 'PCA': \"with\", 'CrossValTrain': scorestrain,'CrossValTest':scorestest,'Accuracy':Accuracy}, index=[6.5])\n",
    "results=results.append(line, ignore_index=False)\n",
    "results = results.sort_index().reset_index(drop=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For SVC RBF, PCA gives slightly better train score and results in same Accuracy (100%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC Linear With PCA Best Param search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'C': 1}\n",
      "Best score:  1.0\n"
     ]
    }
   ],
   "source": [
    "svc_lin = SVC(kernel='linear', random_state=0,probability=True)\n",
    "#model param\n",
    "grid_param = {'C':[1,10,100,200,300]}\n",
    "\n",
    "#grid model\n",
    "grid_search = GridSearchCV(svc_lin, grid_param, cv = 5, n_jobs  = -1)\n",
    "\n",
    "#train grid model\n",
    "grid_search.fit(X_train_reduced, y_train)\n",
    "\n",
    "print('Best params: ', grid_search.best_params_)\n",
    "print('Best score: ', grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[63  0]\n",
      " [ 0 72]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>PCA</th>\n",
       "      <th>CrossValTrain</th>\n",
       "      <th>CrossValTest</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>with</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.992593</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.985185</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>with</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC_RBF</td>\n",
       "      <td>without</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC_RBF</td>\n",
       "      <td>with</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVC_Linear</td>\n",
       "      <td>without</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVC_Linear</td>\n",
       "      <td>with</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVC_Poly</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>without</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model      PCA  CrossValTrain  CrossValTest  Accuracy\n",
       "0            LinearSVC  without       0.992500      1.000000       100\n",
       "1            LinearSVC     with       0.992500      1.000000       100\n",
       "2   LogisticRegression  without       0.992500      0.992593       100\n",
       "3   LogisticRegression     with       0.992500      0.985185       100\n",
       "4                  KNN  without       0.992500      0.970370       100\n",
       "5                  KNN     with       0.997512      1.000000       100\n",
       "6              SVC_RBF  without       0.997512      1.000000       100\n",
       "7              SVC_RBF     with       1.000000      1.000000       100\n",
       "8           SVC_Linear  without       1.000000      1.000000       100\n",
       "9           SVC_Linear     with       1.000000      1.000000       100\n",
       "10            SVC_Poly  without       0.992537      1.000000       100\n",
       "11        DecisionTree  without       0.997512      1.000000       100"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_lin = SVC(kernel='linear', C=1)\n",
    "svc_lin.fit(X_train_reduced,y_train)\n",
    "\n",
    "scorestrain=(cross_val_score(svc_lin, X_train_reduced, y_train,cv=3)).mean()\n",
    "scorestest=(cross_val_score(svc_lin, X_test_reduced, y_test,cv=3)).mean()\n",
    "pred = svc_lin.predict(X_test_reduced)\n",
    "Accuracy=statistics.mean(y_test==pred)*100\n",
    "\n",
    "confusion = confusion_matrix(y_test, pred)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))\n",
    "\n",
    "line = pd.DataFrame({'Model':\"SVC_Linear\" , 'PCA': \"with\", 'CrossValTrain': scorestrain,'CrossValTest':scorestest,'Accuracy':Accuracy}, index=[8.5])\n",
    "results=results.append(line, ignore_index=False)\n",
    "results = results.sort_index().reset_index(drop=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For SVC Linear, PCA gives excatly the same train, test score and results in same Accuracy (100%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC_POLY with PCA best parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'C': 10, 'degree': 1}\n",
      "Best score:  1.0\n"
     ]
    }
   ],
   "source": [
    "svc_poly = SVC(kernel='poly', random_state=0,probability=True)\n",
    "#model param\n",
    "grid_param = {'degree':[1,2,3,4],'C':[1,10,100,200,300]}\n",
    "\n",
    "#grid model\n",
    "grid_search = GridSearchCV(svc_poly, grid_param, cv = 5, n_jobs  = -1)\n",
    "\n",
    "#train grid model\n",
    "grid_search.fit(X_train_reduced, y_train)\n",
    "\n",
    "print('Best params: ', grid_search.best_params_)\n",
    "print('Best score: ', grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[63  0]\n",
      " [ 0 72]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>PCA</th>\n",
       "      <th>CrossValTrain</th>\n",
       "      <th>CrossValTest</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>with</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.992593</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.985185</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>with</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC_RBF</td>\n",
       "      <td>without</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC_RBF</td>\n",
       "      <td>with</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVC_Linear</td>\n",
       "      <td>without</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVC_Linear</td>\n",
       "      <td>with</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVC_Poly</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVC_Poly</td>\n",
       "      <td>with</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>without</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model      PCA  CrossValTrain  CrossValTest  Accuracy\n",
       "0            LinearSVC  without       0.992500      1.000000       100\n",
       "1            LinearSVC     with       0.992500      1.000000       100\n",
       "2   LogisticRegression  without       0.992500      0.992593       100\n",
       "3   LogisticRegression     with       0.992500      0.985185       100\n",
       "4                  KNN  without       0.992500      0.970370       100\n",
       "5                  KNN     with       0.997512      1.000000       100\n",
       "6              SVC_RBF  without       0.997512      1.000000       100\n",
       "7              SVC_RBF     with       1.000000      1.000000       100\n",
       "8           SVC_Linear  without       1.000000      1.000000       100\n",
       "9           SVC_Linear     with       1.000000      1.000000       100\n",
       "10            SVC_Poly  without       0.992537      1.000000       100\n",
       "11            SVC_Poly     with       1.000000      1.000000       100\n",
       "12        DecisionTree  without       0.997512      1.000000       100"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_poly = SVC(kernel='poly', degree=1, C=10)\n",
    "svc_poly.fit(X_train_reduced,y_train)\n",
    "\n",
    "scorestrain=(cross_val_score(svc_poly, X_train_reduced, y_train,cv=3)).mean()\n",
    "scorestest=(cross_val_score(svc_poly, X_test_reduced, y_test,cv=3)).mean()\n",
    "pred = svc_poly.predict(X_test_reduced)\n",
    "Accuracy=statistics.mean(y_test==pred)*100\n",
    "\n",
    "confusion = confusion_matrix(y_test, pred)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))\n",
    "\n",
    "line = pd.DataFrame({'Model':\"SVC_Poly\" , 'PCA': \"with\", 'CrossValTrain': scorestrain,'CrossValTest':scorestest,'Accuracy':Accuracy}, index=[10.5])\n",
    "results=results.append(line, ignore_index=False)\n",
    "results = results.sort_index().reset_index(drop=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For SVC Polynomial, PCA gives slightly better train score and results in same Accuracy (100%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree with PCA and best params search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'max_depth': 1}\n",
      "Best score:  0.9950248756218906\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier(random_state=0)\n",
    "#model param\n",
    "grid_param = {'max_depth':[1,2,3,4,5]}\n",
    "\n",
    "#grid model\n",
    "grid_search = GridSearchCV(dtree, grid_param, cv = 5, n_jobs  = -1)\n",
    "\n",
    "#train grid model\n",
    "grid_search.fit(X_train_reduced, y_train)\n",
    "\n",
    "print('Best params: ', grid_search.best_params_)\n",
    "print('Best score: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[63  0]\n",
      " [ 1 71]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>PCA</th>\n",
       "      <th>CrossValTrain</th>\n",
       "      <th>CrossValTest</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>with</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.992593</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.985185</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>with</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC_RBF</td>\n",
       "      <td>without</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC_RBF</td>\n",
       "      <td>with</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVC_Linear</td>\n",
       "      <td>without</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVC_Linear</td>\n",
       "      <td>with</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVC_Poly</td>\n",
       "      <td>without</td>\n",
       "      <td>0.992537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVC_Poly</td>\n",
       "      <td>with</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>without</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>with</td>\n",
       "      <td>0.994987</td>\n",
       "      <td>0.992593</td>\n",
       "      <td>99.259259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model      PCA  CrossValTrain  CrossValTest    Accuracy\n",
       "0            LinearSVC  without       0.992500      1.000000  100.000000\n",
       "1            LinearSVC     with       0.992500      1.000000  100.000000\n",
       "2   LogisticRegression  without       0.992500      0.992593  100.000000\n",
       "3   LogisticRegression     with       0.992500      0.985185  100.000000\n",
       "4                  KNN  without       0.992500      0.970370  100.000000\n",
       "5                  KNN     with       0.997512      1.000000  100.000000\n",
       "6              SVC_RBF  without       0.997512      1.000000  100.000000\n",
       "7              SVC_RBF     with       1.000000      1.000000  100.000000\n",
       "8           SVC_Linear  without       1.000000      1.000000  100.000000\n",
       "9           SVC_Linear     with       1.000000      1.000000  100.000000\n",
       "10            SVC_Poly  without       0.992537      1.000000  100.000000\n",
       "11            SVC_Poly     with       1.000000      1.000000  100.000000\n",
       "12        DecisionTree  without       0.997512      1.000000  100.000000\n",
       "13        DecisionTree     with       0.994987      0.992593   99.259259"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier(max_depth=1, random_state=0)\n",
    "dtree.fit(X_train_reduced, y_train)\n",
    "\n",
    "scorestrain=(cross_val_score(dtree, X_train_reduced, y_train,cv=3)).mean()\n",
    "scorestest=(cross_val_score(dtree, X_test_reduced, y_test,cv=3)).mean()\n",
    "pred = dtree.predict(X_test_reduced)\n",
    "Accuracy=statistics.mean(y_test==pred)*100\n",
    "\n",
    "confusion = confusion_matrix(y_test, pred)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))\n",
    "\n",
    "line = pd.DataFrame({'Model':\"DecisionTree\" , 'PCA': \"with\", 'CrossValTrain': scorestrain,'CrossValTest':scorestest,'Accuracy':Accuracy}, index=[12.5])\n",
    "results=results.append(line, ignore_index=False)\n",
    "results = results.sort_index().reset_index(drop=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Decision Tree, PCA gives slightly worse train and test score and results in one misclassification, giving the Accuracy of (99.2%). In this case, PCA results in loss of information while modelling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(537, 21)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "402/402 [==============================] - 0s 379us/step - loss: 0.4364 - mean_squared_error: 0.4364\n",
      "Epoch 2/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.3312 - mean_squared_error: 0.3312\n",
      "Epoch 3/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.2742 - mean_squared_error: 0.2742\n",
      "Epoch 4/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.2419 - mean_squared_error: 0.2419\n",
      "Epoch 5/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.2301 - mean_squared_error: 0.2301\n",
      "Epoch 6/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.2198 - mean_squared_error: 0.2198\n",
      "Epoch 7/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.2143 - mean_squared_error: 0.2143\n",
      "Epoch 8/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.2117 - mean_squared_error: 0.2117\n",
      "Epoch 9/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.2071 - mean_squared_error: 0.2071\n",
      "Epoch 10/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.2044 - mean_squared_error: 0.2044\n",
      "Epoch 11/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.2020 - mean_squared_error: 0.2020\n",
      "Epoch 12/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.1996 - mean_squared_error: 0.1996\n",
      "Epoch 13/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.1977 - mean_squared_error: 0.1977\n",
      "Epoch 14/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1955 - mean_squared_error: 0.1955\n",
      "Epoch 15/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.1932 - mean_squared_error: 0.1932\n",
      "Epoch 16/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1912 - mean_squared_error: 0.1912\n",
      "Epoch 17/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.1890 - mean_squared_error: 0.1890\n",
      "Epoch 18/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.1869 - mean_squared_error: 0.1869\n",
      "Epoch 19/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.1848 - mean_squared_error: 0.1848\n",
      "Epoch 20/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.1829 - mean_squared_error: 0.1829\n",
      "Epoch 21/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1810 - mean_squared_error: 0.1810\n",
      "Epoch 22/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.1790 - mean_squared_error: 0.1790\n",
      "Epoch 23/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.1771 - mean_squared_error: 0.1771\n",
      "Epoch 24/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1753 - mean_squared_error: 0.1753\n",
      "Epoch 25/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1735 - mean_squared_error: 0.1735\n",
      "Epoch 26/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1716 - mean_squared_error: 0.1716\n",
      "Epoch 27/400\n",
      "402/402 [==============================] - 0s 25us/step - loss: 0.1698 - mean_squared_error: 0.1698\n",
      "Epoch 28/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.1681 - mean_squared_error: 0.1681\n",
      "Epoch 29/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.1665 - mean_squared_error: 0.1665\n",
      "Epoch 30/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1648 - mean_squared_error: 0.1648\n",
      "Epoch 31/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1631 - mean_squared_error: 0.1631\n",
      "Epoch 32/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1615 - mean_squared_error: 0.1615\n",
      "Epoch 33/400\n",
      "402/402 [==============================] - ETA: 0s - loss: 0.1614 - mean_squared_error: 0.16 - 0s 17us/step - loss: 0.1599 - mean_squared_error: 0.1599\n",
      "Epoch 34/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1586 - mean_squared_error: 0.1586\n",
      "Epoch 35/400\n",
      "402/402 [==============================] - 0s 32us/step - loss: 0.1569 - mean_squared_error: 0.1569\n",
      "Epoch 36/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1554 - mean_squared_error: 0.1554\n",
      "Epoch 37/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.1538 - mean_squared_error: 0.1538\n",
      "Epoch 38/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1523 - mean_squared_error: 0.1523\n",
      "Epoch 39/400\n",
      "402/402 [==============================] - ETA: 0s - loss: 0.1461 - mean_squared_error: 0.14 - 0s 20us/step - loss: 0.1510 - mean_squared_error: 0.1510\n",
      "Epoch 40/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1494 - mean_squared_error: 0.1494\n",
      "Epoch 41/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1482 - mean_squared_error: 0.1482\n",
      "Epoch 42/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1469 - mean_squared_error: 0.1469\n",
      "Epoch 43/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.1451 - mean_squared_error: 0.1451\n",
      "Epoch 44/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.1439 - mean_squared_error: 0.1439\n",
      "Epoch 45/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1426 - mean_squared_error: 0.1426\n",
      "Epoch 46/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.1413 - mean_squared_error: 0.1413\n",
      "Epoch 47/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.1400 - mean_squared_error: 0.1400\n",
      "Epoch 48/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.1386 - mean_squared_error: 0.1386\n",
      "Epoch 49/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1376 - mean_squared_error: 0.1376\n",
      "Epoch 50/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1362 - mean_squared_error: 0.1362\n",
      "Epoch 51/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1350 - mean_squared_error: 0.1350\n",
      "Epoch 52/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1340 - mean_squared_error: 0.1340\n",
      "Epoch 53/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1327 - mean_squared_error: 0.1327\n",
      "Epoch 54/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.1318 - mean_squared_error: 0.1318\n",
      "Epoch 55/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1306 - mean_squared_error: 0.1306\n",
      "Epoch 56/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1295 - mean_squared_error: 0.1295\n",
      "Epoch 57/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1283 - mean_squared_error: 0.1283\n",
      "Epoch 58/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.1273 - mean_squared_error: 0.1273\n",
      "Epoch 59/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1262 - mean_squared_error: 0.1262\n",
      "Epoch 60/400\n",
      "402/402 [==============================] - 0s 25us/step - loss: 0.1251 - mean_squared_error: 0.1251\n",
      "Epoch 61/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1241 - mean_squared_error: 0.1241\n",
      "Epoch 62/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.1231 - mean_squared_error: 0.1231\n",
      "Epoch 63/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.1222 - mean_squared_error: 0.1222\n",
      "Epoch 64/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1213 - mean_squared_error: 0.1213\n",
      "Epoch 65/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.1203 - mean_squared_error: 0.1203\n",
      "Epoch 66/400\n",
      "402/402 [==============================] - 0s 25us/step - loss: 0.1194 - mean_squared_error: 0.1194\n",
      "Epoch 67/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.1183 - mean_squared_error: 0.1183\n",
      "Epoch 68/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1174 - mean_squared_error: 0.1174\n",
      "Epoch 69/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1165 - mean_squared_error: 0.1165\n",
      "Epoch 70/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1156 - mean_squared_error: 0.1156\n",
      "Epoch 71/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.1147 - mean_squared_error: 0.1147\n",
      "Epoch 72/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 0s 20us/step - loss: 0.1139 - mean_squared_error: 0.1139\n",
      "Epoch 73/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.1132 - mean_squared_error: 0.1132\n",
      "Epoch 74/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.1122 - mean_squared_error: 0.1122\n",
      "Epoch 75/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1114 - mean_squared_error: 0.1114\n",
      "Epoch 76/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1107 - mean_squared_error: 0.1107\n",
      "Epoch 77/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.1099 - mean_squared_error: 0.1099\n",
      "Epoch 78/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1091 - mean_squared_error: 0.1091\n",
      "Epoch 79/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.1084 - mean_squared_error: 0.1084\n",
      "Epoch 80/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1076 - mean_squared_error: 0.1076\n",
      "Epoch 81/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.1068 - mean_squared_error: 0.1068\n",
      "Epoch 82/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1060 - mean_squared_error: 0.1060\n",
      "Epoch 83/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.1055 - mean_squared_error: 0.1055\n",
      "Epoch 84/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.1047 - mean_squared_error: 0.1047\n",
      "Epoch 85/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1040 - mean_squared_error: 0.1040\n",
      "Epoch 86/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.1034 - mean_squared_error: 0.1034\n",
      "Epoch 87/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.1029 - mean_squared_error: 0.1029\n",
      "Epoch 88/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1021 - mean_squared_error: 0.1021\n",
      "Epoch 89/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1014 - mean_squared_error: 0.1014\n",
      "Epoch 90/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1007 - mean_squared_error: 0.1007\n",
      "Epoch 91/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.1001 - mean_squared_error: 0.1001\n",
      "Epoch 92/400\n",
      "402/402 [==============================] - 0s 16us/step - loss: 0.0994 - mean_squared_error: 0.0994\n",
      "Epoch 93/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0989 - mean_squared_error: 0.0989\n",
      "Epoch 94/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0983 - mean_squared_error: 0.0983\n",
      "Epoch 95/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0977 - mean_squared_error: 0.0977\n",
      "Epoch 96/400\n",
      "402/402 [==============================] - 0s 37us/step - loss: 0.0971 - mean_squared_error: 0.0971\n",
      "Epoch 97/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.0966 - mean_squared_error: 0.0966\n",
      "Epoch 98/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0960 - mean_squared_error: 0.0960\n",
      "Epoch 99/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0955 - mean_squared_error: 0.0955\n",
      "Epoch 100/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0949 - mean_squared_error: 0.0949\n",
      "Epoch 101/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0944 - mean_squared_error: 0.0944\n",
      "Epoch 102/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0939 - mean_squared_error: 0.0939\n",
      "Epoch 103/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0934 - mean_squared_error: 0.0934\n",
      "Epoch 104/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0929 - mean_squared_error: 0.0929\n",
      "Epoch 105/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0924 - mean_squared_error: 0.0924\n",
      "Epoch 106/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0918 - mean_squared_error: 0.0918\n",
      "Epoch 107/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0913 - mean_squared_error: 0.0913\n",
      "Epoch 108/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0909 - mean_squared_error: 0.0909\n",
      "Epoch 109/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0905 - mean_squared_error: 0.0905\n",
      "Epoch 110/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0902 - mean_squared_error: 0.0902\n",
      "Epoch 111/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0896 - mean_squared_error: 0.0896\n",
      "Epoch 112/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0891 - mean_squared_error: 0.0891\n",
      "Epoch 113/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0885 - mean_squared_error: 0.0885\n",
      "Epoch 114/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0880 - mean_squared_error: 0.0880\n",
      "Epoch 115/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0877 - mean_squared_error: 0.0877\n",
      "Epoch 116/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0872 - mean_squared_error: 0.0872\n",
      "Epoch 117/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0870 - mean_squared_error: 0.0870\n",
      "Epoch 118/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0866 - mean_squared_error: 0.0866\n",
      "Epoch 119/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0862 - mean_squared_error: 0.0862\n",
      "Epoch 120/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0856 - mean_squared_error: 0.0856\n",
      "Epoch 121/400\n",
      "402/402 [==============================] - 0s 25us/step - loss: 0.0852 - mean_squared_error: 0.0852\n",
      "Epoch 122/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0849 - mean_squared_error: 0.0849\n",
      "Epoch 123/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0846 - mean_squared_error: 0.0846\n",
      "Epoch 124/400\n",
      "402/402 [==============================] - 0s 47us/step - loss: 0.0841 - mean_squared_error: 0.0841\n",
      "Epoch 125/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0837 - mean_squared_error: 0.0837\n",
      "Epoch 126/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0834 - mean_squared_error: 0.0834\n",
      "Epoch 127/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0830 - mean_squared_error: 0.0830\n",
      "Epoch 128/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0826 - mean_squared_error: 0.0826\n",
      "Epoch 129/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0822 - mean_squared_error: 0.0822\n",
      "Epoch 130/400\n",
      "402/402 [==============================] - 0s 30us/step - loss: 0.0819 - mean_squared_error: 0.0819\n",
      "Epoch 131/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0816 - mean_squared_error: 0.0816\n",
      "Epoch 132/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0812 - mean_squared_error: 0.0812\n",
      "Epoch 133/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0810 - mean_squared_error: 0.0810\n",
      "Epoch 134/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0806 - mean_squared_error: 0.0806\n",
      "Epoch 135/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.0803 - mean_squared_error: 0.0803\n",
      "Epoch 136/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0800 - mean_squared_error: 0.0800\n",
      "Epoch 137/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0798 - mean_squared_error: 0.0798\n",
      "Epoch 138/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0794 - mean_squared_error: 0.0794\n",
      "Epoch 139/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0790 - mean_squared_error: 0.0790\n",
      "Epoch 140/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0787 - mean_squared_error: 0.0787\n",
      "Epoch 141/400\n",
      "402/402 [==============================] - 0s 47us/step - loss: 0.0785 - mean_squared_error: 0.0785\n",
      "Epoch 142/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.0782 - mean_squared_error: 0.0782\n",
      "Epoch 143/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0779 - mean_squared_error: 0.0779\n",
      "Epoch 144/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 0s 17us/step - loss: 0.0776 - mean_squared_error: 0.0776\n",
      "Epoch 145/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0773 - mean_squared_error: 0.0773\n",
      "Epoch 146/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0771 - mean_squared_error: 0.0771\n",
      "Epoch 147/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0770 - mean_squared_error: 0.0770\n",
      "Epoch 148/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0768 - mean_squared_error: 0.0768\n",
      "Epoch 149/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0763 - mean_squared_error: 0.0763\n",
      "Epoch 150/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0760 - mean_squared_error: 0.0760\n",
      "Epoch 151/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0758 - mean_squared_error: 0.0758\n",
      "Epoch 152/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0754 - mean_squared_error: 0.0754\n",
      "Epoch 153/400\n",
      "402/402 [==============================] - 0s 25us/step - loss: 0.0752 - mean_squared_error: 0.0752\n",
      "Epoch 154/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0750 - mean_squared_error: 0.0750\n",
      "Epoch 155/400\n",
      "402/402 [==============================] - 0s 27us/step - loss: 0.0749 - mean_squared_error: 0.0749\n",
      "Epoch 156/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0746 - mean_squared_error: 0.0746\n",
      "Epoch 157/400\n",
      "402/402 [==============================] - 0s 25us/step - loss: 0.0744 - mean_squared_error: 0.0744\n",
      "Epoch 158/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0742 - mean_squared_error: 0.0742\n",
      "Epoch 159/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0739 - mean_squared_error: 0.0739\n",
      "Epoch 160/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0739 - mean_squared_error: 0.0739\n",
      "Epoch 161/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0735 - mean_squared_error: 0.0735\n",
      "Epoch 162/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0732 - mean_squared_error: 0.0732\n",
      "Epoch 163/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0730 - mean_squared_error: 0.0730\n",
      "Epoch 164/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.0728 - mean_squared_error: 0.0728\n",
      "Epoch 165/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0725 - mean_squared_error: 0.0725\n",
      "Epoch 166/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0723 - mean_squared_error: 0.0723\n",
      "Epoch 167/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0721 - mean_squared_error: 0.0721\n",
      "Epoch 168/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0719 - mean_squared_error: 0.0719\n",
      "Epoch 169/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0717 - mean_squared_error: 0.0717\n",
      "Epoch 170/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0716 - mean_squared_error: 0.0716\n",
      "Epoch 171/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0714 - mean_squared_error: 0.0714\n",
      "Epoch 172/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0711 - mean_squared_error: 0.0711\n",
      "Epoch 173/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0709 - mean_squared_error: 0.0709\n",
      "Epoch 174/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0707 - mean_squared_error: 0.0707\n",
      "Epoch 175/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0706 - mean_squared_error: 0.0706\n",
      "Epoch 176/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0703 - mean_squared_error: 0.0703\n",
      "Epoch 177/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0701 - mean_squared_error: 0.0701\n",
      "Epoch 178/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0699 - mean_squared_error: 0.0699\n",
      "Epoch 179/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0697 - mean_squared_error: 0.0697\n",
      "Epoch 180/400\n",
      "402/402 [==============================] - 0s 32us/step - loss: 0.0696 - mean_squared_error: 0.0696\n",
      "Epoch 181/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0695 - mean_squared_error: 0.0695\n",
      "Epoch 182/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0694 - mean_squared_error: 0.0694\n",
      "Epoch 183/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0692 - mean_squared_error: 0.0692\n",
      "Epoch 184/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0689 - mean_squared_error: 0.0689\n",
      "Epoch 185/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0688 - mean_squared_error: 0.0688\n",
      "Epoch 186/400\n",
      "402/402 [==============================] - 0s 27us/step - loss: 0.0686 - mean_squared_error: 0.0686\n",
      "Epoch 187/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0684 - mean_squared_error: 0.0684\n",
      "Epoch 188/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0683 - mean_squared_error: 0.0683\n",
      "Epoch 189/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0681 - mean_squared_error: 0.0681\n",
      "Epoch 190/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0679 - mean_squared_error: 0.0679\n",
      "Epoch 191/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.0678 - mean_squared_error: 0.0678\n",
      "Epoch 192/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0677 - mean_squared_error: 0.0677\n",
      "Epoch 193/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0675 - mean_squared_error: 0.0675\n",
      "Epoch 194/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0673 - mean_squared_error: 0.0673\n",
      "Epoch 195/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.0672 - mean_squared_error: 0.0672\n",
      "Epoch 196/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0670 - mean_squared_error: 0.0670\n",
      "Epoch 197/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0669 - mean_squared_error: 0.0669\n",
      "Epoch 198/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0669 - mean_squared_error: 0.0669\n",
      "Epoch 199/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0666 - mean_squared_error: 0.0666\n",
      "Epoch 200/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0664 - mean_squared_error: 0.0664\n",
      "Epoch 201/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0663 - mean_squared_error: 0.0663\n",
      "Epoch 202/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0661 - mean_squared_error: 0.0661\n",
      "Epoch 203/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0660 - mean_squared_error: 0.0660\n",
      "Epoch 204/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0659 - mean_squared_error: 0.0659\n",
      "Epoch 205/400\n",
      "402/402 [==============================] - 0s 32us/step - loss: 0.0658 - mean_squared_error: 0.0658\n",
      "Epoch 206/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0656 - mean_squared_error: 0.0656\n",
      "Epoch 207/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0654 - mean_squared_error: 0.0654\n",
      "Epoch 208/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0653 - mean_squared_error: 0.0653\n",
      "Epoch 209/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0652 - mean_squared_error: 0.0652\n",
      "Epoch 210/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0651 - mean_squared_error: 0.0651\n",
      "Epoch 211/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0649 - mean_squared_error: 0.0649\n",
      "Epoch 212/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0648 - mean_squared_error: 0.0648\n",
      "Epoch 213/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.0647 - mean_squared_error: 0.0647\n",
      "Epoch 214/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0647 - mean_squared_error: 0.0647\n",
      "Epoch 215/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0646 - mean_squared_error: 0.0646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.0645 - mean_squared_error: 0.0645\n",
      "Epoch 217/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.0642 - mean_squared_error: 0.0642\n",
      "Epoch 218/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.0641 - mean_squared_error: 0.0641\n",
      "Epoch 219/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0640 - mean_squared_error: 0.0640\n",
      "Epoch 220/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0639 - mean_squared_error: 0.0639\n",
      "Epoch 221/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0637 - mean_squared_error: 0.0637\n",
      "Epoch 222/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0636 - mean_squared_error: 0.0636\n",
      "Epoch 223/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0636 - mean_squared_error: 0.0636\n",
      "Epoch 224/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0633 - mean_squared_error: 0.0633\n",
      "Epoch 225/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0633 - mean_squared_error: 0.0633\n",
      "Epoch 226/400\n",
      "402/402 [==============================] - 0s 32us/step - loss: 0.0632 - mean_squared_error: 0.0632\n",
      "Epoch 227/400\n",
      "402/402 [==============================] - 0s 25us/step - loss: 0.0630 - mean_squared_error: 0.0630\n",
      "Epoch 228/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0629 - mean_squared_error: 0.0629\n",
      "Epoch 229/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0628 - mean_squared_error: 0.0628\n",
      "Epoch 230/400\n",
      "402/402 [==============================] - 0s 27us/step - loss: 0.0626 - mean_squared_error: 0.0626\n",
      "Epoch 231/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0626 - mean_squared_error: 0.0626\n",
      "Epoch 232/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0625 - mean_squared_error: 0.0625\n",
      "Epoch 233/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0623 - mean_squared_error: 0.0623\n",
      "Epoch 234/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0623 - mean_squared_error: 0.0623\n",
      "Epoch 235/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0622 - mean_squared_error: 0.0622\n",
      "Epoch 236/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0621 - mean_squared_error: 0.0621\n",
      "Epoch 237/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0620 - mean_squared_error: 0.0620\n",
      "Epoch 238/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.0619 - mean_squared_error: 0.0619\n",
      "Epoch 239/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0618 - mean_squared_error: 0.0618\n",
      "Epoch 240/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0616 - mean_squared_error: 0.0616\n",
      "Epoch 241/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0615 - mean_squared_error: 0.0615\n",
      "Epoch 242/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0614 - mean_squared_error: 0.0614\n",
      "Epoch 243/400\n",
      "402/402 [==============================] - 0s 32us/step - loss: 0.0614 - mean_squared_error: 0.0614\n",
      "Epoch 244/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0612 - mean_squared_error: 0.0612\n",
      "Epoch 245/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0611 - mean_squared_error: 0.0611\n",
      "Epoch 246/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0611 - mean_squared_error: 0.0611\n",
      "Epoch 247/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0610 - mean_squared_error: 0.0610\n",
      "Epoch 248/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0608 - mean_squared_error: 0.0608\n",
      "Epoch 249/400\n",
      "402/402 [==============================] - 0s 27us/step - loss: 0.0608 - mean_squared_error: 0.0608\n",
      "Epoch 250/400\n",
      "402/402 [==============================] - ETA: 0s - loss: 0.0597 - mean_squared_error: 0.05 - 0s 20us/step - loss: 0.0606 - mean_squared_error: 0.0606\n",
      "Epoch 251/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0606 - mean_squared_error: 0.0606\n",
      "Epoch 252/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0605 - mean_squared_error: 0.0605\n",
      "Epoch 253/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0604 - mean_squared_error: 0.0604\n",
      "Epoch 254/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0603 - mean_squared_error: 0.0603\n",
      "Epoch 255/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.0602 - mean_squared_error: 0.0602\n",
      "Epoch 256/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0601 - mean_squared_error: 0.0601\n",
      "Epoch 257/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0600 - mean_squared_error: 0.0600\n",
      "Epoch 258/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0600 - mean_squared_error: 0.0600\n",
      "Epoch 259/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0598 - mean_squared_error: 0.0598\n",
      "Epoch 260/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0597 - mean_squared_error: 0.0597\n",
      "Epoch 261/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0596 - mean_squared_error: 0.0596\n",
      "Epoch 262/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0595 - mean_squared_error: 0.0595\n",
      "Epoch 263/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0594 - mean_squared_error: 0.0594\n",
      "Epoch 264/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0593 - mean_squared_error: 0.0593\n",
      "Epoch 265/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0592 - mean_squared_error: 0.0592\n",
      "Epoch 266/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0592 - mean_squared_error: 0.0592\n",
      "Epoch 267/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0591 - mean_squared_error: 0.0591\n",
      "Epoch 268/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0589 - mean_squared_error: 0.0589\n",
      "Epoch 269/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0590 - mean_squared_error: 0.0590\n",
      "Epoch 270/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0589 - mean_squared_error: 0.0589\n",
      "Epoch 271/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0588 - mean_squared_error: 0.0588\n",
      "Epoch 272/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0587 - mean_squared_error: 0.0587\n",
      "Epoch 273/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0586 - mean_squared_error: 0.0586\n",
      "Epoch 274/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0585 - mean_squared_error: 0.0585\n",
      "Epoch 275/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.0583 - mean_squared_error: 0.0583\n",
      "Epoch 276/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0583 - mean_squared_error: 0.0583\n",
      "Epoch 277/400\n",
      "402/402 [==============================] - 0s 32us/step - loss: 0.0583 - mean_squared_error: 0.0583\n",
      "Epoch 278/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0582 - mean_squared_error: 0.0582\n",
      "Epoch 279/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0581 - mean_squared_error: 0.0581\n",
      "Epoch 280/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0580 - mean_squared_error: 0.0580\n",
      "Epoch 281/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0578 - mean_squared_error: 0.0578\n",
      "Epoch 282/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0578 - mean_squared_error: 0.0578\n",
      "Epoch 283/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0578 - mean_squared_error: 0.0578\n",
      "Epoch 284/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0576 - mean_squared_error: 0.0576\n",
      "Epoch 285/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0575 - mean_squared_error: 0.0575\n",
      "Epoch 286/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0575 - mean_squared_error: 0.0575\n",
      "Epoch 287/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 0s 17us/step - loss: 0.0574 - mean_squared_error: 0.0574\n",
      "Epoch 288/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0574 - mean_squared_error: 0.0574\n",
      "Epoch 289/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0572 - mean_squared_error: 0.0572\n",
      "Epoch 290/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0571 - mean_squared_error: 0.0571\n",
      "Epoch 291/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0570 - mean_squared_error: 0.0570\n",
      "Epoch 292/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0570 - mean_squared_error: 0.0570\n",
      "Epoch 293/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0569 - mean_squared_error: 0.0569\n",
      "Epoch 294/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0568 - mean_squared_error: 0.0568\n",
      "Epoch 295/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0567 - mean_squared_error: 0.0567\n",
      "Epoch 296/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0567 - mean_squared_error: 0.0567\n",
      "Epoch 297/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0566 - mean_squared_error: 0.0566\n",
      "Epoch 298/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0565 - mean_squared_error: 0.0565\n",
      "Epoch 299/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.0564 - mean_squared_error: 0.0564\n",
      "Epoch 300/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0564 - mean_squared_error: 0.0564\n",
      "Epoch 301/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0563 - mean_squared_error: 0.0563\n",
      "Epoch 302/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0562 - mean_squared_error: 0.0562\n",
      "Epoch 303/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0561 - mean_squared_error: 0.0561\n",
      "Epoch 304/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0561 - mean_squared_error: 0.0561\n",
      "Epoch 305/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0560 - mean_squared_error: 0.0560\n",
      "Epoch 306/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0560 - mean_squared_error: 0.0560\n",
      "Epoch 307/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0559 - mean_squared_error: 0.0559\n",
      "Epoch 308/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0559 - mean_squared_error: 0.0559\n",
      "Epoch 309/400\n",
      "402/402 [==============================] - ETA: 0s - loss: 0.0566 - mean_squared_error: 0.05 - 0s 17us/step - loss: 0.0558 - mean_squared_error: 0.0558\n",
      "Epoch 310/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0556 - mean_squared_error: 0.0556\n",
      "Epoch 311/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0556 - mean_squared_error: 0.0556\n",
      "Epoch 312/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0555 - mean_squared_error: 0.0555\n",
      "Epoch 313/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0554 - mean_squared_error: 0.0554\n",
      "Epoch 314/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0553 - mean_squared_error: 0.0553\n",
      "Epoch 315/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0553 - mean_squared_error: 0.0553\n",
      "Epoch 316/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0552 - mean_squared_error: 0.0552\n",
      "Epoch 317/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0552 - mean_squared_error: 0.0552\n",
      "Epoch 318/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0551 - mean_squared_error: 0.0551\n",
      "Epoch 319/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.0550 - mean_squared_error: 0.0550\n",
      "Epoch 320/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0549 - mean_squared_error: 0.0549\n",
      "Epoch 321/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0549 - mean_squared_error: 0.0549\n",
      "Epoch 322/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0548 - mean_squared_error: 0.0548\n",
      "Epoch 323/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0547 - mean_squared_error: 0.0547\n",
      "Epoch 324/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0547 - mean_squared_error: 0.0547\n",
      "Epoch 325/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0546 - mean_squared_error: 0.0546\n",
      "Epoch 326/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0545 - mean_squared_error: 0.0545\n",
      "Epoch 327/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0545 - mean_squared_error: 0.0545\n",
      "Epoch 328/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0545 - mean_squared_error: 0.0545\n",
      "Epoch 329/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0544 - mean_squared_error: 0.0544\n",
      "Epoch 330/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0543 - mean_squared_error: 0.0543\n",
      "Epoch 331/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0543 - mean_squared_error: 0.0543\n",
      "Epoch 332/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0542 - mean_squared_error: 0.0542\n",
      "Epoch 333/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0541 - mean_squared_error: 0.0541\n",
      "Epoch 334/400\n",
      "402/402 [==============================] - 0s 21us/step - loss: 0.0540 - mean_squared_error: 0.0540\n",
      "Epoch 335/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0540 - mean_squared_error: 0.0540\n",
      "Epoch 336/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0540 - mean_squared_error: 0.0540\n",
      "Epoch 337/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0538 - mean_squared_error: 0.0538\n",
      "Epoch 338/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0538 - mean_squared_error: 0.0538\n",
      "Epoch 339/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.0539 - mean_squared_error: 0.0539\n",
      "Epoch 340/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0538 - mean_squared_error: 0.0538\n",
      "Epoch 341/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.0537 - mean_squared_error: 0.0537\n",
      "Epoch 342/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0535 - mean_squared_error: 0.0535\n",
      "Epoch 343/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0534 - mean_squared_error: 0.0534\n",
      "Epoch 344/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0534 - mean_squared_error: 0.0534\n",
      "Epoch 345/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0533 - mean_squared_error: 0.0533\n",
      "Epoch 346/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0533 - mean_squared_error: 0.0533\n",
      "Epoch 347/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0532 - mean_squared_error: 0.0532\n",
      "Epoch 348/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0531 - mean_squared_error: 0.0531\n",
      "Epoch 349/400\n",
      "402/402 [==============================] - 0s 12us/step - loss: 0.0531 - mean_squared_error: 0.0531\n",
      "Epoch 350/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0530 - mean_squared_error: 0.0530\n",
      "Epoch 351/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.0529 - mean_squared_error: 0.0529\n",
      "Epoch 352/400\n",
      "402/402 [==============================] - 0s 25us/step - loss: 0.0530 - mean_squared_error: 0.0530\n",
      "Epoch 353/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.0528 - mean_squared_error: 0.0528\n",
      "Epoch 354/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0527 - mean_squared_error: 0.0527\n",
      "Epoch 355/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0527 - mean_squared_error: 0.0527\n",
      "Epoch 356/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0526 - mean_squared_error: 0.0526\n",
      "Epoch 357/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0525 - mean_squared_error: 0.0525\n",
      "Epoch 358/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 0s 17us/step - loss: 0.0525 - mean_squared_error: 0.0525\n",
      "Epoch 359/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0524 - mean_squared_error: 0.0524\n",
      "Epoch 360/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0523 - mean_squared_error: 0.0523\n",
      "Epoch 361/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0523 - mean_squared_error: 0.0523\n",
      "Epoch 362/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0522 - mean_squared_error: 0.0522\n",
      "Epoch 363/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0522 - mean_squared_error: 0.0522\n",
      "Epoch 364/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0521 - mean_squared_error: 0.0521\n",
      "Epoch 365/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0521 - mean_squared_error: 0.0521\n",
      "Epoch 366/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0521 - mean_squared_error: 0.0521\n",
      "Epoch 367/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.0520 - mean_squared_error: 0.0520\n",
      "Epoch 368/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.0519 - mean_squared_error: 0.0519\n",
      "Epoch 369/400\n",
      "402/402 [==============================] - 0s 30us/step - loss: 0.0518 - mean_squared_error: 0.0518\n",
      "Epoch 370/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0517 - mean_squared_error: 0.0517\n",
      "Epoch 371/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0517 - mean_squared_error: 0.0517\n",
      "Epoch 372/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0516 - mean_squared_error: 0.0516\n",
      "Epoch 373/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0516 - mean_squared_error: 0.0516\n",
      "Epoch 374/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0515 - mean_squared_error: 0.0515\n",
      "Epoch 375/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0515 - mean_squared_error: 0.0515\n",
      "Epoch 376/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0514 - mean_squared_error: 0.0514\n",
      "Epoch 377/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0514 - mean_squared_error: 0.0514\n",
      "Epoch 378/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0513 - mean_squared_error: 0.0513\n",
      "Epoch 379/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0513 - mean_squared_error: 0.0513\n",
      "Epoch 380/400\n",
      "402/402 [==============================] - 0s 19us/step - loss: 0.0512 - mean_squared_error: 0.0512\n",
      "Epoch 381/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0512 - mean_squared_error: 0.0512\n",
      "Epoch 382/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0511 - mean_squared_error: 0.0511\n",
      "Epoch 383/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0512 - mean_squared_error: 0.0512\n",
      "Epoch 384/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0511 - mean_squared_error: 0.0511\n",
      "Epoch 385/400\n",
      "402/402 [==============================] - 0s 25us/step - loss: 0.0509 - mean_squared_error: 0.0509\n",
      "Epoch 386/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 0.0509 - mean_squared_error: 0.0509\n",
      "Epoch 387/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0508 - mean_squared_error: 0.0508\n",
      "Epoch 388/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0508 - mean_squared_error: 0.0508\n",
      "Epoch 389/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0508 - mean_squared_error: 0.0508\n",
      "Epoch 390/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0508 - mean_squared_error: 0.0508\n",
      "Epoch 391/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0507 - mean_squared_error: 0.0507\n",
      "Epoch 392/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0506 - mean_squared_error: 0.0506\n",
      "Epoch 393/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0505 - mean_squared_error: 0.0505\n",
      "Epoch 394/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0504 - mean_squared_error: 0.0504\n",
      "Epoch 395/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 0.0504 - mean_squared_error: 0.0504\n",
      "Epoch 396/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0503 - mean_squared_error: 0.0503\n",
      "Epoch 397/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0503 - mean_squared_error: 0.0503\n",
      "Epoch 398/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 0.0502 - mean_squared_error: 0.0502\n",
      "Epoch 399/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0502 - mean_squared_error: 0.0502\n",
      "Epoch 400/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 0.0501 - mean_squared_error: 0.0501\n",
      "402/402 [==============================] - 0s 86us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05005736815840451, 0.05005736815840451]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "#step 1: make model - no hidden layer\n",
    "model = Sequential()\n",
    "#input layer: input_dim = no. of columns in X_train\n",
    "model.add(Dense(10, input_dim = 21 , activation = 'sigmoid'))\n",
    "#hidden layer : add if needed\n",
    "#output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "# step 2: compile the model -> create the computational graph\n",
    "model.compile(loss ='mse', optimizer = 'sgd' , metrics = ['mse'] )\n",
    "\n",
    "# step 3: train the model -> fit epochs and batch_size\n",
    "model.fit(X_train, y_train, epochs = 400, batch_size = 128)\n",
    "\n",
    "#step 4: evaluation\n",
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[63  0]\n",
      " [ 4 68]]\n",
      "Accuracy :\n",
      "97.03703703703704\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = model.predict(X_test)\n",
    "for i in range(len(pred)):\n",
    "    if pred[i,0]>=0.5:\n",
    "        pred[i,0]=1\n",
    "    else:\n",
    "        pred[i,0]=0\n",
    "Accuracy=statistics.mean(y_test==pred[:,0])*100\n",
    "confusion = confusion_matrix(y_test, pred[:,0])\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))\n",
    "print(\"Accuracy :\\n{}\".format(Accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "402/402 [==============================] - 0s 546us/step - loss: 0.6728 - mean_squared_error: 0.7240\n",
      "Epoch 2/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4727 - mean_squared_error: 0.4545\n",
      "Epoch 3/400\n",
      "402/402 [==============================] - 0s 278us/step - loss: 0.4716 - mean_squared_error: 0.4571\n",
      "Epoch 4/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.4710 - mean_squared_error: 0.4490\n",
      "Epoch 5/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4693 - mean_squared_error: 0.4558\n",
      "Epoch 6/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4690 - mean_squared_error: 0.4439\n",
      "Epoch 7/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4686 - mean_squared_error: 0.4510\n",
      "Epoch 8/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.4673 - mean_squared_error: 0.4499\n",
      "Epoch 9/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.4667 - mean_squared_error: 0.4484\n",
      "Epoch 10/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.4663 - mean_squared_error: 0.4487\n",
      "Epoch 11/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.4661 - mean_squared_error: 0.4469\n",
      "Epoch 12/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.4654 - mean_squared_error: 0.4438\n",
      "Epoch 13/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.4654 - mean_squared_error: 0.4462\n",
      "Epoch 14/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.4657 - mean_squared_error: 0.4426\n",
      "Epoch 15/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.4641 - mean_squared_error: 0.4446\n",
      "Epoch 16/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4651 - mean_squared_error: 0.4308\n",
      "Epoch 17/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.4640 - mean_squared_error: 0.4442\n",
      "Epoch 18/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4639 - mean_squared_error: 0.4434\n",
      "Epoch 19/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.4636 - mean_squared_error: 0.4460\n",
      "Epoch 20/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4626 - mean_squared_error: 0.4444\n",
      "Epoch 21/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4633 - mean_squared_error: 0.4312\n",
      "Epoch 22/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.4620 - mean_squared_error: 0.4336\n",
      "Epoch 23/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.4623 - mean_squared_error: 0.4364\n",
      "Epoch 24/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.4609 - mean_squared_error: 0.4376\n",
      "Epoch 25/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.4611 - mean_squared_error: 0.4390\n",
      "Epoch 26/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.4611 - mean_squared_error: 0.4234\n",
      "Epoch 27/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4596 - mean_squared_error: 0.4350\n",
      "Epoch 28/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.4590 - mean_squared_error: 0.4335\n",
      "Epoch 29/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4583 - mean_squared_error: 0.4312\n",
      "Epoch 30/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.4580 - mean_squared_error: 0.4317\n",
      "Epoch 31/400\n",
      "402/402 [==============================] - 0s 72us/step - loss: 0.4587 - mean_squared_error: 0.4221\n",
      "Epoch 32/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.4572 - mean_squared_error: 0.4241\n",
      "Epoch 33/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.4565 - mean_squared_error: 0.4235\n",
      "Epoch 34/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4553 - mean_squared_error: 0.4211\n",
      "Epoch 35/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4550 - mean_squared_error: 0.4212\n",
      "Epoch 36/400\n",
      "402/402 [==============================] - 0s 59us/step - loss: 0.4538 - mean_squared_error: 0.4192\n",
      "Epoch 37/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4543 - mean_squared_error: 0.3960\n",
      "Epoch 38/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.4518 - mean_squared_error: 0.4139\n",
      "Epoch 39/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.4508 - mean_squared_error: 0.4148\n",
      "Epoch 40/400\n",
      "402/402 [==============================] - 0s 58us/step - loss: 0.4494 - mean_squared_error: 0.4080\n",
      "Epoch 41/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.4495 - mean_squared_error: 0.4047\n",
      "Epoch 42/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.4471 - mean_squared_error: 0.4029\n",
      "Epoch 43/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.4457 - mean_squared_error: 0.3881\n",
      "Epoch 44/400\n",
      "402/402 [==============================] - 0s 56us/step - loss: 0.4432 - mean_squared_error: 0.3929\n",
      "Epoch 45/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.4424 - mean_squared_error: 0.3923\n",
      "Epoch 46/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4401 - mean_squared_error: 0.3864\n",
      "Epoch 47/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.4373 - mean_squared_error: 0.3822\n",
      "Epoch 48/400\n",
      "402/402 [==============================] - 0s 63us/step - loss: 0.4350 - mean_squared_error: 0.3789\n",
      "Epoch 49/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.4320 - mean_squared_error: 0.3680\n",
      "Epoch 50/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.4282 - mean_squared_error: 0.3636\n",
      "Epoch 51/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.4221 - mean_squared_error: 0.3533\n",
      "Epoch 52/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.4138 - mean_squared_error: 0.3325\n",
      "Epoch 53/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.4025 - mean_squared_error: 0.3157\n",
      "Epoch 54/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.3913 - mean_squared_error: 0.2973\n",
      "Epoch 55/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.3827 - mean_squared_error: 0.2798\n",
      "Epoch 56/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.3721 - mean_squared_error: 0.2645\n",
      "Epoch 57/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.3610 - mean_squared_error: 0.2474\n",
      "Epoch 58/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.3480 - mean_squared_error: 0.2239\n",
      "Epoch 59/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.3318 - mean_squared_error: 0.2024\n",
      "Epoch 60/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.3130 - mean_squared_error: 0.1793\n",
      "Epoch 61/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.2939 - mean_squared_error: 0.1590\n",
      "Epoch 62/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.2808 - mean_squared_error: 0.1391\n",
      "Epoch 63/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.2637 - mean_squared_error: 0.1229\n",
      "Epoch 64/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.2454 - mean_squared_error: 0.1073\n",
      "Epoch 65/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.2325 - mean_squared_error: 0.0975\n",
      "Epoch 66/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.2136 - mean_squared_error: 0.0821\n",
      "Epoch 67/400\n",
      "402/402 [==============================] - 0s 50us/step - loss: 0.1960 - mean_squared_error: 0.0726\n",
      "Epoch 68/400\n",
      "402/402 [==============================] - 0s 74us/step - loss: 0.1809 - mean_squared_error: 0.0615\n",
      "Epoch 69/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.1644 - mean_squared_error: 0.0533\n",
      "Epoch 70/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.1439 - mean_squared_error: 0.0494\n",
      "Epoch 71/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.1269 - mean_squared_error: 0.0417\n",
      "Epoch 72/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.1204 - mean_squared_error: 0.0395\n",
      "Epoch 73/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 0s 67us/step - loss: 0.1125 - mean_squared_error: 0.0364\n",
      "Epoch 74/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.1090 - mean_squared_error: 0.0353\n",
      "Epoch 75/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.1045 - mean_squared_error: 0.0347\n",
      "Epoch 76/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0965 - mean_squared_error: 0.0293\n",
      "Epoch 77/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0916 - mean_squared_error: 0.0272\n",
      "Epoch 78/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0878 - mean_squared_error: 0.0263\n",
      "Epoch 79/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0809 - mean_squared_error: 0.0241\n",
      "Epoch 80/400\n",
      "402/402 [==============================] - 0s 58us/step - loss: 0.0757 - mean_squared_error: 0.0218\n",
      "Epoch 81/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.0762 - mean_squared_error: 0.0220\n",
      "Epoch 82/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0711 - mean_squared_error: 0.0212\n",
      "Epoch 83/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0645 - mean_squared_error: 0.0187\n",
      "Epoch 84/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0639 - mean_squared_error: 0.0166\n",
      "Epoch 85/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0607 - mean_squared_error: 0.0156\n",
      "Epoch 86/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0558 - mean_squared_error: 0.0138\n",
      "Epoch 87/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0574 - mean_squared_error: 0.0159\n",
      "Epoch 88/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0646 - mean_squared_error: 0.0156\n",
      "Epoch 89/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0586 - mean_squared_error: 0.0129\n",
      "Epoch 90/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0567 - mean_squared_error: 0.0121\n",
      "Epoch 91/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0491 - mean_squared_error: 0.0103\n",
      "Epoch 92/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0551 - mean_squared_error: 0.0106\n",
      "Epoch 93/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0497 - mean_squared_error: 0.0093\n",
      "Epoch 94/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0529 - mean_squared_error: 0.0096\n",
      "Epoch 95/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0464 - mean_squared_error: 0.0091\n",
      "Epoch 96/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0513 - mean_squared_error: 0.0083\n",
      "Epoch 97/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0545 - mean_squared_error: 0.0101\n",
      "Epoch 98/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0519 - mean_squared_error: 0.0086\n",
      "Epoch 99/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0473 - mean_squared_error: 0.0071\n",
      "Epoch 100/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0490 - mean_squared_error: 0.0067\n",
      "Epoch 101/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0442 - mean_squared_error: 0.0058\n",
      "Epoch 102/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0493 - mean_squared_error: 0.0078\n",
      "Epoch 103/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0433 - mean_squared_error: 0.0054\n",
      "Epoch 104/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0454 - mean_squared_error: 0.0077\n",
      "Epoch 105/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0443 - mean_squared_error: 0.0060\n",
      "Epoch 106/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0431 - mean_squared_error: 0.0051\n",
      "Epoch 107/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0471 - mean_squared_error: 0.0058\n",
      "Epoch 108/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0386 - mean_squared_error: 0.0046\n",
      "Epoch 109/400\n",
      "402/402 [==============================] - 0s 50us/step - loss: 0.0438 - mean_squared_error: 0.0049\n",
      "Epoch 110/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0421 - mean_squared_error: 0.0045\n",
      "Epoch 111/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0451 - mean_squared_error: 0.0056\n",
      "Epoch 112/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0402 - mean_squared_error: 0.0044\n",
      "Epoch 113/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0424 - mean_squared_error: 0.0048\n",
      "Epoch 114/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0413 - mean_squared_error: 0.0043\n",
      "Epoch 115/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0470 - mean_squared_error: 0.0063\n",
      "Epoch 116/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0433 - mean_squared_error: 0.0048\n",
      "Epoch 117/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0430 - mean_squared_error: 0.0054\n",
      "Epoch 118/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0432 - mean_squared_error: 0.0051\n",
      "Epoch 119/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0390 - mean_squared_error: 0.0043\n",
      "Epoch 120/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0430 - mean_squared_error: 0.0043\n",
      "Epoch 121/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0458 - mean_squared_error: 0.0065\n",
      "Epoch 122/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0370 - mean_squared_error: 0.0048\n",
      "Epoch 123/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0360 - mean_squared_error: 0.0041\n",
      "Epoch 124/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0324 - mean_squared_error: 0.0034\n",
      "Epoch 125/400\n",
      "402/402 [==============================] - ETA: 0s - loss: 0.0304 - mean_squared_error: 0.00 - 0s 55us/step - loss: 0.0353 - mean_squared_error: 0.0033\n",
      "Epoch 126/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0316 - mean_squared_error: 0.0028\n",
      "Epoch 127/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0337 - mean_squared_error: 0.0035\n",
      "Epoch 128/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0291 - mean_squared_error: 0.0037\n",
      "Epoch 129/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0317 - mean_squared_error: 0.0031\n",
      "Epoch 130/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0296 - mean_squared_error: 0.0030\n",
      "Epoch 131/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0345 - mean_squared_error: 0.0031\n",
      "Epoch 132/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0327 - mean_squared_error: 0.0032\n",
      "Epoch 133/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0321 - mean_squared_error: 0.0031\n",
      "Epoch 134/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0332 - mean_squared_error: 0.0028\n",
      "Epoch 135/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0307 - mean_squared_error: 0.0033\n",
      "Epoch 136/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0334 - mean_squared_error: 0.0028\n",
      "Epoch 137/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0339 - mean_squared_error: 0.0032\n",
      "Epoch 138/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0335 - mean_squared_error: 0.0032\n",
      "Epoch 139/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0330 - mean_squared_error: 0.0038\n",
      "Epoch 140/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0318 - mean_squared_error: 0.0031\n",
      "Epoch 141/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0237 - mean_squared_error: 0.0023\n",
      "Epoch 142/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0289 - mean_squared_error: 0.0027\n",
      "Epoch 143/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0254 - mean_squared_error: 0.0022\n",
      "Epoch 144/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 0s 60us/step - loss: 0.0347 - mean_squared_error: 0.0032\n",
      "Epoch 145/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0316 - mean_squared_error: 0.0028\n",
      "Epoch 146/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0323 - mean_squared_error: 0.0027\n",
      "Epoch 147/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0271 - mean_squared_error: 0.0024\n",
      "Epoch 148/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0294 - mean_squared_error: 0.0026\n",
      "Epoch 149/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0302 - mean_squared_error: 0.0026\n",
      "Epoch 150/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0285 - mean_squared_error: 0.0028\n",
      "Epoch 151/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0266 - mean_squared_error: 0.0026\n",
      "Epoch 152/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0283 - mean_squared_error: 0.0023\n",
      "Epoch 153/400\n",
      "402/402 [==============================] - 0s 68us/step - loss: 0.0285 - mean_squared_error: 0.0026\n",
      "Epoch 154/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0327 - mean_squared_error: 0.0027\n",
      "Epoch 155/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0276 - mean_squared_error: 0.0023\n",
      "Epoch 156/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0289 - mean_squared_error: 0.0025\n",
      "Epoch 157/400\n",
      "402/402 [==============================] - 0s 61us/step - loss: 0.0303 - mean_squared_error: 0.0029\n",
      "Epoch 158/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0278 - mean_squared_error: 0.0025\n",
      "Epoch 159/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0266 - mean_squared_error: 0.0018\n",
      "Epoch 160/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0281 - mean_squared_error: 0.0023\n",
      "Epoch 161/400\n",
      "402/402 [==============================] - 0s 58us/step - loss: 0.0279 - mean_squared_error: 0.0022\n",
      "Epoch 162/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0288 - mean_squared_error: 0.0023\n",
      "Epoch 163/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0269 - mean_squared_error: 0.0021\n",
      "Epoch 164/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0290 - mean_squared_error: 0.0024\n",
      "Epoch 165/400\n",
      "402/402 [==============================] - 0s 53us/step - loss: 0.0260 - mean_squared_error: 0.0019\n",
      "Epoch 166/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0265 - mean_squared_error: 0.0019\n",
      "Epoch 167/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0296 - mean_squared_error: 0.0029\n",
      "Epoch 168/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0276 - mean_squared_error: 0.0021\n",
      "Epoch 169/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0281 - mean_squared_error: 0.0021\n",
      "Epoch 170/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0314 - mean_squared_error: 0.0025\n",
      "Epoch 171/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0275 - mean_squared_error: 0.0020\n",
      "Epoch 172/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0238 - mean_squared_error: 0.0016\n",
      "Epoch 173/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0256 - mean_squared_error: 0.0019\n",
      "Epoch 174/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0277 - mean_squared_error: 0.0019\n",
      "Epoch 175/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0280 - mean_squared_error: 0.0021\n",
      "Epoch 176/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0282 - mean_squared_error: 0.0020\n",
      "Epoch 177/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0260 - mean_squared_error: 0.0017\n",
      "Epoch 178/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0273 - mean_squared_error: 0.0018\n",
      "Epoch 179/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0254 - mean_squared_error: 0.0019\n",
      "Epoch 180/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0292 - mean_squared_error: 0.0022\n",
      "Epoch 181/400\n",
      "402/402 [==============================] - 0s 50us/step - loss: 0.0243 - mean_squared_error: 0.0020\n",
      "Epoch 182/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0273 - mean_squared_error: 0.0023\n",
      "Epoch 183/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0281 - mean_squared_error: 0.0020\n",
      "Epoch 184/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0247 - mean_squared_error: 0.0016\n",
      "Epoch 185/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0276 - mean_squared_error: 0.0022\n",
      "Epoch 186/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0261 - mean_squared_error: 0.0017\n",
      "Epoch 187/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0219 - mean_squared_error: 0.0016\n",
      "Epoch 188/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0280 - mean_squared_error: 0.0023\n",
      "Epoch 189/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0253 - mean_squared_error: 0.0016\n",
      "Epoch 190/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0273 - mean_squared_error: 0.0022\n",
      "Epoch 191/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0268 - mean_squared_error: 0.0018\n",
      "Epoch 192/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0219 - mean_squared_error: 0.0015\n",
      "Epoch 193/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0245 - mean_squared_error: 0.0022\n",
      "Epoch 194/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0269 - mean_squared_error: 0.0018\n",
      "Epoch 195/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0228 - mean_squared_error: 0.0017\n",
      "Epoch 196/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0244 - mean_squared_error: 0.0019\n",
      "Epoch 197/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0271 - mean_squared_error: 0.0019\n",
      "Epoch 198/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0265 - mean_squared_error: 0.0019\n",
      "Epoch 199/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0277 - mean_squared_error: 0.0019\n",
      "Epoch 200/400\n",
      "402/402 [==============================] - 0s 50us/step - loss: 0.0263 - mean_squared_error: 0.0019\n",
      "Epoch 201/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0275 - mean_squared_error: 0.0019\n",
      "Epoch 202/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0261 - mean_squared_error: 0.0018\n",
      "Epoch 203/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0257 - mean_squared_error: 0.0018\n",
      "Epoch 204/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0250 - mean_squared_error: 0.0017\n",
      "Epoch 205/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0283 - mean_squared_error: 0.0023\n",
      "Epoch 206/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0250 - mean_squared_error: 0.0019\n",
      "Epoch 207/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0250 - mean_squared_error: 0.0015\n",
      "Epoch 208/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0285 - mean_squared_error: 0.0022\n",
      "Epoch 209/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0269 - mean_squared_error: 0.0018\n",
      "Epoch 210/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0263 - mean_squared_error: 0.0017\n",
      "Epoch 211/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0212 - mean_squared_error: 0.0014\n",
      "Epoch 212/400\n",
      "402/402 [==============================] - 0s 56us/step - loss: 0.0254 - mean_squared_error: 0.0019\n",
      "Epoch 213/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0268 - mean_squared_error: 0.0017\n",
      "Epoch 214/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0270 - mean_squared_error: 0.0018\n",
      "Epoch 215/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0236 - mean_squared_error: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0250 - mean_squared_error: 0.0016\n",
      "Epoch 217/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0231 - mean_squared_error: 0.0015\n",
      "Epoch 218/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0254 - mean_squared_error: 0.0017\n",
      "Epoch 219/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0240 - mean_squared_error: 0.0017\n",
      "Epoch 220/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0261 - mean_squared_error: 0.0020\n",
      "Epoch 221/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0252 - mean_squared_error: 0.0017\n",
      "Epoch 222/400\n",
      "402/402 [==============================] - 0s 50us/step - loss: 0.0214 - mean_squared_error: 0.0014\n",
      "Epoch 223/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0239 - mean_squared_error: 0.0018\n",
      "Epoch 224/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0237 - mean_squared_error: 0.0015\n",
      "Epoch 225/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0221 - mean_squared_error: 0.0015\n",
      "Epoch 226/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0255 - mean_squared_error: 0.0017\n",
      "Epoch 227/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0255 - mean_squared_error: 0.0018\n",
      "Epoch 228/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0253 - mean_squared_error: 0.0019\n",
      "Epoch 229/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0240 - mean_squared_error: 0.0017\n",
      "Epoch 230/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0274 - mean_squared_error: 0.0018\n",
      "Epoch 231/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.0265 - mean_squared_error: 0.0019\n",
      "Epoch 232/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0247 - mean_squared_error: 0.0017\n",
      "Epoch 233/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0238 - mean_squared_error: 0.0016\n",
      "Epoch 234/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0243 - mean_squared_error: 0.0019\n",
      "Epoch 235/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0251 - mean_squared_error: 0.0016\n",
      "Epoch 236/400\n",
      "402/402 [==============================] - 0s 72us/step - loss: 0.0253 - mean_squared_error: 0.0016\n",
      "Epoch 237/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0230 - mean_squared_error: 0.0014\n",
      "Epoch 238/400\n",
      "402/402 [==============================] - 0s 74us/step - loss: 0.0240 - mean_squared_error: 0.0016\n",
      "Epoch 239/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0220 - mean_squared_error: 0.0014\n",
      "Epoch 240/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0235 - mean_squared_error: 0.0016\n",
      "Epoch 241/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0233 - mean_squared_error: 0.0015\n",
      "Epoch 242/400\n",
      "402/402 [==============================] - 0s 74us/step - loss: 0.0222 - mean_squared_error: 0.0013\n",
      "Epoch 243/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0247 - mean_squared_error: 0.0016\n",
      "Epoch 244/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0236 - mean_squared_error: 0.0015\n",
      "Epoch 245/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0238 - mean_squared_error: 0.0015\n",
      "Epoch 246/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0223 - mean_squared_error: 0.0015\n",
      "Epoch 247/400\n",
      "402/402 [==============================] - 0s 77us/step - loss: 0.0237 - mean_squared_error: 0.0015\n",
      "Epoch 248/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.0225 - mean_squared_error: 0.0015\n",
      "Epoch 249/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0226 - mean_squared_error: 0.0013\n",
      "Epoch 250/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.0217 - mean_squared_error: 0.0013\n",
      "Epoch 251/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.0234 - mean_squared_error: 0.0015\n",
      "Epoch 252/400\n",
      "402/402 [==============================] - 0s 72us/step - loss: 0.0265 - mean_squared_error: 0.0018\n",
      "Epoch 253/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0232 - mean_squared_error: 0.0015\n",
      "Epoch 254/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0232 - mean_squared_error: 0.0017\n",
      "Epoch 255/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0230 - mean_squared_error: 0.0014\n",
      "Epoch 256/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0229 - mean_squared_error: 0.0013\n",
      "Epoch 257/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.0244 - mean_squared_error: 0.0015\n",
      "Epoch 258/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0228 - mean_squared_error: 0.0012\n",
      "Epoch 259/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0236 - mean_squared_error: 0.0014\n",
      "Epoch 260/400\n",
      "402/402 [==============================] - 0s 77us/step - loss: 0.0221 - mean_squared_error: 0.0013\n",
      "Epoch 261/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0220 - mean_squared_error: 0.0013\n",
      "Epoch 262/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0221 - mean_squared_error: 0.0014\n",
      "Epoch 263/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.0231 - mean_squared_error: 0.0015\n",
      "Epoch 264/400\n",
      "402/402 [==============================] - 0s 74us/step - loss: 0.0247 - mean_squared_error: 0.0016\n",
      "Epoch 265/400\n",
      "402/402 [==============================] - 0s 64us/step - loss: 0.0219 - mean_squared_error: 0.0013\n",
      "Epoch 266/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0244 - mean_squared_error: 0.0017\n",
      "Epoch 267/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0235 - mean_squared_error: 0.0014\n",
      "Epoch 268/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.0228 - mean_squared_error: 0.0014\n",
      "Epoch 269/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0211 - mean_squared_error: 0.0013\n",
      "Epoch 270/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0215 - mean_squared_error: 0.0014\n",
      "Epoch 271/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0228 - mean_squared_error: 0.0014\n",
      "Epoch 272/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.0248 - mean_squared_error: 0.0017\n",
      "Epoch 273/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0223 - mean_squared_error: 0.0013\n",
      "Epoch 274/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.0217 - mean_squared_error: 0.0013\n",
      "Epoch 275/400\n",
      "402/402 [==============================] - 0s 99us/step - loss: 0.0221 - mean_squared_error: 0.0014\n",
      "Epoch 276/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0202 - mean_squared_error: 0.0012\n",
      "Epoch 277/400\n",
      "402/402 [==============================] - 0s 74us/step - loss: 0.0216 - mean_squared_error: 0.0014\n",
      "Epoch 278/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.0213 - mean_squared_error: 0.0012\n",
      "Epoch 279/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0240 - mean_squared_error: 0.0015\n",
      "Epoch 280/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0221 - mean_squared_error: 0.0013\n",
      "Epoch 281/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0205 - mean_squared_error: 0.0013\n",
      "Epoch 282/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0243 - mean_squared_error: 0.0016\n",
      "Epoch 283/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0215 - mean_squared_error: 0.0011\n",
      "Epoch 284/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.0226 - mean_squared_error: 0.0013\n",
      "Epoch 285/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0222 - mean_squared_error: 0.0012\n",
      "Epoch 286/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0219 - mean_squared_error: 0.0011\n",
      "Epoch 287/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 0s 60us/step - loss: 0.0227 - mean_squared_error: 0.0014\n",
      "Epoch 288/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0228 - mean_squared_error: 0.0015\n",
      "Epoch 289/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0219 - mean_squared_error: 0.0014\n",
      "Epoch 290/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0210 - mean_squared_error: 0.0011\n",
      "Epoch 291/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0212 - mean_squared_error: 0.0014\n",
      "Epoch 292/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0219 - mean_squared_error: 0.0015\n",
      "Epoch 293/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0220 - mean_squared_error: 0.0014\n",
      "Epoch 294/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0222 - mean_squared_error: 0.0015\n",
      "Epoch 295/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0205 - mean_squared_error: 0.0011\n",
      "Epoch 296/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0223 - mean_squared_error: 0.0014\n",
      "Epoch 297/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0242 - mean_squared_error: 0.0015\n",
      "Epoch 298/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.0217 - mean_squared_error: 0.0015\n",
      "Epoch 299/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0209 - mean_squared_error: 0.0012\n",
      "Epoch 300/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0214 - mean_squared_error: 0.0014\n",
      "Epoch 301/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0215 - mean_squared_error: 0.0014\n",
      "Epoch 302/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0219 - mean_squared_error: 0.0013\n",
      "Epoch 303/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0222 - mean_squared_error: 0.0013\n",
      "Epoch 304/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0199 - mean_squared_error: 0.0012\n",
      "Epoch 305/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0214 - mean_squared_error: 0.0013\n",
      "Epoch 306/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0207 - mean_squared_error: 0.0012\n",
      "Epoch 307/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0202 - mean_squared_error: 0.0012\n",
      "Epoch 308/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0240 - mean_squared_error: 0.0014\n",
      "Epoch 309/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0230 - mean_squared_error: 0.0016\n",
      "Epoch 310/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0210 - mean_squared_error: 0.0014\n",
      "Epoch 311/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0231 - mean_squared_error: 0.0014\n",
      "Epoch 312/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0212 - mean_squared_error: 0.0012\n",
      "Epoch 313/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0218 - mean_squared_error: 0.0012\n",
      "Epoch 314/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0203 - mean_squared_error: 0.0011\n",
      "Epoch 315/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0222 - mean_squared_error: 0.0013\n",
      "Epoch 316/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0216 - mean_squared_error: 0.0014\n",
      "Epoch 317/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0205 - mean_squared_error: 0.0013\n",
      "Epoch 318/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.0226 - mean_squared_error: 0.0014\n",
      "Epoch 319/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0204 - mean_squared_error: 0.0011\n",
      "Epoch 320/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0178 - mean_squared_error: 0.0011\n",
      "Epoch 321/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.0183 - mean_squared_error: 0.0011\n",
      "Epoch 322/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0214 - mean_squared_error: 0.0012\n",
      "Epoch 323/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0207 - mean_squared_error: 0.0012\n",
      "Epoch 324/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0218 - mean_squared_error: 0.0012\n",
      "Epoch 325/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.0211 - mean_squared_error: 0.0013\n",
      "Epoch 326/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.0219 - mean_squared_error: 0.0014\n",
      "Epoch 327/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0198 - mean_squared_error: 0.0011\n",
      "Epoch 328/400\n",
      "402/402 [==============================] - 0s 50us/step - loss: 0.0203 - mean_squared_error: 0.0011\n",
      "Epoch 329/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0212 - mean_squared_error: 0.0013\n",
      "Epoch 330/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0161 - mean_squared_error: 8.8584e-04\n",
      "Epoch 331/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0209 - mean_squared_error: 0.0012\n",
      "Epoch 332/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0214 - mean_squared_error: 0.0011\n",
      "Epoch 333/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0199 - mean_squared_error: 0.0012\n",
      "Epoch 334/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0203 - mean_squared_error: 0.0014\n",
      "Epoch 335/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0206 - mean_squared_error: 0.0011\n",
      "Epoch 336/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0220 - mean_squared_error: 0.0012\n",
      "Epoch 337/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0204 - mean_squared_error: 0.0012\n",
      "Epoch 338/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0194 - mean_squared_error: 0.0010\n",
      "Epoch 339/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0221 - mean_squared_error: 0.0016\n",
      "Epoch 340/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0210 - mean_squared_error: 0.0013\n",
      "Epoch 341/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0198 - mean_squared_error: 0.0012\n",
      "Epoch 342/400\n",
      "402/402 [==============================] - 0s 50us/step - loss: 0.0182 - mean_squared_error: 9.7106e-04\n",
      "Epoch 343/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0207 - mean_squared_error: 0.0012\n",
      "Epoch 344/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0203 - mean_squared_error: 0.0014\n",
      "Epoch 345/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0183 - mean_squared_error: 9.5575e-04\n",
      "Epoch 346/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0205 - mean_squared_error: 0.0012\n",
      "Epoch 347/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0204 - mean_squared_error: 0.0013\n",
      "Epoch 348/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0205 - mean_squared_error: 0.0013\n",
      "Epoch 349/400\n",
      "402/402 [==============================] - 0s 66us/step - loss: 0.0211 - mean_squared_error: 0.0013\n",
      "Epoch 350/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0204 - mean_squared_error: 0.0013\n",
      "Epoch 351/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0206 - mean_squared_error: 0.0012\n",
      "Epoch 352/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0198 - mean_squared_error: 0.0012\n",
      "Epoch 353/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0197 - mean_squared_error: 0.0012\n",
      "Epoch 354/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0211 - mean_squared_error: 0.0012\n",
      "Epoch 355/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0196 - mean_squared_error: 0.0011\n",
      "Epoch 356/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0204 - mean_squared_error: 0.0012\n",
      "Epoch 357/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0193 - mean_squared_error: 9.9741e-04\n",
      "Epoch 358/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 0s 62us/step - loss: 0.0186 - mean_squared_error: 9.9490e-04\n",
      "Epoch 359/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0204 - mean_squared_error: 0.0012\n",
      "Epoch 360/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0198 - mean_squared_error: 0.0011\n",
      "Epoch 361/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0198 - mean_squared_error: 0.0010\n",
      "Epoch 362/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0211 - mean_squared_error: 0.0013\n",
      "Epoch 363/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0180 - mean_squared_error: 9.9172e-04\n",
      "Epoch 364/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0199 - mean_squared_error: 0.0012\n",
      "Epoch 365/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0194 - mean_squared_error: 0.0012\n",
      "Epoch 366/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0201 - mean_squared_error: 0.0012\n",
      "Epoch 367/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0201 - mean_squared_error: 0.0011\n",
      "Epoch 368/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0189 - mean_squared_error: 0.0011\n",
      "Epoch 369/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0200 - mean_squared_error: 0.0012\n",
      "Epoch 370/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0190 - mean_squared_error: 0.0011\n",
      "Epoch 371/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0198 - mean_squared_error: 0.0012\n",
      "Epoch 372/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0172 - mean_squared_error: 9.0037e-04\n",
      "Epoch 373/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0197 - mean_squared_error: 0.0011\n",
      "Epoch 374/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0193 - mean_squared_error: 0.0012\n",
      "Epoch 375/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0203 - mean_squared_error: 0.0012\n",
      "Epoch 376/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0208 - mean_squared_error: 0.0013\n",
      "Epoch 377/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0191 - mean_squared_error: 0.0010\n",
      "Epoch 378/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0197 - mean_squared_error: 0.0010\n",
      "Epoch 379/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0182 - mean_squared_error: 9.5266e-04\n",
      "Epoch 380/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0197 - mean_squared_error: 0.0011\n",
      "Epoch 381/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0205 - mean_squared_error: 0.0012\n",
      "Epoch 382/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0207 - mean_squared_error: 0.0015\n",
      "Epoch 383/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0160 - mean_squared_error: 8.6194e-04\n",
      "Epoch 384/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.0196 - mean_squared_error: 0.0012\n",
      "Epoch 385/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0195 - mean_squared_error: 0.0012\n",
      "Epoch 386/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.0195 - mean_squared_error: 0.0010\n",
      "Epoch 387/400\n",
      "402/402 [==============================] - 0s 71us/step - loss: 0.0197 - mean_squared_error: 0.0011\n",
      "Epoch 388/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0185 - mean_squared_error: 9.7317e-04\n",
      "Epoch 389/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.0198 - mean_squared_error: 0.0010\n",
      "Epoch 390/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0188 - mean_squared_error: 0.0010\n",
      "Epoch 391/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0190 - mean_squared_error: 0.0010\n",
      "Epoch 392/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0196 - mean_squared_error: 0.0013\n",
      "Epoch 393/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.0202 - mean_squared_error: 0.0012\n",
      "Epoch 394/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0187 - mean_squared_error: 0.0011\n",
      "Epoch 395/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0188 - mean_squared_error: 0.0010\n",
      "Epoch 396/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.0180 - mean_squared_error: 9.4140e-04\n",
      "Epoch 397/400\n",
      "402/402 [==============================] - 0s 63us/step - loss: 0.0187 - mean_squared_error: 0.0010\n",
      "Epoch 398/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0187 - mean_squared_error: 0.0010\n",
      "Epoch 399/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.0189 - mean_squared_error: 9.5970e-04\n",
      "Epoch 400/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.0198 - mean_squared_error: 0.0012\n",
      "402/402 [==============================] - 0s 109us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.024723392193071285, 0.0012953333207406104]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 1: build the model\n",
    "model = Sequential()\n",
    "#input layer\n",
    "model.add(Dense(10, input_dim = 21, activation = 'sigmoid'))\n",
    "#hidden layers\n",
    "\n",
    "model.add(Dense(6, activation = 'relu'))\n",
    "model.add(Dense(3, activation = 'relu'))\n",
    "#output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "#step 2: build the computational graph - compile\n",
    "model.compile(loss = 'mae', optimizer = 'sgd', metrics = ['mse'])\n",
    "\n",
    "#step 3: train the model\n",
    "model.fit(X_train, y_train, epochs = 400, batch_size= 20)\n",
    "\n",
    "#step 4: evaluate\n",
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[63  0]\n",
      " [ 0 72]]\n",
      "Accuracy :\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "for i in range(len(pred)):\n",
    "    if pred[i,0]>=0.5:\n",
    "        pred[i,0]=1\n",
    "    else:\n",
    "        pred[i,0]=0\n",
    "Accuracy=statistics.mean(y_test==pred[:,0])*100\n",
    "confusion = confusion_matrix(y_test, pred[:,0])\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))\n",
    "print(\"Accuracy :\\n{}\".format(Accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Audit_Risk']\n",
    "X=data.drop(['Audit_Risk'],axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector_score</th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>Score_A</th>\n",
       "      <th>Risk_A</th>\n",
       "      <th>PARA_B</th>\n",
       "      <th>Score_B</th>\n",
       "      <th>Risk_B</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>numbers</th>\n",
       "      <th>Score_B.1</th>\n",
       "      <th>...</th>\n",
       "      <th>Score_MV</th>\n",
       "      <th>Risk_D</th>\n",
       "      <th>RiSk_E</th>\n",
       "      <th>History</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Score</th>\n",
       "      <th>Inherent_Risk</th>\n",
       "      <th>CONTROL_RISK</th>\n",
       "      <th>Risk</th>\n",
       "      <th>MONEY_Marks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.89</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.508</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500</td>\n",
       "      <td>6.68</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>8.574</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.83</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.966</td>\n",
       "      <td>4.83</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.554</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.89</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.74</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.548</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.80</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.480</td>\n",
       "      <td>10.80</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.050</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>17.530</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.416</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sector_score  PARA_A  Score_A  Risk_A  PARA_B  Score_B  Risk_B  TOTAL  \\\n",
       "0          3.89    4.18      0.6   2.508    2.50      0.2   0.500   6.68   \n",
       "1          3.89    0.00      0.2   0.000    4.83      0.2   0.966   4.83   \n",
       "2          3.89    0.51      0.2   0.102    0.23      0.2   0.046   0.74   \n",
       "3          3.89    0.00      0.2   0.000   10.80      0.6   6.480  10.80   \n",
       "4          3.89    0.00      0.2   0.000    0.08      0.2   0.016   0.08   \n",
       "\n",
       "   numbers  Score_B.1     ...       Score_MV  Risk_D  RiSk_E  History  Prob  \\\n",
       "0      5.0        0.2     ...            0.2   0.676     0.4        0   0.2   \n",
       "1      5.0        0.2     ...            0.2   0.188     0.4        0   0.2   \n",
       "2      5.0        0.2     ...            0.2   0.000     0.4        0   0.2   \n",
       "3      6.0        0.6     ...            0.6   7.050     0.4        0   0.2   \n",
       "4      5.0        0.2     ...            0.2   0.000     0.4        0   0.2   \n",
       "\n",
       "   Score  Inherent_Risk  CONTROL_RISK  Risk  MONEY_Marks  \n",
       "0    2.4          8.574           0.4     1            2  \n",
       "1    2.0          2.554           0.4     0            2  \n",
       "2    2.0          1.548           0.4     0            2  \n",
       "3    4.4         17.530           0.4     1            6  \n",
       "4    2.0          1.416           0.4     0            2  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_dt, X_test_dt, y_train, y_test = train_test_split(X,y,random_state=0,)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MinMaxScaler perserves the shape of orginal distribution. It doesn't change the information embedded in the orginal data. Since we already removed the outliers 4 standard deviations away from mean in the previous step, we wanted to preserve the remaining far values and variance in data as it is, to better predict the unknown data set with its variances. Standard scaler simply brings the mean of variables to zero with standard deviation 1 thereby changing the original distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler= MinMaxScaler()\n",
    "X_train = Scaler.fit_transform(X_train_dt)\n",
    "X_test = Scaler.transform(X_test_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with Bagging "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'max_depth': 5}\n",
      "Best score:  0.9245580321076733\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "#model param\n",
    "grid_param = {'max_depth':[1,2,3,4,5,6,7]}\n",
    "\n",
    "#grid model\n",
    "grid_search = GridSearchCV(dtree, grid_param, cv = 5, n_jobs  = -1)\n",
    "\n",
    "#train grid model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Best params: ', grid_search.best_params_)\n",
    "print('Best score: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "score=[]\n",
    "for i in range(len(grid_search.grid_scores_)):\n",
    "    score.append(grid_search.grid_scores_[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Max Depth')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig ,ax= plt.subplots(figsize = (15,5))\n",
    "plt.plot(range(1,8), score, c = 'g', label = 'Cross Validation Score')\n",
    "plt.legend(loc = 3)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Max Depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.90\n",
      "Test score: 0.83\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.metrics import accuracy_score\n",
    "dtree = DecisionTreeRegressor(max_depth=5, random_state=0)\n",
    "bag= BaggingRegressor(dtree, n_estimators=500,max_samples=100, bootstrap=True, random_state=0)\n",
    "bag.fit(X_train, y_train)\n",
    "y_pred = bag.predict(X_test)\n",
    "print('Train score: {:.2f}'.format(bag.score(X_train, y_train)))\n",
    "print('Test score: {:.2f}'.format(bag.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN Regressor Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_neighbors': 2}\n",
      "Best cross-validation score: 0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "param_grid = {'n_neighbors': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]}\n",
    "knn = KNeighborsRegressor()\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "score=[]\n",
    "for i in range(len(grid_search.grid_scores_)):\n",
    "    score.append(grid_search.grid_scores_[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'K Neighbors')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig ,ax= plt.subplots(figsize = (15,5))\n",
    "plt.plot(range(1,21), score, c = 'g', label = 'Cross Validation Score')\n",
    "plt.legend(loc = 3)\n",
    "plt.grid(True)\n",
    "plt.xlabel('K Neighbors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: 0.7603405505469605\n",
      "Test scores: 0.6876984040147497\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(2)\n",
    "bag= BaggingRegressor(knn, n_estimators=500,max_samples=100, bootstrap=True, random_state=0)\n",
    "bag.fit(X_train, y_train)\n",
    "print(\"Train scores: {}\".format(bag.score(X_train, y_train)))\n",
    "print(\"Test scores: {}\".format(bag.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'C': 300, 'gamma': 0.1}\n",
      "Best score:  0.9755069896328408\n"
     ]
    }
   ],
   "source": [
    "svr_rbf = SVR(kernel='rbf',epsilon=.1)\n",
    "\n",
    "#model param\n",
    "grid_param = {'C':[1,10,100,200,300],'gamma':[0.01,0.1,1,5]}\n",
    "\n",
    "#grid model\n",
    "grid_search = GridSearchCV(svr_rbf, grid_param, cv = 5, n_jobs  = -1)\n",
    "\n",
    "#train grid model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Best params: ', grid_search.best_params_)\n",
    "print('Best score: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=[]\n",
    "c_range = [1,10,100,200,300]\n",
    "g_range = [0.01,0.1,1,5]\n",
    "\n",
    "for x in c_range:\n",
    "    for g in g_range:\n",
    "        index.append((x,g))\n",
    "        \n",
    "score=[]\n",
    "for i in range(len(grid_search.grid_scores_)):\n",
    "    score.append(grid_search.grid_scores_[i][1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'C and Gamma')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig ,ax= plt.subplots(figsize = (15,5))\n",
    "plt.plot(range(len(index)), score, c = 'g', label = 'Cross Validation Score')\n",
    "plt.legend(loc = 3)\n",
    "plt.grid(True)\n",
    "plt.xticks(range(len(index)), index, rotation=90)\n",
    "plt.xlabel(r'C and Gamma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: 0.9493406391849555\n",
      "Test scores: 0.9061240319741178\n"
     ]
    }
   ],
   "source": [
    "svr_rbf = SVR(kernel='rbf', C=300, gamma=0.1, epsilon=.1)\n",
    "bag= BaggingRegressor(svr_rbf, n_estimators=500,max_samples=100, bootstrap=False, random_state=0)\n",
    "bag.fit(X_train, y_train)\n",
    "print(\"Train scores: {}\".format(bag.score(X_train, y_train)))\n",
    "print(\"Test scores: {}\".format(bag.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Pasting - Best Parameters from previous Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.92\n",
      "Test score: 0.85\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.metrics import accuracy_score\n",
    "dtree = DecisionTreeRegressor(max_depth=5, random_state=0)\n",
    "bag= BaggingRegressor(dtree, n_estimators=500,max_samples=100, bootstrap=False, random_state=0)\n",
    "bag.fit(X_train, y_train)\n",
    "y_pred = bag.predict(X_test)\n",
    "print('Train score: {:.2f}'.format(bag.score(X_train, y_train)))\n",
    "print('Test score: {:.2f}'.format(bag.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaboost-Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.8562646773556435\n",
      "Best Paramters:  {'learning_rate': 0.1, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "#base model\n",
    "ridge_reg = Ridge(random_state = 0)\n",
    "ada_reg = AdaBoostRegressor(ridge_reg)\n",
    "\n",
    "#grid param\n",
    "grid_param = {'n_estimators': [10,100,200,300,400,500],\n",
    "             'learning_rate' : [0.1, 0.5, 1]}\n",
    "\n",
    "#grid model\n",
    "grid_search = GridSearchCV(ada_reg, grid_param, cv = 5, return_train_score=True)\n",
    "\n",
    "#train grid model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#grid model evaluation\n",
    "print(\"Best Score: \",grid_search.best_score_)\n",
    "\n",
    "print(\"Best Paramters: \", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.89\n",
      "Test score: 0.90\n"
     ]
    }
   ],
   "source": [
    "ada_reg = AdaBoostRegressor(Ridge(random_state=0), n_estimators=10, learning_rate=0.1, random_state=0)\n",
    "ada_reg.fit(X_train, y_train)\n",
    "print('Train score: {:.2f}'.format(ada_reg.score(X_train, y_train)))\n",
    "print('Test score: {:.2f}'.format(ada_reg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost SVC Kernel Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'C': 100}\n",
      "Best score:  0.8054734359700395\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svr_lin = SVR(kernel='linear')\n",
    "\n",
    "#model param\n",
    "grid_param = {'C':[1,10,100,200,300]}\n",
    "\n",
    "#grid model\n",
    "grid_search = GridSearchCV(svr_lin, grid_param, cv = 5, n_jobs  = -1)\n",
    "\n",
    "#train grid model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Best params: ', grid_search.best_params_)\n",
    "print('Best score: ', grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.84\n",
      "Test score: 0.88\n"
     ]
    }
   ],
   "source": [
    "ada_reg = AdaBoostRegressor(SVR(kernel='linear',C=100), n_estimators=10, learning_rate=0.1, random_state=0)\n",
    "ada_reg.fit(X_train, y_train)\n",
    "print('Train score: {:.2f}'.format(ada_reg.score(X_train, y_train)))\n",
    "print('Test score: {:.2f}'.format(ada_reg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "Best score:  0.9687621015473706\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "#model param\n",
    "grid_param = {'learning_rate':[1,0.5,0.25,0.1,0.05], 'max_depth':[1,2,3,4,5], 'n_estimators':[1,5,10,20,30,50,100]}\n",
    "\n",
    "#grid model\n",
    "grid_search = GridSearchCV(gbrt, grid_param, cv = 5, n_jobs  = -1)\n",
    "\n",
    "#train grid model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Best params: ', grid_search.best_params_)\n",
    "print('Best score: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.00\n",
      "Test score: 0.96\n"
     ]
    }
   ],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth=3, n_estimators=100, learning_rate=0.1, random_state=0)\n",
    "gbrt.fit(X_train, y_train)\n",
    "print('Train score: {:.2f}'.format(gbrt.score(X_train, y_train)))\n",
    "print('Test score: {:.2f}'.format(gbrt.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(402, 22)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "pca = PCA()\n",
    "#train\n",
    "pca.fit(X_train)\n",
    "#transform\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components = 0.95)\n",
    "pca.fit(X_train)\n",
    "X_train_reduced = pca.transform(X_train)\n",
    "X_test_reduced = pca.transform(X_test)\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96651881, 0.19200345, 0.15042489, 0.12899541, 0.09849201,\n",
       "       0.08365935, 0.06035038, 0.04274751])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing regression results from previous project file to draw comparision between non-PCA model and PCA model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>PCA</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.905049</td>\n",
       "      <td>0.916381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.894074</td>\n",
       "      <td>0.905362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LassoRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.866539</td>\n",
       "      <td>0.902303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGDRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>-7.111675</td>\n",
       "      <td>-6.965662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PolyRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNNRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.951087</td>\n",
       "      <td>0.645903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVR</td>\n",
       "      <td>without</td>\n",
       "      <td>0.473188</td>\n",
       "      <td>0.465114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVR_RBF</td>\n",
       "      <td>without</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>0.969262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVR_Linear</td>\n",
       "      <td>without</td>\n",
       "      <td>0.788536</td>\n",
       "      <td>0.829035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR_Poly</td>\n",
       "      <td>without</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>0.999520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model      PCA     Train      Test\n",
       "0  LinearRegression  without  0.905049  0.916381\n",
       "1   RidgeRegression  without  0.894074  0.905362\n",
       "2   LassoRegression  without  0.866539  0.902303\n",
       "3     SGDRegression  without -7.111675 -6.965662\n",
       "4    PolyRegression  without  1.000000  1.000000\n",
       "5     KNNRegression  without  0.951087  0.645903\n",
       "6               SVR  without  0.473188  0.465114\n",
       "7           SVR_RBF  without  0.999681  0.969262\n",
       "8        SVR_Linear  without  0.788536  0.829035\n",
       "9          SVR_Poly  without  0.999935  0.999520"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv('RegressionResults.csv')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: 0.7686975851819471\n",
      "Test scores: 0.7574485393164948\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lreg = LinearRegression()\n",
    "lreg.fit(X_train_reduced, y_train)\n",
    "print(\"Train scores: {}\".format(lreg.score(X_train_reduced, y_train)))\n",
    "print(\"Test scores: {}\".format(lreg.score(X_test_reduced, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>PCA</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.905049</td>\n",
       "      <td>0.916381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768698</td>\n",
       "      <td>0.757449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RidgeRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.894074</td>\n",
       "      <td>0.905362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LassoRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.866539</td>\n",
       "      <td>0.902303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGDRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>-7.111675</td>\n",
       "      <td>-6.965662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PolyRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNNRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.951087</td>\n",
       "      <td>0.645903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVR</td>\n",
       "      <td>without</td>\n",
       "      <td>0.473188</td>\n",
       "      <td>0.465114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVR_RBF</td>\n",
       "      <td>without</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>0.969262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR_Linear</td>\n",
       "      <td>without</td>\n",
       "      <td>0.788536</td>\n",
       "      <td>0.829035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVR_Poly</td>\n",
       "      <td>without</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>0.999520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model      PCA     Train      Test\n",
       "0   LinearRegression  without  0.905049  0.916381\n",
       "1   LinearRegression     with  0.768698  0.757449\n",
       "2    RidgeRegression  without  0.894074  0.905362\n",
       "3    LassoRegression  without  0.866539  0.902303\n",
       "4      SGDRegression  without -7.111675 -6.965662\n",
       "5     PolyRegression  without  1.000000  1.000000\n",
       "6      KNNRegression  without  0.951087  0.645903\n",
       "7                SVR  without  0.473188  0.465114\n",
       "8            SVR_RBF  without  0.999681  0.969262\n",
       "9         SVR_Linear  without  0.788536  0.829035\n",
       "10          SVR_Poly  without  0.999935  0.999520"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = pd.DataFrame({'Model':\"LinearRegression\" , 'PCA': \"with\", 'Train': lreg.score(X_train_reduced, y_train),'Test':lreg.score(X_test_reduced, y_test)}, index=[0.5])\n",
    "results=results.append(line, ignore_index=False)\n",
    "results = results.sort_index().reset_index(drop=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression train and test score worsens significantly after PCA . It is clear that PCA results in loss of variation(information) in data while modelling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge Regression with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'alpha': 0.1}\n",
      "Best score:  0.7502257986122572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge=Ridge()\n",
    "\n",
    "#model param\n",
    "grid_param = {'alpha':[0.001,0.01,0.1,1,10,100]}\n",
    "\n",
    "#grid model\n",
    "grid_search = GridSearchCV(ridge, grid_param, cv = 5, n_jobs  = -1)\n",
    "\n",
    "#train grid model\n",
    "grid_search.fit(X_train_reduced, y_train)\n",
    "\n",
    "print('Best params: ', grid_search.best_params_)\n",
    "print('Best score: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.7683\n",
      "Test score: 0.7570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>PCA</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.905049</td>\n",
       "      <td>0.916381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768698</td>\n",
       "      <td>0.757449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RidgeRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.894074</td>\n",
       "      <td>0.905362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RidgeRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768290</td>\n",
       "      <td>0.757020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LassoRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.866539</td>\n",
       "      <td>0.902303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGDRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>-7.111675</td>\n",
       "      <td>-6.965662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PolyRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNNRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.951087</td>\n",
       "      <td>0.645903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVR</td>\n",
       "      <td>without</td>\n",
       "      <td>0.473188</td>\n",
       "      <td>0.465114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR_RBF</td>\n",
       "      <td>without</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>0.969262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVR_Linear</td>\n",
       "      <td>without</td>\n",
       "      <td>0.788536</td>\n",
       "      <td>0.829035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVR_Poly</td>\n",
       "      <td>without</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>0.999520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model      PCA     Train      Test\n",
       "0   LinearRegression  without  0.905049  0.916381\n",
       "1   LinearRegression     with  0.768698  0.757449\n",
       "2    RidgeRegression  without  0.894074  0.905362\n",
       "3    RidgeRegression     with  0.768290  0.757020\n",
       "4    LassoRegression  without  0.866539  0.902303\n",
       "5      SGDRegression  without -7.111675 -6.965662\n",
       "6     PolyRegression  without  1.000000  1.000000\n",
       "7      KNNRegression  without  0.951087  0.645903\n",
       "8                SVR  without  0.473188  0.465114\n",
       "9            SVR_RBF  without  0.999681  0.969262\n",
       "10        SVR_Linear  without  0.788536  0.829035\n",
       "11          SVR_Poly  without  0.999935  0.999520"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge(alpha = 1)\n",
    "ridge.fit(X_train_reduced,y_train)\n",
    "print('Train score: {:.4f}'.format(ridge.score(X_train_reduced,y_train)))\n",
    "print('Test score: {:.4f}'.format(ridge.score(X_test_reduced, y_test)))\n",
    "\n",
    "line = pd.DataFrame({'Model':\"RidgeRegression\" , 'PCA': \"with\", 'Train': ridge.score(X_train_reduced, y_train),'Test':ridge.score(X_test_reduced, y_test)}, index=[2.5])\n",
    "results=results.append(line, ignore_index=False)\n",
    "results = results.sort_index().reset_index(drop=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression train and test score worsens significantly after PCA . It is clear that PCA results in loss of variation(information) in data while modelling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso Regression with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'alpha': 0.01}\n",
      "Best score:  0.7513247684936506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso=Lasso()\n",
    "\n",
    "#model param\n",
    "grid_param = {'alpha':[0.000001,0.00001,0.0001,0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "#grid model\n",
    "grid_search = GridSearchCV(lasso, grid_param, cv = 5, n_jobs  = -1)\n",
    "\n",
    "#train grid model\n",
    "grid_search.fit(X_train_reduced, y_train)\n",
    "\n",
    "print('Best params: ', grid_search.best_params_)\n",
    "print('Best score: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.7686\n",
      "Test score: 0.7580\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>PCA</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.905049</td>\n",
       "      <td>0.916381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768698</td>\n",
       "      <td>0.757449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RidgeRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.894074</td>\n",
       "      <td>0.905362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RidgeRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768290</td>\n",
       "      <td>0.757020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LassoRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.866539</td>\n",
       "      <td>0.902303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LassoRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768583</td>\n",
       "      <td>0.757975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGDRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>-7.111675</td>\n",
       "      <td>-6.965662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PolyRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNNRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.951087</td>\n",
       "      <td>0.645903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>without</td>\n",
       "      <td>0.473188</td>\n",
       "      <td>0.465114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVR_RBF</td>\n",
       "      <td>without</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>0.969262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVR_Linear</td>\n",
       "      <td>without</td>\n",
       "      <td>0.788536</td>\n",
       "      <td>0.829035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVR_Poly</td>\n",
       "      <td>without</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>0.999520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model      PCA     Train      Test\n",
       "0   LinearRegression  without  0.905049  0.916381\n",
       "1   LinearRegression     with  0.768698  0.757449\n",
       "2    RidgeRegression  without  0.894074  0.905362\n",
       "3    RidgeRegression     with  0.768290  0.757020\n",
       "4    LassoRegression  without  0.866539  0.902303\n",
       "5    LassoRegression     with  0.768583  0.757975\n",
       "6      SGDRegression  without -7.111675 -6.965662\n",
       "7     PolyRegression  without  1.000000  1.000000\n",
       "8      KNNRegression  without  0.951087  0.645903\n",
       "9                SVR  without  0.473188  0.465114\n",
       "10           SVR_RBF  without  0.999681  0.969262\n",
       "11        SVR_Linear  without  0.788536  0.829035\n",
       "12          SVR_Poly  without  0.999935  0.999520"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso(alpha = 0.01)\n",
    "lasso.fit(X_train_reduced,y_train)\n",
    "print('Train score: {:.4f}'.format(lasso.score(X_train_reduced,y_train)))\n",
    "print('Test score: {:.4f}'.format(lasso.score(X_test_reduced, y_test)))\n",
    "\n",
    "line = pd.DataFrame({'Model':\"LassoRegression\" , 'PCA': \"with\", 'Train': lasso.score(X_train_reduced, y_train),'Test':lasso.score(X_test_reduced, y_test)}, index=[4.5])\n",
    "results=results.append(line, ignore_index=False)\n",
    "results = results.sort_index().reset_index(drop=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression train and test score worsens significantly after PCA at 0.95 . It is clear that PCA results in loss of variation(information) in data while modelling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'alpha': 0.04}\n",
      "Best score:  0.7525456439862623\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd_reg = SGDRegressor(random_state=0, max_iter=100000, learning_rate='optimal', penalty='l1')\n",
    "\n",
    "#model param\n",
    "grid_param = {'alpha':[0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.2]}\n",
    "\n",
    "#grid model\n",
    "grid_search = GridSearchCV(sgd_reg, grid_param, cv = 5, n_jobs  = -1)\n",
    "\n",
    "#train grid model\n",
    "grid_search.fit(X_train_reduced, y_train)\n",
    "\n",
    "print('Best params: ', grid_search.best_params_)\n",
    "print('Best score: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.7672\n",
      "Test score: 0.7573\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>PCA</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.905049</td>\n",
       "      <td>0.916381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768698</td>\n",
       "      <td>0.757449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RidgeRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.894074</td>\n",
       "      <td>0.905362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RidgeRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768290</td>\n",
       "      <td>0.757020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LassoRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.866539</td>\n",
       "      <td>0.902303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LassoRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768583</td>\n",
       "      <td>0.757975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGDRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>-7.111675</td>\n",
       "      <td>-6.965662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGDRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.767191</td>\n",
       "      <td>0.757326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PolyRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNNRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.951087</td>\n",
       "      <td>0.645903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVR</td>\n",
       "      <td>without</td>\n",
       "      <td>0.473188</td>\n",
       "      <td>0.465114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVR_RBF</td>\n",
       "      <td>without</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>0.969262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVR_Linear</td>\n",
       "      <td>without</td>\n",
       "      <td>0.788536</td>\n",
       "      <td>0.829035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVR_Poly</td>\n",
       "      <td>without</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>0.999520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model      PCA     Train      Test\n",
       "0   LinearRegression  without  0.905049  0.916381\n",
       "1   LinearRegression     with  0.768698  0.757449\n",
       "2    RidgeRegression  without  0.894074  0.905362\n",
       "3    RidgeRegression     with  0.768290  0.757020\n",
       "4    LassoRegression  without  0.866539  0.902303\n",
       "5    LassoRegression     with  0.768583  0.757975\n",
       "6      SGDRegression  without -7.111675 -6.965662\n",
       "7      SGDRegression     with  0.767191  0.757326\n",
       "8     PolyRegression  without  1.000000  1.000000\n",
       "9      KNNRegression  without  0.951087  0.645903\n",
       "10               SVR  without  0.473188  0.465114\n",
       "11           SVR_RBF  without  0.999681  0.969262\n",
       "12        SVR_Linear  without  0.788536  0.829035\n",
       "13          SVR_Poly  without  0.999935  0.999520"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_reg = SGDRegressor(random_state=0, max_iter=100000, alpha=0.04, learning_rate='optimal', penalty='l1')\n",
    "sgd_reg.fit(X_train_reduced, y_train)\n",
    "print('Train score: {:.4f}'.format(sgd_reg.score(X_train_reduced,y_train)))\n",
    "print('Test score: {:.4f}'.format(sgd_reg.score(X_test_reduced, y_test)))\n",
    "\n",
    "line = pd.DataFrame({'Model':\"SGDRegression\" , 'PCA': \"with\", 'Train': sgd_reg.score(X_train_reduced, y_train),'Test':sgd_reg.score(X_test_reduced, y_test)}, index=[6.5])\n",
    "results=results.append(line, ignore_index=False)\n",
    "results = results.sort_index().reset_index(drop=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Regression train and test score shoots up significantly after PCA at 0.95 . PCA helps the model capture essential variation and transforms it from performing worse than Naive model to significantly better than Naive model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poly Regression with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.7501923692024967\n",
      "Best Paramters:  {'polynomialfeatures__degree': 1}\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.preprocessing  import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree), LinearRegression(**kwargs))\n",
    "\n",
    "param_grid = {'polynomialfeatures__degree': [1,2,3,4]}\n",
    "\n",
    "poly_grid = GridSearchCV(PolynomialRegression(), param_grid, cv = 5, return_train_score=True)\n",
    "\n",
    "poly_grid.fit(X_train_reduced, y_train)\n",
    "\n",
    "print(\"Best Score: \",poly_grid.best_score_)\n",
    "\n",
    "print(\"Best Paramters: \", poly_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: 0.7686975851819471\n",
      "Test scores: 0.7574485393164946\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>PCA</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.905049</td>\n",
       "      <td>0.916381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768698</td>\n",
       "      <td>0.757449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RidgeRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.894074</td>\n",
       "      <td>0.905362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RidgeRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768290</td>\n",
       "      <td>0.757020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LassoRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.866539</td>\n",
       "      <td>0.902303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LassoRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768583</td>\n",
       "      <td>0.757975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGDRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>-7.111675</td>\n",
       "      <td>-6.965662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGDRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.767191</td>\n",
       "      <td>0.757326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PolyRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PolyRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768698</td>\n",
       "      <td>0.757449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNNRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.951087</td>\n",
       "      <td>0.645903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVR</td>\n",
       "      <td>without</td>\n",
       "      <td>0.473188</td>\n",
       "      <td>0.465114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVR_RBF</td>\n",
       "      <td>without</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>0.969262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVR_Linear</td>\n",
       "      <td>without</td>\n",
       "      <td>0.788536</td>\n",
       "      <td>0.829035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVR_Poly</td>\n",
       "      <td>without</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>0.999520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model      PCA     Train      Test\n",
       "0   LinearRegression  without  0.905049  0.916381\n",
       "1   LinearRegression     with  0.768698  0.757449\n",
       "2    RidgeRegression  without  0.894074  0.905362\n",
       "3    RidgeRegression     with  0.768290  0.757020\n",
       "4    LassoRegression  without  0.866539  0.902303\n",
       "5    LassoRegression     with  0.768583  0.757975\n",
       "6      SGDRegression  without -7.111675 -6.965662\n",
       "7      SGDRegression     with  0.767191  0.757326\n",
       "8     PolyRegression  without  1.000000  1.000000\n",
       "9     PolyRegression     with  0.768698  0.757449\n",
       "10     KNNRegression  without  0.951087  0.645903\n",
       "11               SVR  without  0.473188  0.465114\n",
       "12           SVR_RBF  without  0.999681  0.969262\n",
       "13        SVR_Linear  without  0.788536  0.829035\n",
       "14          SVR_Poly  without  0.999935  0.999520"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  sklearn.preprocessing  import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(1)\n",
    "X_train_poly = poly.fit_transform(X_train_reduced)\n",
    "X_test_poly = poly.transform(X_test_reduced)\n",
    "lreg = LinearRegression()\n",
    "lreg.fit(X_train_poly, y_train)\n",
    "print(\"Train scores: {}\".format(lreg.score(X_train_poly, y_train)))\n",
    "print(\"Test scores: {}\".format(lreg.score(X_test_poly, y_test)))\n",
    "\n",
    "line = pd.DataFrame({'Model':\"PolyRegression\" , 'PCA': \"with\", 'Train': lreg.score(X_train_poly, y_train),'Test':lreg.score(X_test_poly, y_test)}, index=[8.5])\n",
    "results=results.append(line, ignore_index=False)\n",
    "results = results.sort_index().reset_index(drop=True)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression train and test score worsens significantly after PCA at 0.95 , it bring dows the perfect scor to approximately 75% for train and test score. It is clear that PCA results in loss of variation(information) in data while modelling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN Regressor with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'n_neighbors': 3}\n",
      "Best score:  0.7342539327302701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "#model param\n",
    "grid_param = {'n_neighbors':[1,2,3,4,5,6,7,8,9,10]}\n",
    "\n",
    "#grid model\n",
    "grid_search = GridSearchCV(knn, grid_param, cv = 5, n_jobs  = -1)\n",
    "\n",
    "#train grid model\n",
    "grid_search.fit(X_train_reduced, y_train)\n",
    "\n",
    "print('Best params: ', grid_search.best_params_)\n",
    "print('Best score: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8616\n",
      "Test score: 0.6519\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>PCA</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.905049</td>\n",
       "      <td>0.916381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768698</td>\n",
       "      <td>0.757449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RidgeRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.894074</td>\n",
       "      <td>0.905362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RidgeRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768290</td>\n",
       "      <td>0.757020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LassoRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.866539</td>\n",
       "      <td>0.902303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LassoRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768583</td>\n",
       "      <td>0.757975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGDRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>-7.111675</td>\n",
       "      <td>-6.965662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGDRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.767191</td>\n",
       "      <td>0.757326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PolyRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PolyRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768698</td>\n",
       "      <td>0.757449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNNRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.951087</td>\n",
       "      <td>0.645903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNNRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.861643</td>\n",
       "      <td>0.651891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVR</td>\n",
       "      <td>without</td>\n",
       "      <td>0.473188</td>\n",
       "      <td>0.465114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVR_RBF</td>\n",
       "      <td>without</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>0.969262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVR_Linear</td>\n",
       "      <td>without</td>\n",
       "      <td>0.788536</td>\n",
       "      <td>0.829035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVR_Poly</td>\n",
       "      <td>without</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>0.999520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model      PCA     Train      Test\n",
       "0   LinearRegression  without  0.905049  0.916381\n",
       "1   LinearRegression     with  0.768698  0.757449\n",
       "2    RidgeRegression  without  0.894074  0.905362\n",
       "3    RidgeRegression     with  0.768290  0.757020\n",
       "4    LassoRegression  without  0.866539  0.902303\n",
       "5    LassoRegression     with  0.768583  0.757975\n",
       "6      SGDRegression  without -7.111675 -6.965662\n",
       "7      SGDRegression     with  0.767191  0.757326\n",
       "8     PolyRegression  without  1.000000  1.000000\n",
       "9     PolyRegression     with  0.768698  0.757449\n",
       "10     KNNRegression  without  0.951087  0.645903\n",
       "11     KNNRegression     with  0.861643  0.651891\n",
       "12               SVR  without  0.473188  0.465114\n",
       "13           SVR_RBF  without  0.999681  0.969262\n",
       "14        SVR_Linear  without  0.788536  0.829035\n",
       "15          SVR_Poly  without  0.999935  0.999520"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(3)\n",
    "knn.fit(X_train_reduced,y_train)\n",
    "print('Train score: {:.4f}'.format(knn.score(X_train_reduced,y_train)))\n",
    "print('Test score: {:.4f}'.format(knn.score(X_test_reduced, y_test)))\n",
    "\n",
    "line = pd.DataFrame({'Model':\"KNNRegression\" , 'PCA': \"with\", 'Train': knn.score(X_train_reduced, y_train),'Test':knn.score(X_test_reduced, y_test)}, index=[10.5])\n",
    "results=results.append(line, ignore_index=False)\n",
    "results = results.sort_index().reset_index(drop=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Regression train score worsens slightly and test score remains almost the same after PCA at 0.95 . Performing PCA prior to KNN regression fetches almost the same results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR with PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: 0.5401633097240643\n",
      "Test scores: 0.5264211454185395\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>PCA</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.905049</td>\n",
       "      <td>0.916381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768698</td>\n",
       "      <td>0.757449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RidgeRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.894074</td>\n",
       "      <td>0.905362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RidgeRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768290</td>\n",
       "      <td>0.757020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LassoRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.866539</td>\n",
       "      <td>0.902303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LassoRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768583</td>\n",
       "      <td>0.757975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGDRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>-7.111675</td>\n",
       "      <td>-6.965662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGDRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.767191</td>\n",
       "      <td>0.757326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PolyRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PolyRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768698</td>\n",
       "      <td>0.757449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNNRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.951087</td>\n",
       "      <td>0.645903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNNRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.861643</td>\n",
       "      <td>0.651891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVR</td>\n",
       "      <td>without</td>\n",
       "      <td>0.473188</td>\n",
       "      <td>0.465114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVR</td>\n",
       "      <td>with</td>\n",
       "      <td>0.540163</td>\n",
       "      <td>0.526421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVR_RBF</td>\n",
       "      <td>without</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>0.969262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVR_Linear</td>\n",
       "      <td>without</td>\n",
       "      <td>0.788536</td>\n",
       "      <td>0.829035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVR_Poly</td>\n",
       "      <td>without</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>0.999520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model      PCA     Train      Test\n",
       "0   LinearRegression  without  0.905049  0.916381\n",
       "1   LinearRegression     with  0.768698  0.757449\n",
       "2    RidgeRegression  without  0.894074  0.905362\n",
       "3    RidgeRegression     with  0.768290  0.757020\n",
       "4    LassoRegression  without  0.866539  0.902303\n",
       "5    LassoRegression     with  0.768583  0.757975\n",
       "6      SGDRegression  without -7.111675 -6.965662\n",
       "7      SGDRegression     with  0.767191  0.757326\n",
       "8     PolyRegression  without  1.000000  1.000000\n",
       "9     PolyRegression     with  0.768698  0.757449\n",
       "10     KNNRegression  without  0.951087  0.645903\n",
       "11     KNNRegression     with  0.861643  0.651891\n",
       "12               SVR  without  0.473188  0.465114\n",
       "13               SVR     with  0.540163  0.526421\n",
       "14           SVR_RBF  without  0.999681  0.969262\n",
       "15        SVR_Linear  without  0.788536  0.829035\n",
       "16          SVR_Poly  without  0.999935  0.999520"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr = SVR()\n",
    "svr.fit(X_train_reduced,y_train)\n",
    "\n",
    "print(\"Train scores: {}\".format(svr.score(X_train_reduced, y_train)))\n",
    "print(\"Test scores: {}\".format(svr.score(X_test_reduced, y_test)))\n",
    "\n",
    "line = pd.DataFrame({'Model':\"SVR\" , 'PCA': \"with\", 'Train': svr.score(X_train_reduced, y_train),'Test':svr.score(X_test_reduced, y_test)}, index=[12.5])\n",
    "results=results.append(line, ignore_index=False)\n",
    "results = results.sort_index().reset_index(drop=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR Regression train and test score shoots up slightly after PCA at 0.95 , making it little better than Naive model. Performing PCA prior to SVR regression may slightly fetch better results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'C': 300, 'gamma': 0.1}\n",
      "Best score:  0.8664716075245322\n"
     ]
    }
   ],
   "source": [
    "svr_rbf = SVR(kernel='rbf', epsilon=.1)\n",
    "\n",
    "#model param\n",
    "grid_param = {'C':[1,10,100,200,300],'gamma':[0.01,0.1,1,5]}\n",
    "\n",
    "#grid model\n",
    "grid_search = GridSearchCV(svr_rbf, grid_param, cv = 5, n_jobs  = -1)\n",
    "\n",
    "#train grid model\n",
    "grid_search.fit(X_train_reduced, y_train)\n",
    "\n",
    "print('Best params: ', grid_search.best_params_)\n",
    "print('Best score: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: 0.9194374513423013\n",
      "Test scores: 0.7842961546798071\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>PCA</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.905049</td>\n",
       "      <td>0.916381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768698</td>\n",
       "      <td>0.757449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RidgeRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.894074</td>\n",
       "      <td>0.905362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RidgeRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768290</td>\n",
       "      <td>0.757020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LassoRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.866539</td>\n",
       "      <td>0.902303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LassoRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768583</td>\n",
       "      <td>0.757975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGDRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>-7.111675</td>\n",
       "      <td>-6.965662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGDRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.767191</td>\n",
       "      <td>0.757326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PolyRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PolyRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768698</td>\n",
       "      <td>0.757449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNNRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.951087</td>\n",
       "      <td>0.645903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNNRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.861643</td>\n",
       "      <td>0.651891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVR</td>\n",
       "      <td>without</td>\n",
       "      <td>0.473188</td>\n",
       "      <td>0.465114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVR</td>\n",
       "      <td>with</td>\n",
       "      <td>0.540163</td>\n",
       "      <td>0.526421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVR_RBF</td>\n",
       "      <td>without</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>0.969262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVR_RBF</td>\n",
       "      <td>with</td>\n",
       "      <td>0.919437</td>\n",
       "      <td>0.784296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVR_Linear</td>\n",
       "      <td>without</td>\n",
       "      <td>0.788536</td>\n",
       "      <td>0.829035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVR_Poly</td>\n",
       "      <td>without</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>0.999520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model      PCA     Train      Test\n",
       "0   LinearRegression  without  0.905049  0.916381\n",
       "1   LinearRegression     with  0.768698  0.757449\n",
       "2    RidgeRegression  without  0.894074  0.905362\n",
       "3    RidgeRegression     with  0.768290  0.757020\n",
       "4    LassoRegression  without  0.866539  0.902303\n",
       "5    LassoRegression     with  0.768583  0.757975\n",
       "6      SGDRegression  without -7.111675 -6.965662\n",
       "7      SGDRegression     with  0.767191  0.757326\n",
       "8     PolyRegression  without  1.000000  1.000000\n",
       "9     PolyRegression     with  0.768698  0.757449\n",
       "10     KNNRegression  without  0.951087  0.645903\n",
       "11     KNNRegression     with  0.861643  0.651891\n",
       "12               SVR  without  0.473188  0.465114\n",
       "13               SVR     with  0.540163  0.526421\n",
       "14           SVR_RBF  without  0.999681  0.969262\n",
       "15           SVR_RBF     with  0.919437  0.784296\n",
       "16        SVR_Linear  without  0.788536  0.829035\n",
       "17          SVR_Poly  without  0.999935  0.999520"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rbf = SVR(kernel='rbf', C=300, gamma=0.1, epsilon=.1)\n",
    "svr_rbf.fit(X_train_reduced,y_train)\n",
    "\n",
    "print(\"Train scores: {}\".format(svr_rbf.score(X_train_reduced, y_train)))\n",
    "print(\"Test scores: {}\".format(svr_rbf.score(X_test_reduced, y_test)))\n",
    "\n",
    "line = pd.DataFrame({'Model':\"SVR_RBF\" , 'PCA': \"with\", 'Train': svr_rbf.score(X_train_reduced, y_train),'Test':svr_rbf.score(X_test_reduced, y_test)}, index=[14.5])\n",
    "results=results.append(line, ignore_index=False)\n",
    "results = results.sort_index().reset_index(drop=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR RBF Regression train  score worsens slightly but test score drops further down after PCA at 0.95 . It is clear that in this case, PCA results in loss of variation(information) in data while modelling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR_Linear with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'C': 200}\n",
      "Best score:  0.70891610251022\n"
     ]
    }
   ],
   "source": [
    "svr_lin = SVR(kernel='linear')\n",
    "\n",
    "#model param\n",
    "grid_param = {'C':[1,10,100,200,300]}\n",
    "\n",
    "#grid model\n",
    "grid_search = GridSearchCV(svr_lin, grid_param, cv = 5, n_jobs  = -1)\n",
    "\n",
    "#train grid model\n",
    "grid_search.fit(X_train_reduced, y_train)\n",
    "\n",
    "print('Best params: ', grid_search.best_params_)\n",
    "print('Best score: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: 0.7042911603725673\n",
      "Test scores: 0.7362340838393324\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>PCA</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.905049</td>\n",
       "      <td>0.916381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768698</td>\n",
       "      <td>0.757449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RidgeRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.894074</td>\n",
       "      <td>0.905362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RidgeRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768290</td>\n",
       "      <td>0.757020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LassoRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.866539</td>\n",
       "      <td>0.902303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LassoRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768583</td>\n",
       "      <td>0.757975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGDRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>-7.111675</td>\n",
       "      <td>-6.965662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGDRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.767191</td>\n",
       "      <td>0.757326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PolyRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PolyRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768698</td>\n",
       "      <td>0.757449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNNRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.951087</td>\n",
       "      <td>0.645903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNNRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.861643</td>\n",
       "      <td>0.651891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVR</td>\n",
       "      <td>without</td>\n",
       "      <td>0.473188</td>\n",
       "      <td>0.465114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVR</td>\n",
       "      <td>with</td>\n",
       "      <td>0.540163</td>\n",
       "      <td>0.526421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVR_RBF</td>\n",
       "      <td>without</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>0.969262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVR_RBF</td>\n",
       "      <td>with</td>\n",
       "      <td>0.919437</td>\n",
       "      <td>0.784296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVR_Linear</td>\n",
       "      <td>without</td>\n",
       "      <td>0.788536</td>\n",
       "      <td>0.829035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVR_Linear</td>\n",
       "      <td>with</td>\n",
       "      <td>0.704291</td>\n",
       "      <td>0.736234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SVR_Poly</td>\n",
       "      <td>without</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>0.999520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model      PCA     Train      Test\n",
       "0   LinearRegression  without  0.905049  0.916381\n",
       "1   LinearRegression     with  0.768698  0.757449\n",
       "2    RidgeRegression  without  0.894074  0.905362\n",
       "3    RidgeRegression     with  0.768290  0.757020\n",
       "4    LassoRegression  without  0.866539  0.902303\n",
       "5    LassoRegression     with  0.768583  0.757975\n",
       "6      SGDRegression  without -7.111675 -6.965662\n",
       "7      SGDRegression     with  0.767191  0.757326\n",
       "8     PolyRegression  without  1.000000  1.000000\n",
       "9     PolyRegression     with  0.768698  0.757449\n",
       "10     KNNRegression  without  0.951087  0.645903\n",
       "11     KNNRegression     with  0.861643  0.651891\n",
       "12               SVR  without  0.473188  0.465114\n",
       "13               SVR     with  0.540163  0.526421\n",
       "14           SVR_RBF  without  0.999681  0.969262\n",
       "15           SVR_RBF     with  0.919437  0.784296\n",
       "16        SVR_Linear  without  0.788536  0.829035\n",
       "17        SVR_Linear     with  0.704291  0.736234\n",
       "18          SVR_Poly  without  0.999935  0.999520"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_lin = SVR(kernel='linear', C=200)\n",
    "svr_lin.fit(X_train_reduced,y_train)\n",
    "\n",
    "print(\"Train scores: {}\".format(svr_lin.score(X_train_reduced, y_train)))\n",
    "print(\"Test scores: {}\".format(svr_lin.score(X_test_reduced, y_test)))\n",
    "\n",
    "line = pd.DataFrame({'Model':\"SVR_Linear\" , 'PCA': \"with\", 'Train': svr_lin.score(X_train_reduced, y_train),'Test':svr_lin.score(X_test_reduced, y_test)}, index=[16.5])\n",
    "results=results.append(line, ignore_index=False)\n",
    "results = results.sort_index().reset_index(drop=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR Poly with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'C': 300, 'degree': 3}\n",
      "Best score:  0.8249245777034931\n"
     ]
    }
   ],
   "source": [
    "svr_poly = SVR(kernel='poly')\n",
    "\n",
    "\n",
    "#model param\n",
    "grid_param = {'C':[1,10,100,200,300],'degree':[2,3,4]}\n",
    "\n",
    "#grid model\n",
    "grid_search = GridSearchCV(svr_poly, grid_param, cv = 5, n_jobs  = -1)\n",
    "\n",
    "#train grid model\n",
    "grid_search.fit(X_train_reduced, y_train)\n",
    "\n",
    "print('Best params: ', grid_search.best_params_)\n",
    "print('Best score: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: 0.9392509676596843\n",
      "Test scores: 0.8034134544270307\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>PCA</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.905049</td>\n",
       "      <td>0.916381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768698</td>\n",
       "      <td>0.757449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RidgeRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.894074</td>\n",
       "      <td>0.905362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RidgeRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768290</td>\n",
       "      <td>0.757020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LassoRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.866539</td>\n",
       "      <td>0.902303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LassoRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768583</td>\n",
       "      <td>0.757975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGDRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>-7.111675</td>\n",
       "      <td>-6.965662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGDRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.767191</td>\n",
       "      <td>0.757326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PolyRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PolyRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.768698</td>\n",
       "      <td>0.757449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNNRegression</td>\n",
       "      <td>without</td>\n",
       "      <td>0.951087</td>\n",
       "      <td>0.645903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNNRegression</td>\n",
       "      <td>with</td>\n",
       "      <td>0.861643</td>\n",
       "      <td>0.651891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVR</td>\n",
       "      <td>without</td>\n",
       "      <td>0.473188</td>\n",
       "      <td>0.465114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVR</td>\n",
       "      <td>with</td>\n",
       "      <td>0.540163</td>\n",
       "      <td>0.526421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVR_RBF</td>\n",
       "      <td>without</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>0.969262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVR_RBF</td>\n",
       "      <td>with</td>\n",
       "      <td>0.919437</td>\n",
       "      <td>0.784296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVR_Linear</td>\n",
       "      <td>without</td>\n",
       "      <td>0.788536</td>\n",
       "      <td>0.829035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVR_Linear</td>\n",
       "      <td>with</td>\n",
       "      <td>0.704291</td>\n",
       "      <td>0.736234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SVR_Poly</td>\n",
       "      <td>without</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>0.999520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SVR_Poly</td>\n",
       "      <td>with</td>\n",
       "      <td>0.939251</td>\n",
       "      <td>0.803413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model      PCA     Train      Test\n",
       "0   LinearRegression  without  0.905049  0.916381\n",
       "1   LinearRegression     with  0.768698  0.757449\n",
       "2    RidgeRegression  without  0.894074  0.905362\n",
       "3    RidgeRegression     with  0.768290  0.757020\n",
       "4    LassoRegression  without  0.866539  0.902303\n",
       "5    LassoRegression     with  0.768583  0.757975\n",
       "6      SGDRegression  without -7.111675 -6.965662\n",
       "7      SGDRegression     with  0.767191  0.757326\n",
       "8     PolyRegression  without  1.000000  1.000000\n",
       "9     PolyRegression     with  0.768698  0.757449\n",
       "10     KNNRegression  without  0.951087  0.645903\n",
       "11     KNNRegression     with  0.861643  0.651891\n",
       "12               SVR  without  0.473188  0.465114\n",
       "13               SVR     with  0.540163  0.526421\n",
       "14           SVR_RBF  without  0.999681  0.969262\n",
       "15           SVR_RBF     with  0.919437  0.784296\n",
       "16        SVR_Linear  without  0.788536  0.829035\n",
       "17        SVR_Linear     with  0.704291  0.736234\n",
       "18          SVR_Poly  without  0.999935  0.999520\n",
       "19          SVR_Poly     with  0.939251  0.803413"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_poly = SVR(kernel='poly', C=300, degree=3)\n",
    "svr_poly.fit(X_train_reduced,y_train)\n",
    "\n",
    "print(\"Train scores: {}\".format(svr_poly.score(X_train_reduced, y_train)))\n",
    "print(\"Test scores: {}\".format(svr_poly.score(X_test_reduced, y_test)))\n",
    "\n",
    "line = pd.DataFrame({'Model':\"SVR_Poly\" , 'PCA': \"with\", 'Train': svr_poly.score(X_train_reduced, y_train),'Test':svr_poly.score(X_test_reduced, y_test)}, index=[18.5])\n",
    "results=results.append(line, ignore_index=False)\n",
    "results = results.sort_index().reset_index(drop=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR Linear and SVR Polynomial Regression train  score worsens slightly but test score drops further down after PCA at 0.95 . It is clear that in these case, PCA results in loss of variation(information) in data while modelling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(402, 22)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "402/402 [==============================] - 0s 383us/step - loss: 87.9918 - mean_squared_error: 87.9918\n",
      "Epoch 2/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 78.0952 - mean_squared_error: 78.0952\n",
      "Epoch 3/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 71.7077 - mean_squared_error: 71.7077\n",
      "Epoch 4/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 68.0627 - mean_squared_error: 68.0627\n",
      "Epoch 5/400\n",
      "402/402 [==============================] - 0s 12us/step - loss: 66.2785 - mean_squared_error: 66.2785\n",
      "Epoch 6/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 65.1449 - mean_squared_error: 65.1449\n",
      "Epoch 7/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 64.2554 - mean_squared_error: 64.2554\n",
      "Epoch 8/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 63.1012 - mean_squared_error: 63.1012\n",
      "Epoch 9/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 62.3141 - mean_squared_error: 62.3141\n",
      "Epoch 10/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 61.0464 - mean_squared_error: 61.0464\n",
      "Epoch 11/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 60.0159 - mean_squared_error: 60.0159\n",
      "Epoch 12/400\n",
      "402/402 [==============================] - 0s 27us/step - loss: 58.9200 - mean_squared_error: 58.9200\n",
      "Epoch 13/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 57.8422 - mean_squared_error: 57.8422\n",
      "Epoch 14/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 56.8369 - mean_squared_error: 56.8369\n",
      "Epoch 15/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 55.6111 - mean_squared_error: 55.6111\n",
      "Epoch 16/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 54.5927 - mean_squared_error: 54.5927\n",
      "Epoch 17/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 53.4889 - mean_squared_error: 53.4889\n",
      "Epoch 18/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 52.5479 - mean_squared_error: 52.5479\n",
      "Epoch 19/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 51.6561 - mean_squared_error: 51.6561\n",
      "Epoch 20/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 50.8775 - mean_squared_error: 50.8775\n",
      "Epoch 21/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 49.7954 - mean_squared_error: 49.7954\n",
      "Epoch 22/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 48.9903 - mean_squared_error: 48.9903\n",
      "Epoch 23/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 47.8809 - mean_squared_error: 47.8809\n",
      "Epoch 24/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 47.0024 - mean_squared_error: 47.0024\n",
      "Epoch 25/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 46.2311 - mean_squared_error: 46.2311\n",
      "Epoch 26/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 45.6075 - mean_squared_error: 45.6075\n",
      "Epoch 27/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 44.8304 - mean_squared_error: 44.8304\n",
      "Epoch 28/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 44.0723 - mean_squared_error: 44.0723\n",
      "Epoch 29/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 43.3701 - mean_squared_error: 43.3701\n",
      "Epoch 30/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 42.7959 - mean_squared_error: 42.7959\n",
      "Epoch 31/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 42.0181 - mean_squared_error: 42.0181\n",
      "Epoch 32/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 41.0683 - mean_squared_error: 41.0683\n",
      "Epoch 33/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 40.1848 - mean_squared_error: 40.1848\n",
      "Epoch 34/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 39.5450 - mean_squared_error: 39.5450\n",
      "Epoch 35/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 39.0661 - mean_squared_error: 39.0661\n",
      "Epoch 36/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 38.5262 - mean_squared_error: 38.5262\n",
      "Epoch 37/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 37.9372 - mean_squared_error: 37.9372\n",
      "Epoch 38/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 37.2126 - mean_squared_error: 37.2126\n",
      "Epoch 39/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 36.6112 - mean_squared_error: 36.6112\n",
      "Epoch 40/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 35.9622 - mean_squared_error: 35.9622\n",
      "Epoch 41/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 35.4361 - mean_squared_error: 35.4361\n",
      "Epoch 42/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 34.9615 - mean_squared_error: 34.9615\n",
      "Epoch 43/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 34.2585 - mean_squared_error: 34.2585\n",
      "Epoch 44/400\n",
      "402/402 [==============================] - 0s 25us/step - loss: 33.8405 - mean_squared_error: 33.8405\n",
      "Epoch 45/400\n",
      "402/402 [==============================] - 0s 27us/step - loss: 33.3510 - mean_squared_error: 33.3510\n",
      "Epoch 46/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 32.7179 - mean_squared_error: 32.7179\n",
      "Epoch 47/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 32.1557 - mean_squared_error: 32.1557\n",
      "Epoch 48/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 31.5512 - mean_squared_error: 31.5512\n",
      "Epoch 49/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 30.9635 - mean_squared_error: 30.9635\n",
      "Epoch 50/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 30.3731 - mean_squared_error: 30.3731\n",
      "Epoch 51/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 29.9359 - mean_squared_error: 29.9359\n",
      "Epoch 52/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 29.3770 - mean_squared_error: 29.3770\n",
      "Epoch 53/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 28.8909 - mean_squared_error: 28.8909\n",
      "Epoch 54/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 28.3277 - mean_squared_error: 28.3277\n",
      "Epoch 55/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 27.7003 - mean_squared_error: 27.7003\n",
      "Epoch 56/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 27.0868 - mean_squared_error: 27.0868\n",
      "Epoch 57/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 26.6918 - mean_squared_error: 26.6918\n",
      "Epoch 58/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 26.1864 - mean_squared_error: 26.1864\n",
      "Epoch 59/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 25.7166 - mean_squared_error: 25.7166\n",
      "Epoch 60/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 25.1337 - mean_squared_error: 25.1337\n",
      "Epoch 61/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 24.7285 - mean_squared_error: 24.7285\n",
      "Epoch 62/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 24.3993 - mean_squared_error: 24.3993\n",
      "Epoch 63/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 23.9897 - mean_squared_error: 23.9897\n",
      "Epoch 64/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 23.7785 - mean_squared_error: 23.7785\n",
      "Epoch 65/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 23.4592 - mean_squared_error: 23.4592\n",
      "Epoch 66/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 23.0435 - mean_squared_error: 23.0435\n",
      "Epoch 67/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 22.5285 - mean_squared_error: 22.5285\n",
      "Epoch 68/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 22.2178 - mean_squared_error: 22.2178\n",
      "Epoch 69/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 22.0109 - mean_squared_error: 22.0109\n",
      "Epoch 70/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 21.7410 - mean_squared_error: 21.7410\n",
      "Epoch 71/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 21.3703 - mean_squared_error: 21.3703\n",
      "Epoch 72/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 0s 17us/step - loss: 21.0982 - mean_squared_error: 21.0982\n",
      "Epoch 73/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 20.7908 - mean_squared_error: 20.7908\n",
      "Epoch 74/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 20.5753 - mean_squared_error: 20.5753\n",
      "Epoch 75/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 20.1743 - mean_squared_error: 20.1743\n",
      "Epoch 76/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 19.9000 - mean_squared_error: 19.9000\n",
      "Epoch 77/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 19.6377 - mean_squared_error: 19.6377\n",
      "Epoch 78/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 19.2134 - mean_squared_error: 19.2134\n",
      "Epoch 79/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 18.8844 - mean_squared_error: 18.8844\n",
      "Epoch 80/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 18.6047 - mean_squared_error: 18.6047\n",
      "Epoch 81/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 18.0939 - mean_squared_error: 18.0939\n",
      "Epoch 82/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 17.8757 - mean_squared_error: 17.8757\n",
      "Epoch 83/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 17.6403 - mean_squared_error: 17.6403\n",
      "Epoch 84/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 17.5016 - mean_squared_error: 17.5016\n",
      "Epoch 85/400\n",
      "402/402 [==============================] - 0s 12us/step - loss: 17.2689 - mean_squared_error: 17.2689\n",
      "Epoch 86/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 17.1066 - mean_squared_error: 17.1066\n",
      "Epoch 87/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 16.8732 - mean_squared_error: 16.8732\n",
      "Epoch 88/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 16.5970 - mean_squared_error: 16.5970\n",
      "Epoch 89/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 16.3287 - mean_squared_error: 16.3287\n",
      "Epoch 90/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 16.1533 - mean_squared_error: 16.1533\n",
      "Epoch 91/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 15.9592 - mean_squared_error: 15.9592\n",
      "Epoch 92/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 15.7901 - mean_squared_error: 15.7901\n",
      "Epoch 93/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 15.6329 - mean_squared_error: 15.6329\n",
      "Epoch 94/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 15.3595 - mean_squared_error: 15.3595\n",
      "Epoch 95/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 15.2453 - mean_squared_error: 15.2453\n",
      "Epoch 96/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 15.0990 - mean_squared_error: 15.0990\n",
      "Epoch 97/400\n",
      "402/402 [==============================] - 0s 32us/step - loss: 14.9449 - mean_squared_error: 14.9449\n",
      "Epoch 98/400\n",
      "402/402 [==============================] - 0s 25us/step - loss: 14.8672 - mean_squared_error: 14.8672\n",
      "Epoch 99/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 14.4936 - mean_squared_error: 14.4936\n",
      "Epoch 100/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 14.3460 - mean_squared_error: 14.3460\n",
      "Epoch 101/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 14.5359 - mean_squared_error: 14.5359\n",
      "Epoch 102/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 13.8876 - mean_squared_error: 13.8876\n",
      "Epoch 103/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 13.5772 - mean_squared_error: 13.5772\n",
      "Epoch 104/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 13.3066 - mean_squared_error: 13.3066\n",
      "Epoch 105/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 13.1543 - mean_squared_error: 13.1543\n",
      "Epoch 106/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 13.0640 - mean_squared_error: 13.0640\n",
      "Epoch 107/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 12.8988 - mean_squared_error: 12.8988\n",
      "Epoch 108/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 12.7429 - mean_squared_error: 12.7429\n",
      "Epoch 109/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 12.6437 - mean_squared_error: 12.6437\n",
      "Epoch 110/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 12.4787 - mean_squared_error: 12.4787\n",
      "Epoch 111/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 12.4558 - mean_squared_error: 12.4558\n",
      "Epoch 112/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 12.1857 - mean_squared_error: 12.1857\n",
      "Epoch 113/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 12.1312 - mean_squared_error: 12.1312\n",
      "Epoch 114/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 11.9236 - mean_squared_error: 11.9236\n",
      "Epoch 115/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 11.7741 - mean_squared_error: 11.7741\n",
      "Epoch 116/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 11.7559 - mean_squared_error: 11.7559\n",
      "Epoch 117/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 11.4931 - mean_squared_error: 11.4931\n",
      "Epoch 118/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 11.4404 - mean_squared_error: 11.4404\n",
      "Epoch 119/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 11.3873 - mean_squared_error: 11.3873\n",
      "Epoch 120/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 11.1501 - mean_squared_error: 11.1501\n",
      "Epoch 121/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 11.1395 - mean_squared_error: 11.1395\n",
      "Epoch 122/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 10.9159 - mean_squared_error: 10.9159\n",
      "Epoch 123/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 10.7971 - mean_squared_error: 10.7971\n",
      "Epoch 124/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 10.6979 - mean_squared_error: 10.6979\n",
      "Epoch 125/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 10.5628 - mean_squared_error: 10.5628\n",
      "Epoch 126/400\n",
      "402/402 [==============================] - 0s 27us/step - loss: 10.4445 - mean_squared_error: 10.4445\n",
      "Epoch 127/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 10.3774 - mean_squared_error: 10.3774\n",
      "Epoch 128/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 10.2890 - mean_squared_error: 10.2890\n",
      "Epoch 129/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 10.3400 - mean_squared_error: 10.3400\n",
      "Epoch 130/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 10.0348 - mean_squared_error: 10.0348\n",
      "Epoch 131/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 9.8749 - mean_squared_error: 9.8749\n",
      "Epoch 132/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 9.7640 - mean_squared_error: 9.7640\n",
      "Epoch 133/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 9.5915 - mean_squared_error: 9.5915\n",
      "Epoch 134/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 9.5221 - mean_squared_error: 9.5221\n",
      "Epoch 135/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 9.5065 - mean_squared_error: 9.5065\n",
      "Epoch 136/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 9.3275 - mean_squared_error: 9.3275\n",
      "Epoch 137/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 9.2666 - mean_squared_error: 9.2666\n",
      "Epoch 138/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 9.3591 - mean_squared_error: 9.3591\n",
      "Epoch 139/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 9.0320 - mean_squared_error: 9.0320\n",
      "Epoch 140/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 9.0043 - mean_squared_error: 9.0043\n",
      "Epoch 141/400\n",
      "402/402 [==============================] - 0s 25us/step - loss: 8.8917 - mean_squared_error: 8.8917\n",
      "Epoch 142/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 8.8657 - mean_squared_error: 8.8657\n",
      "Epoch 143/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 0s 17us/step - loss: 8.7273 - mean_squared_error: 8.7273\n",
      "Epoch 144/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 8.5994 - mean_squared_error: 8.5994\n",
      "Epoch 145/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 8.5417 - mean_squared_error: 8.5417\n",
      "Epoch 146/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 8.5005 - mean_squared_error: 8.5005\n",
      "Epoch 147/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 8.4172 - mean_squared_error: 8.4172\n",
      "Epoch 148/400\n",
      "402/402 [==============================] - 0s 25us/step - loss: 8.2871 - mean_squared_error: 8.2871\n",
      "Epoch 149/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 8.2271 - mean_squared_error: 8.2271\n",
      "Epoch 150/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 8.1786 - mean_squared_error: 8.1786\n",
      "Epoch 151/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 8.0937 - mean_squared_error: 8.0937\n",
      "Epoch 152/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 8.0463 - mean_squared_error: 8.0463\n",
      "Epoch 153/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 7.9248 - mean_squared_error: 7.9248\n",
      "Epoch 154/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 7.8491 - mean_squared_error: 7.8491\n",
      "Epoch 155/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 7.7971 - mean_squared_error: 7.7971\n",
      "Epoch 156/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 7.7210 - mean_squared_error: 7.7210\n",
      "Epoch 157/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 7.7801 - mean_squared_error: 7.7801\n",
      "Epoch 158/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 7.5020 - mean_squared_error: 7.5020\n",
      "Epoch 159/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 7.6239 - mean_squared_error: 7.6239\n",
      "Epoch 160/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 7.3748 - mean_squared_error: 7.3748\n",
      "Epoch 161/400\n",
      "402/402 [==============================] - 0s 35us/step - loss: 7.2986 - mean_squared_error: 7.2986\n",
      "Epoch 162/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 7.2775 - mean_squared_error: 7.2775\n",
      "Epoch 163/400\n",
      "402/402 [==============================] - 0s 25us/step - loss: 7.1892 - mean_squared_error: 7.1892\n",
      "Epoch 164/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 7.1156 - mean_squared_error: 7.1156\n",
      "Epoch 165/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 7.0547 - mean_squared_error: 7.0547\n",
      "Epoch 166/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 7.0015 - mean_squared_error: 7.0015\n",
      "Epoch 167/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 7.0955 - mean_squared_error: 7.0955\n",
      "Epoch 168/400\n",
      "402/402 [==============================] - 0s 25us/step - loss: 6.8915 - mean_squared_error: 6.8915\n",
      "Epoch 169/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 6.8534 - mean_squared_error: 6.8534\n",
      "Epoch 170/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 6.8271 - mean_squared_error: 6.8271\n",
      "Epoch 171/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 6.7749 - mean_squared_error: 6.7749\n",
      "Epoch 172/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 6.7371 - mean_squared_error: 6.7371\n",
      "Epoch 173/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 6.6525 - mean_squared_error: 6.6525\n",
      "Epoch 174/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 6.5654 - mean_squared_error: 6.5654\n",
      "Epoch 175/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 6.5153 - mean_squared_error: 6.5153\n",
      "Epoch 176/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 6.4792 - mean_squared_error: 6.4792\n",
      "Epoch 177/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 6.5347 - mean_squared_error: 6.5347\n",
      "Epoch 178/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 6.4186 - mean_squared_error: 6.4186\n",
      "Epoch 179/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 6.3610 - mean_squared_error: 6.3610\n",
      "Epoch 180/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 6.2769 - mean_squared_error: 6.2769\n",
      "Epoch 181/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 6.5365 - mean_squared_error: 6.5365\n",
      "Epoch 182/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 6.1514 - mean_squared_error: 6.1514\n",
      "Epoch 183/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 6.1033 - mean_squared_error: 6.1033\n",
      "Epoch 184/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 6.0757 - mean_squared_error: 6.0757\n",
      "Epoch 185/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 6.0455 - mean_squared_error: 6.0455\n",
      "Epoch 186/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 5.9801 - mean_squared_error: 5.9801\n",
      "Epoch 187/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 5.9664 - mean_squared_error: 5.9664\n",
      "Epoch 188/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 5.9130 - mean_squared_error: 5.9130\n",
      "Epoch 189/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 5.9456 - mean_squared_error: 5.9456\n",
      "Epoch 190/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 5.8280 - mean_squared_error: 5.8280\n",
      "Epoch 191/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 5.7737 - mean_squared_error: 5.7737\n",
      "Epoch 192/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 5.7345 - mean_squared_error: 5.7345\n",
      "Epoch 193/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 5.6767 - mean_squared_error: 5.6767\n",
      "Epoch 194/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 5.6546 - mean_squared_error: 5.6546\n",
      "Epoch 195/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 5.6112 - mean_squared_error: 5.6112\n",
      "Epoch 196/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 5.5487 - mean_squared_error: 5.5487\n",
      "Epoch 197/400\n",
      "402/402 [==============================] - ETA: 0s - loss: 11.1230 - mean_squared_error: 11.12 - 0s 17us/step - loss: 5.4942 - mean_squared_error: 5.4942\n",
      "Epoch 198/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 5.4758 - mean_squared_error: 5.4758\n",
      "Epoch 199/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 5.4438 - mean_squared_error: 5.4438\n",
      "Epoch 200/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 5.4380 - mean_squared_error: 5.4380\n",
      "Epoch 201/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 5.4339 - mean_squared_error: 5.4339\n",
      "Epoch 202/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 5.3516 - mean_squared_error: 5.3516\n",
      "Epoch 203/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 5.2653 - mean_squared_error: 5.2653\n",
      "Epoch 204/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 5.2101 - mean_squared_error: 5.2101\n",
      "Epoch 205/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 5.2032 - mean_squared_error: 5.2032\n",
      "Epoch 206/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 5.2803 - mean_squared_error: 5.2803\n",
      "Epoch 207/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 5.1412 - mean_squared_error: 5.1412\n",
      "Epoch 208/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 5.0510 - mean_squared_error: 5.0510\n",
      "Epoch 209/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 5.0329 - mean_squared_error: 5.0329\n",
      "Epoch 210/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 4.9485 - mean_squared_error: 4.9485\n",
      "Epoch 211/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 4.9361 - mean_squared_error: 4.9361\n",
      "Epoch 212/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 4.9042 - mean_squared_error: 4.9042\n",
      "Epoch 213/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 4.8137 - mean_squared_error: 4.8137\n",
      "Epoch 214/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 0s 17us/step - loss: 4.7573 - mean_squared_error: 4.7573\n",
      "Epoch 215/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 4.7277 - mean_squared_error: 4.7277\n",
      "Epoch 216/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 4.7152 - mean_squared_error: 4.7152\n",
      "Epoch 217/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 4.6607 - mean_squared_error: 4.6607\n",
      "Epoch 218/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 4.6581 - mean_squared_error: 4.6581\n",
      "Epoch 219/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 4.6154 - mean_squared_error: 4.6154\n",
      "Epoch 220/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 4.5724 - mean_squared_error: 4.5724\n",
      "Epoch 221/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 4.5637 - mean_squared_error: 4.5637\n",
      "Epoch 222/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 4.4605 - mean_squared_error: 4.4605\n",
      "Epoch 223/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 4.4392 - mean_squared_error: 4.4392\n",
      "Epoch 224/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 4.3913 - mean_squared_error: 4.3913\n",
      "Epoch 225/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 4.3884 - mean_squared_error: 4.3884\n",
      "Epoch 226/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 4.3371 - mean_squared_error: 4.3371\n",
      "Epoch 227/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 4.3155 - mean_squared_error: 4.3155\n",
      "Epoch 228/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 4.3030 - mean_squared_error: 4.3030\n",
      "Epoch 229/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 4.3081 - mean_squared_error: 4.3081\n",
      "Epoch 230/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 4.2350 - mean_squared_error: 4.2350\n",
      "Epoch 231/400\n",
      "402/402 [==============================] - ETA: 0s - loss: 3.1326 - mean_squared_error: 3.13 - 0s 15us/step - loss: 4.2473 - mean_squared_error: 4.2473\n",
      "Epoch 232/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 4.3298 - mean_squared_error: 4.3298\n",
      "Epoch 233/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 4.0935 - mean_squared_error: 4.0935\n",
      "Epoch 234/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 4.0937 - mean_squared_error: 4.0937\n",
      "Epoch 235/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 4.1148 - mean_squared_error: 4.1148\n",
      "Epoch 236/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 4.0212 - mean_squared_error: 4.0212\n",
      "Epoch 237/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 3.9530 - mean_squared_error: 3.9530\n",
      "Epoch 238/400\n",
      "402/402 [==============================] - 0s 25us/step - loss: 3.9493 - mean_squared_error: 3.9493\n",
      "Epoch 239/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 3.9558 - mean_squared_error: 3.9558\n",
      "Epoch 240/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 3.8923 - mean_squared_error: 3.8923\n",
      "Epoch 241/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 3.8514 - mean_squared_error: 3.8514\n",
      "Epoch 242/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 3.8758 - mean_squared_error: 3.8758\n",
      "Epoch 243/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 3.8240 - mean_squared_error: 3.8240\n",
      "Epoch 244/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 3.7613 - mean_squared_error: 3.7613\n",
      "Epoch 245/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 3.7510 - mean_squared_error: 3.7510\n",
      "Epoch 246/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 3.7063 - mean_squared_error: 3.7063\n",
      "Epoch 247/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 3.6997 - mean_squared_error: 3.6997\n",
      "Epoch 248/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 3.7139 - mean_squared_error: 3.7139\n",
      "Epoch 249/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 3.6345 - mean_squared_error: 3.6345\n",
      "Epoch 250/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 3.6855 - mean_squared_error: 3.6855\n",
      "Epoch 251/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 3.6234 - mean_squared_error: 3.6234\n",
      "Epoch 252/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 3.6092 - mean_squared_error: 3.6092\n",
      "Epoch 253/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 3.5099 - mean_squared_error: 3.5099\n",
      "Epoch 254/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 3.4919 - mean_squared_error: 3.4919\n",
      "Epoch 255/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 3.4736 - mean_squared_error: 3.4736\n",
      "Epoch 256/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 3.4491 - mean_squared_error: 3.4491\n",
      "Epoch 257/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 3.4200 - mean_squared_error: 3.4200\n",
      "Epoch 258/400\n",
      "402/402 [==============================] - 0s 30us/step - loss: 3.3929 - mean_squared_error: 3.3929\n",
      "Epoch 259/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 3.3841 - mean_squared_error: 3.3841\n",
      "Epoch 260/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 3.5417 - mean_squared_error: 3.5417\n",
      "Epoch 261/400\n",
      "402/402 [==============================] - 0s 45us/step - loss: 3.3442 - mean_squared_error: 3.3442\n",
      "Epoch 262/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 3.5552 - mean_squared_error: 3.5552\n",
      "Epoch 263/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 3.3491 - mean_squared_error: 3.3491\n",
      "Epoch 264/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 3.2353 - mean_squared_error: 3.2353\n",
      "Epoch 265/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 3.2261 - mean_squared_error: 3.2261\n",
      "Epoch 266/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 3.1927 - mean_squared_error: 3.1927\n",
      "Epoch 267/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 3.2195 - mean_squared_error: 3.2195\n",
      "Epoch 268/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 3.2728 - mean_squared_error: 3.2728\n",
      "Epoch 269/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 3.1497 - mean_squared_error: 3.1497\n",
      "Epoch 270/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 3.1498 - mean_squared_error: 3.1498\n",
      "Epoch 271/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 3.1114 - mean_squared_error: 3.1114\n",
      "Epoch 272/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 3.0965 - mean_squared_error: 3.0965\n",
      "Epoch 273/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 3.1147 - mean_squared_error: 3.1147\n",
      "Epoch 274/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 3.0641 - mean_squared_error: 3.0641\n",
      "Epoch 275/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 3.0525 - mean_squared_error: 3.0525\n",
      "Epoch 276/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 3.0568 - mean_squared_error: 3.0568\n",
      "Epoch 277/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 3.0513 - mean_squared_error: 3.0513\n",
      "Epoch 278/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 3.0214 - mean_squared_error: 3.0214\n",
      "Epoch 279/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.9951 - mean_squared_error: 2.9951\n",
      "Epoch 280/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.9785 - mean_squared_error: 2.9785\n",
      "Epoch 281/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 3.0424 - mean_squared_error: 3.0424\n",
      "Epoch 282/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.9181 - mean_squared_error: 2.9181\n",
      "Epoch 283/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 2.9011 - mean_squared_error: 2.9011\n",
      "Epoch 284/400\n",
      "402/402 [==============================] - 0s 27us/step - loss: 2.9069 - mean_squared_error: 2.9069\n",
      "Epoch 285/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 0s 17us/step - loss: 2.8803 - mean_squared_error: 2.8803\n",
      "Epoch 286/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.8634 - mean_squared_error: 2.8634\n",
      "Epoch 287/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.8351 - mean_squared_error: 2.8351\n",
      "Epoch 288/400\n",
      "402/402 [==============================] - 0s 25us/step - loss: 2.8235 - mean_squared_error: 2.8235\n",
      "Epoch 289/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.8052 - mean_squared_error: 2.8052\n",
      "Epoch 290/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.7981 - mean_squared_error: 2.7981\n",
      "Epoch 291/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 2.8389 - mean_squared_error: 2.8389\n",
      "Epoch 292/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.7644 - mean_squared_error: 2.7644\n",
      "Epoch 293/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.7814 - mean_squared_error: 2.7814\n",
      "Epoch 294/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.7943 - mean_squared_error: 2.7943\n",
      "Epoch 295/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.7445 - mean_squared_error: 2.7445\n",
      "Epoch 296/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.7447 - mean_squared_error: 2.7447\n",
      "Epoch 297/400\n",
      "402/402 [==============================] - 0s 25us/step - loss: 2.7142 - mean_squared_error: 2.7142\n",
      "Epoch 298/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 2.6954 - mean_squared_error: 2.6954\n",
      "Epoch 299/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.7047 - mean_squared_error: 2.7047\n",
      "Epoch 300/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 2.6838 - mean_squared_error: 2.6838\n",
      "Epoch 301/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.6607 - mean_squared_error: 2.6607\n",
      "Epoch 302/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 2.6470 - mean_squared_error: 2.6470\n",
      "Epoch 303/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 2.6268 - mean_squared_error: 2.6268\n",
      "Epoch 304/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.6220 - mean_squared_error: 2.6220\n",
      "Epoch 305/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.6298 - mean_squared_error: 2.6298\n",
      "Epoch 306/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.6933 - mean_squared_error: 2.6933\n",
      "Epoch 307/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.6042 - mean_squared_error: 2.6042\n",
      "Epoch 308/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.5878 - mean_squared_error: 2.5878\n",
      "Epoch 309/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 2.5624 - mean_squared_error: 2.5624\n",
      "Epoch 310/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 2.5549 - mean_squared_error: 2.5549\n",
      "Epoch 311/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.5372 - mean_squared_error: 2.5372\n",
      "Epoch 312/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 2.5297 - mean_squared_error: 2.5297\n",
      "Epoch 313/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.5097 - mean_squared_error: 2.5097\n",
      "Epoch 314/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 2.5063 - mean_squared_error: 2.5063\n",
      "Epoch 315/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.4935 - mean_squared_error: 2.4935\n",
      "Epoch 316/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 2.4811 - mean_squared_error: 2.4811\n",
      "Epoch 317/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.4933 - mean_squared_error: 2.4933\n",
      "Epoch 318/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 2.4558 - mean_squared_error: 2.4558\n",
      "Epoch 319/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.4516 - mean_squared_error: 2.4516\n",
      "Epoch 320/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.4361 - mean_squared_error: 2.4361\n",
      "Epoch 321/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.4547 - mean_squared_error: 2.4547\n",
      "Epoch 322/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 2.4314 - mean_squared_error: 2.4314\n",
      "Epoch 323/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.4066 - mean_squared_error: 2.4066\n",
      "Epoch 324/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.4248 - mean_squared_error: 2.4248\n",
      "Epoch 325/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.3880 - mean_squared_error: 2.3880\n",
      "Epoch 326/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 2.3880 - mean_squared_error: 2.3880\n",
      "Epoch 327/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.3774 - mean_squared_error: 2.3774\n",
      "Epoch 328/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.3528 - mean_squared_error: 2.3528\n",
      "Epoch 329/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 2.3398 - mean_squared_error: 2.3398\n",
      "Epoch 330/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 2.3378 - mean_squared_error: 2.3378\n",
      "Epoch 331/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 2.3314 - mean_squared_error: 2.3314\n",
      "Epoch 332/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.3183 - mean_squared_error: 2.3183\n",
      "Epoch 333/400\n",
      "402/402 [==============================] - 0s 30us/step - loss: 2.3154 - mean_squared_error: 2.3154\n",
      "Epoch 334/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 2.3164 - mean_squared_error: 2.3164\n",
      "Epoch 335/400\n",
      "402/402 [==============================] - 0s 32us/step - loss: 2.2887 - mean_squared_error: 2.2887\n",
      "Epoch 336/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.2796 - mean_squared_error: 2.2796\n",
      "Epoch 337/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.2855 - mean_squared_error: 2.2855\n",
      "Epoch 338/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.2628 - mean_squared_error: 2.2628\n",
      "Epoch 339/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.2503 - mean_squared_error: 2.2503\n",
      "Epoch 340/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 2.2596 - mean_squared_error: 2.2596\n",
      "Epoch 341/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 2.2758 - mean_squared_error: 2.2758\n",
      "Epoch 342/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 2.2989 - mean_squared_error: 2.2989\n",
      "Epoch 343/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.2180 - mean_squared_error: 2.2180\n",
      "Epoch 344/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.2169 - mean_squared_error: 2.2169\n",
      "Epoch 345/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.2217 - mean_squared_error: 2.2217\n",
      "Epoch 346/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 2.2194 - mean_squared_error: 2.2194\n",
      "Epoch 347/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.1810 - mean_squared_error: 2.1810\n",
      "Epoch 348/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 2.1735 - mean_squared_error: 2.1735\n",
      "Epoch 349/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.1708 - mean_squared_error: 2.1708\n",
      "Epoch 350/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 2.1520 - mean_squared_error: 2.1520\n",
      "Epoch 351/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 2.1682 - mean_squared_error: 2.1682\n",
      "Epoch 352/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.1519 - mean_squared_error: 2.1519\n",
      "Epoch 353/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.1477 - mean_squared_error: 2.1477\n",
      "Epoch 354/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 2.1274 - mean_squared_error: 2.1274\n",
      "Epoch 355/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 2.1469 - mean_squared_error: 2.1469\n",
      "Epoch 356/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 2.1246 - mean_squared_error: 2.1246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 357/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.1061 - mean_squared_error: 2.1061\n",
      "Epoch 358/400\n",
      "402/402 [==============================] - 0s 25us/step - loss: 2.0951 - mean_squared_error: 2.0951\n",
      "Epoch 359/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 2.0991 - mean_squared_error: 2.0991\n",
      "Epoch 360/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.0811 - mean_squared_error: 2.0811\n",
      "Epoch 361/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.0871 - mean_squared_error: 2.0871\n",
      "Epoch 362/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.0659 - mean_squared_error: 2.0659\n",
      "Epoch 363/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.0650 - mean_squared_error: 2.0650\n",
      "Epoch 364/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 2.0500 - mean_squared_error: 2.0500\n",
      "Epoch 365/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 2.0568 - mean_squared_error: 2.0568\n",
      "Epoch 366/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 2.0376 - mean_squared_error: 2.0376\n",
      "Epoch 367/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 2.0594 - mean_squared_error: 2.0594\n",
      "Epoch 368/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 2.0304 - mean_squared_error: 2.0304\n",
      "Epoch 369/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 2.1595 - mean_squared_error: 2.1595\n",
      "Epoch 370/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 1.9909 - mean_squared_error: 1.9909\n",
      "Epoch 371/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 1.9870 - mean_squared_error: 1.9870\n",
      "Epoch 372/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 2.0182 - mean_squared_error: 2.0182\n",
      "Epoch 373/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 1.9759 - mean_squared_error: 1.9759\n",
      "Epoch 374/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 1.9786 - mean_squared_error: 1.9786\n",
      "Epoch 375/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 2.0232 - mean_squared_error: 2.0232\n",
      "Epoch 376/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 1.9605 - mean_squared_error: 1.9605\n",
      "Epoch 377/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 1.9457 - mean_squared_error: 1.9457\n",
      "Epoch 378/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 1.9505 - mean_squared_error: 1.9505\n",
      "Epoch 379/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 1.9493 - mean_squared_error: 1.9493\n",
      "Epoch 380/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 1.9246 - mean_squared_error: 1.9246\n",
      "Epoch 381/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 1.9248 - mean_squared_error: 1.9248\n",
      "Epoch 382/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 1.9192 - mean_squared_error: 1.9192\n",
      "Epoch 383/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 1.9250 - mean_squared_error: 1.9250\n",
      "Epoch 384/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 1.9054 - mean_squared_error: 1.9054\n",
      "Epoch 385/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 1.9199 - mean_squared_error: 1.9199\n",
      "Epoch 386/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 1.8855 - mean_squared_error: 1.8855\n",
      "Epoch 387/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 1.8855 - mean_squared_error: 1.8855\n",
      "Epoch 388/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 1.8871 - mean_squared_error: 1.8871\n",
      "Epoch 389/400\n",
      "402/402 [==============================] - 0s 22us/step - loss: 1.8826 - mean_squared_error: 1.8826\n",
      "Epoch 390/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 1.8652 - mean_squared_error: 1.8652\n",
      "Epoch 391/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 1.8605 - mean_squared_error: 1.8605\n",
      "Epoch 392/400\n",
      "402/402 [==============================] - 0s 20us/step - loss: 1.8665 - mean_squared_error: 1.8665\n",
      "Epoch 393/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 1.8733 - mean_squared_error: 1.8733\n",
      "Epoch 394/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 1.8519 - mean_squared_error: 1.8519\n",
      "Epoch 395/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 1.8819 - mean_squared_error: 1.8819\n",
      "Epoch 396/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 1.8291 - mean_squared_error: 1.8291\n",
      "Epoch 397/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 1.8508 - mean_squared_error: 1.8508\n",
      "Epoch 398/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 1.8402 - mean_squared_error: 1.8402\n",
      "Epoch 399/400\n",
      "402/402 [==============================] - 0s 17us/step - loss: 1.8152 - mean_squared_error: 1.8152\n",
      "Epoch 400/400\n",
      "402/402 [==============================] - 0s 15us/step - loss: 1.8309 - mean_squared_error: 1.8309\n",
      "402/402 [==============================] - 0s 122us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.806443146805265, 1.806443146805265]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 1: make model - no hidden layer\n",
    "model = Sequential()\n",
    "#input layer: input_dim = no. of columns in X_train\n",
    "model.add(Dense(10, input_dim = 22 , activation = 'sigmoid'))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "# step 2: compile the model -> create the computational graph\n",
    "model.compile(loss ='mse', optimizer = 'sgd' , metrics = ['mse'] )\n",
    "\n",
    "# step 3: train the model -> fit epochs and batch_size\n",
    "model.fit(X_train, y_train, epochs = 400, batch_size = 128)\n",
    "\n",
    "#step 4: evaluation\n",
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.9750915990450406\n",
      "Test score:  0.9419270330509609\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "print('Train score: ', r2_score(y_train, y_train_pred))\n",
    "print('Test score: ', r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "402/402 [==============================] - 0s 722us/step - loss: 4.0506 - mean_squared_error: 88.4353\n",
      "Epoch 2/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 3.8736 - mean_squared_error: 86.7531\n",
      "Epoch 3/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 3.8371 - mean_squared_error: 86.0502\n",
      "Epoch 4/400\n",
      "402/402 [==============================] - 0s 77us/step - loss: 3.8097 - mean_squared_error: 85.4782\n",
      "Epoch 5/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 3.7826 - mean_squared_error: 84.9673\n",
      "Epoch 6/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 3.7495 - mean_squared_error: 84.1648\n",
      "Epoch 7/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 3.7092 - mean_squared_error: 83.7338\n",
      "Epoch 8/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 3.6591 - mean_squared_error: 82.7783\n",
      "Epoch 9/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 3.5974 - mean_squared_error: 81.5832\n",
      "Epoch 10/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 3.5160 - mean_squared_error: 80.2203\n",
      "Epoch 11/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 3.4339 - mean_squared_error: 78.5334\n",
      "Epoch 12/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 3.3628 - mean_squared_error: 76.9305\n",
      "Epoch 13/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 3.2932 - mean_squared_error: 75.2889\n",
      "Epoch 14/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 3.2191 - mean_squared_error: 73.2746\n",
      "Epoch 15/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 3.1574 - mean_squared_error: 71.3415\n",
      "Epoch 16/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 3.1162 - mean_squared_error: 69.6851\n",
      "Epoch 17/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 3.0388 - mean_squared_error: 67.2313\n",
      "Epoch 18/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 2.9998 - mean_squared_error: 65.2736\n",
      "Epoch 19/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 2.9418 - mean_squared_error: 63.7883\n",
      "Epoch 20/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 2.9123 - mean_squared_error: 62.2460\n",
      "Epoch 21/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 2.8673 - mean_squared_error: 60.5643\n",
      "Epoch 22/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 2.8822 - mean_squared_error: 60.1670\n",
      "Epoch 23/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 2.8313 - mean_squared_error: 57.9794\n",
      "Epoch 24/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 2.8033 - mean_squared_error: 57.3129\n",
      "Epoch 25/400\n",
      "402/402 [==============================] - 0s 79us/step - loss: 2.7604 - mean_squared_error: 56.8407\n",
      "Epoch 26/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 2.7386 - mean_squared_error: 54.9499\n",
      "Epoch 27/400\n",
      "402/402 [==============================] - 0s 87us/step - loss: 2.6820 - mean_squared_error: 53.6076\n",
      "Epoch 28/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 2.7200 - mean_squared_error: 54.2322\n",
      "Epoch 29/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 2.6365 - mean_squared_error: 53.0484\n",
      "Epoch 30/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 2.6131 - mean_squared_error: 51.8339\n",
      "Epoch 31/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 2.5984 - mean_squared_error: 51.0003\n",
      "Epoch 32/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 2.5966 - mean_squared_error: 49.5459\n",
      "Epoch 33/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 2.5197 - mean_squared_error: 47.9486\n",
      "Epoch 34/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 2.5322 - mean_squared_error: 47.4418\n",
      "Epoch 35/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 2.5294 - mean_squared_error: 48.3209\n",
      "Epoch 36/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 2.4751 - mean_squared_error: 45.8583\n",
      "Epoch 37/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 2.4557 - mean_squared_error: 44.9913\n",
      "Epoch 38/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 2.4115 - mean_squared_error: 44.3576\n",
      "Epoch 39/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 2.4261 - mean_squared_error: 44.5120\n",
      "Epoch 40/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 2.4211 - mean_squared_error: 43.7475\n",
      "Epoch 41/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 2.3983 - mean_squared_error: 43.4680\n",
      "Epoch 42/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 2.3821 - mean_squared_error: 42.1513\n",
      "Epoch 43/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 2.3293 - mean_squared_error: 41.3373\n",
      "Epoch 44/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 2.3498 - mean_squared_error: 41.4265\n",
      "Epoch 45/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 2.2745 - mean_squared_error: 40.6652\n",
      "Epoch 46/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 2.2639 - mean_squared_error: 40.0191\n",
      "Epoch 47/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 2.2587 - mean_squared_error: 38.7707\n",
      "Epoch 48/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 2.2061 - mean_squared_error: 38.9726\n",
      "Epoch 49/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 2.1848 - mean_squared_error: 38.5064\n",
      "Epoch 50/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 2.1810 - mean_squared_error: 37.7819\n",
      "Epoch 51/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 2.1531 - mean_squared_error: 35.3583\n",
      "Epoch 52/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 2.1070 - mean_squared_error: 35.7867\n",
      "Epoch 53/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 2.0542 - mean_squared_error: 34.3754\n",
      "Epoch 54/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 2.1316 - mean_squared_error: 34.5138\n",
      "Epoch 55/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 2.0768 - mean_squared_error: 33.9815\n",
      "Epoch 56/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 1.9902 - mean_squared_error: 31.4663\n",
      "Epoch 57/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 2.0178 - mean_squared_error: 31.1029\n",
      "Epoch 58/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 2.0199 - mean_squared_error: 29.9971\n",
      "Epoch 59/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 1.9078 - mean_squared_error: 30.0268\n",
      "Epoch 60/400\n",
      "402/402 [==============================] - 0s 72us/step - loss: 1.9432 - mean_squared_error: 28.6443\n",
      "Epoch 61/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 1.8632 - mean_squared_error: 27.7436\n",
      "Epoch 62/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.8888 - mean_squared_error: 26.8364\n",
      "Epoch 63/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 1.8884 - mean_squared_error: 27.0072\n",
      "Epoch 64/400\n",
      "402/402 [==============================] - 0s 50us/step - loss: 1.8727 - mean_squared_error: 25.8161\n",
      "Epoch 65/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 1.7747 - mean_squared_error: 23.7278\n",
      "Epoch 66/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 1.8954 - mean_squared_error: 25.0119\n",
      "Epoch 67/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.7636 - mean_squared_error: 23.2736\n",
      "Epoch 68/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 1.8173 - mean_squared_error: 21.8033\n",
      "Epoch 69/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 1.8130 - mean_squared_error: 22.6049\n",
      "Epoch 70/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.7283 - mean_squared_error: 21.2181\n",
      "Epoch 71/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 1.7596 - mean_squared_error: 20.4438\n",
      "Epoch 72/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 0s 69us/step - loss: 1.7187 - mean_squared_error: 20.2859\n",
      "Epoch 73/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 1.7036 - mean_squared_error: 18.9934\n",
      "Epoch 74/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 1.6453 - mean_squared_error: 19.1113\n",
      "Epoch 75/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 1.6254 - mean_squared_error: 18.2461\n",
      "Epoch 76/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 1.5411 - mean_squared_error: 17.7364\n",
      "Epoch 77/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 1.6297 - mean_squared_error: 17.5110\n",
      "Epoch 78/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 1.5178 - mean_squared_error: 17.4103\n",
      "Epoch 79/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.5539 - mean_squared_error: 17.1061\n",
      "Epoch 80/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 1.5316 - mean_squared_error: 15.3279\n",
      "Epoch 81/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 1.5722 - mean_squared_error: 17.5040\n",
      "Epoch 82/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.5387 - mean_squared_error: 15.0307\n",
      "Epoch 83/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 1.5211 - mean_squared_error: 15.7957\n",
      "Epoch 84/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 1.5305 - mean_squared_error: 15.2619\n",
      "Epoch 85/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.5562 - mean_squared_error: 16.2892\n",
      "Epoch 86/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 1.5762 - mean_squared_error: 14.4116\n",
      "Epoch 87/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.5264 - mean_squared_error: 14.7833\n",
      "Epoch 88/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 1.4832 - mean_squared_error: 14.0206\n",
      "Epoch 89/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 1.4556 - mean_squared_error: 15.3670\n",
      "Epoch 90/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 1.3699 - mean_squared_error: 13.5857\n",
      "Epoch 91/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.4149 - mean_squared_error: 13.5848\n",
      "Epoch 92/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 1.4657 - mean_squared_error: 13.9232\n",
      "Epoch 93/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.4902 - mean_squared_error: 13.0012\n",
      "Epoch 94/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 1.4285 - mean_squared_error: 12.2614\n",
      "Epoch 95/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 1.3711 - mean_squared_error: 11.6206\n",
      "Epoch 96/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 1.3418 - mean_squared_error: 12.4532\n",
      "Epoch 97/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 1.3346 - mean_squared_error: 12.1135\n",
      "Epoch 98/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 1.2758 - mean_squared_error: 11.2765\n",
      "Epoch 99/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.3358 - mean_squared_error: 12.8240\n",
      "Epoch 100/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 1.4329 - mean_squared_error: 11.6711\n",
      "Epoch 101/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 1.2928 - mean_squared_error: 11.4006\n",
      "Epoch 102/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 1.2875 - mean_squared_error: 10.7529\n",
      "Epoch 103/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.2418 - mean_squared_error: 11.5476\n",
      "Epoch 104/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.2745 - mean_squared_error: 10.9624\n",
      "Epoch 105/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 1.3054 - mean_squared_error: 10.5023\n",
      "Epoch 106/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 1.2649 - mean_squared_error: 10.9879\n",
      "Epoch 107/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.2175 - mean_squared_error: 9.9998\n",
      "Epoch 108/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 1.2544 - mean_squared_error: 10.4174\n",
      "Epoch 109/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 1.3496 - mean_squared_error: 10.3064\n",
      "Epoch 110/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.1839 - mean_squared_error: 10.1711\n",
      "Epoch 111/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.2515 - mean_squared_error: 9.8682\n",
      "Epoch 112/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 1.2519 - mean_squared_error: 10.2297\n",
      "Epoch 113/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 1.2121 - mean_squared_error: 9.7666\n",
      "Epoch 114/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.1624 - mean_squared_error: 8.9652\n",
      "Epoch 115/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 1.0431 - mean_squared_error: 9.1834\n",
      "Epoch 116/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.0863 - mean_squared_error: 9.0246\n",
      "Epoch 117/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 1.1304 - mean_squared_error: 8.8167\n",
      "Epoch 118/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 1.1050 - mean_squared_error: 8.9937\n",
      "Epoch 119/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 1.1137 - mean_squared_error: 9.1693\n",
      "Epoch 120/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.0960 - mean_squared_error: 9.1283\n",
      "Epoch 121/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 1.0313 - mean_squared_error: 8.5829\n",
      "Epoch 122/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 1.1459 - mean_squared_error: 9.2502\n",
      "Epoch 123/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 1.0926 - mean_squared_error: 8.7697\n",
      "Epoch 124/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.2455 - mean_squared_error: 11.6050\n",
      "Epoch 125/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.0548 - mean_squared_error: 8.6825\n",
      "Epoch 126/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.1347 - mean_squared_error: 9.0689\n",
      "Epoch 127/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.0848 - mean_squared_error: 7.9748\n",
      "Epoch 128/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.0781 - mean_squared_error: 7.9293\n",
      "Epoch 129/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 1.0656 - mean_squared_error: 7.6720\n",
      "Epoch 130/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.0085 - mean_squared_error: 7.5054\n",
      "Epoch 131/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 1.0741 - mean_squared_error: 7.2151\n",
      "Epoch 132/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.9776 - mean_squared_error: 7.1922\n",
      "Epoch 133/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.9892 - mean_squared_error: 7.3004\n",
      "Epoch 134/400\n",
      "402/402 [==============================] - 0s 72us/step - loss: 0.9980 - mean_squared_error: 6.7767\n",
      "Epoch 135/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.9982 - mean_squared_error: 6.8228\n",
      "Epoch 136/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 1.0387 - mean_squared_error: 7.3283\n",
      "Epoch 137/400\n",
      "402/402 [==============================] - 0s 82us/step - loss: 0.9697 - mean_squared_error: 6.7145\n",
      "Epoch 138/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.9649 - mean_squared_error: 6.2352\n",
      "Epoch 139/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.9480 - mean_squared_error: 6.1946\n",
      "Epoch 140/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.9579 - mean_squared_error: 5.8251\n",
      "Epoch 141/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 1.0477 - mean_squared_error: 5.9134\n",
      "Epoch 142/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.9599 - mean_squared_error: 5.7646\n",
      "Epoch 143/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 0s 52us/step - loss: 0.9238 - mean_squared_error: 5.4168\n",
      "Epoch 144/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.9071 - mean_squared_error: 5.0483\n",
      "Epoch 145/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.8214 - mean_squared_error: 4.3507\n",
      "Epoch 146/400\n",
      "402/402 [==============================] - 0s 72us/step - loss: 0.9018 - mean_squared_error: 4.5279\n",
      "Epoch 147/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.9160 - mean_squared_error: 4.9656\n",
      "Epoch 148/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.8738 - mean_squared_error: 4.4361\n",
      "Epoch 149/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.9094 - mean_squared_error: 4.8320\n",
      "Epoch 150/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.8694 - mean_squared_error: 4.1801\n",
      "Epoch 151/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.9140 - mean_squared_error: 4.6947\n",
      "Epoch 152/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.8446 - mean_squared_error: 4.4571\n",
      "Epoch 153/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.8924 - mean_squared_error: 3.9600\n",
      "Epoch 154/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.9210 - mean_squared_error: 4.5234\n",
      "Epoch 155/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.8176 - mean_squared_error: 3.8344\n",
      "Epoch 156/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.7497 - mean_squared_error: 3.7278\n",
      "Epoch 157/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.8068 - mean_squared_error: 3.5472\n",
      "Epoch 158/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.8198 - mean_squared_error: 3.6260\n",
      "Epoch 159/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.8169 - mean_squared_error: 3.7173\n",
      "Epoch 160/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.7521 - mean_squared_error: 3.2333\n",
      "Epoch 161/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.8338 - mean_squared_error: 3.4903\n",
      "Epoch 162/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.7574 - mean_squared_error: 2.9921\n",
      "Epoch 163/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.8036 - mean_squared_error: 3.2328\n",
      "Epoch 164/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.7648 - mean_squared_error: 3.1067\n",
      "Epoch 165/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.6852 - mean_squared_error: 2.9012\n",
      "Epoch 166/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.7865 - mean_squared_error: 2.9184\n",
      "Epoch 167/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.7412 - mean_squared_error: 2.4478\n",
      "Epoch 168/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.7883 - mean_squared_error: 2.6521\n",
      "Epoch 169/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.7084 - mean_squared_error: 2.0908\n",
      "Epoch 170/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.6719 - mean_squared_error: 2.0210\n",
      "Epoch 171/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.8285 - mean_squared_error: 3.2239\n",
      "Epoch 172/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.7346 - mean_squared_error: 2.4125\n",
      "Epoch 173/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.8124 - mean_squared_error: 2.5026\n",
      "Epoch 174/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.7044 - mean_squared_error: 2.3126\n",
      "Epoch 175/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.7217 - mean_squared_error: 2.0175\n",
      "Epoch 176/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.7067 - mean_squared_error: 1.9462\n",
      "Epoch 177/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.7621 - mean_squared_error: 2.1724\n",
      "Epoch 178/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.6343 - mean_squared_error: 2.0458\n",
      "Epoch 179/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.6819 - mean_squared_error: 1.8558\n",
      "Epoch 180/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.6540 - mean_squared_error: 1.7404\n",
      "Epoch 181/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.6739 - mean_squared_error: 1.9080\n",
      "Epoch 182/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.6401 - mean_squared_error: 1.8366\n",
      "Epoch 183/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.6848 - mean_squared_error: 2.0663\n",
      "Epoch 184/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.5716 - mean_squared_error: 1.5505\n",
      "Epoch 185/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.6194 - mean_squared_error: 1.7395\n",
      "Epoch 186/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.6584 - mean_squared_error: 1.7611\n",
      "Epoch 187/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.6707 - mean_squared_error: 1.8883\n",
      "Epoch 188/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.6436 - mean_squared_error: 1.9833\n",
      "Epoch 189/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.7027 - mean_squared_error: 2.7186\n",
      "Epoch 190/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.5360 - mean_squared_error: 1.7817\n",
      "Epoch 191/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.5052 - mean_squared_error: 1.5474\n",
      "Epoch 192/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.4517 - mean_squared_error: 1.4313\n",
      "Epoch 193/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.4693 - mean_squared_error: 1.4703\n",
      "Epoch 194/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.5447 - mean_squared_error: 1.6193\n",
      "Epoch 195/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.5248 - mean_squared_error: 1.4814\n",
      "Epoch 196/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.4724 - mean_squared_error: 1.2512\n",
      "Epoch 197/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.5482 - mean_squared_error: 1.5792\n",
      "Epoch 198/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4976 - mean_squared_error: 1.4166\n",
      "Epoch 199/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.4694 - mean_squared_error: 1.6036\n",
      "Epoch 200/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4771 - mean_squared_error: 1.5846\n",
      "Epoch 201/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.5077 - mean_squared_error: 1.6164\n",
      "Epoch 202/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.5641 - mean_squared_error: 1.7739\n",
      "Epoch 203/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.5815 - mean_squared_error: 2.0757\n",
      "Epoch 204/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.5892 - mean_squared_error: 2.3932\n",
      "Epoch 205/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.5788 - mean_squared_error: 1.8717\n",
      "Epoch 206/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.4625 - mean_squared_error: 1.5676\n",
      "Epoch 207/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4087 - mean_squared_error: 1.1670\n",
      "Epoch 208/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.4334 - mean_squared_error: 1.3399\n",
      "Epoch 209/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.4810 - mean_squared_error: 1.5060\n",
      "Epoch 210/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4475 - mean_squared_error: 1.3348\n",
      "Epoch 211/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.4192 - mean_squared_error: 1.1682\n",
      "Epoch 212/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4796 - mean_squared_error: 1.4846\n",
      "Epoch 213/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.5126 - mean_squared_error: 1.4153\n",
      "Epoch 214/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.4443 - mean_squared_error: 1.3332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.4187 - mean_squared_error: 1.2114\n",
      "Epoch 216/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.4176 - mean_squared_error: 1.3110\n",
      "Epoch 217/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.4875 - mean_squared_error: 1.5357\n",
      "Epoch 218/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.4393 - mean_squared_error: 1.3962\n",
      "Epoch 219/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.4049 - mean_squared_error: 1.1472\n",
      "Epoch 220/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4517 - mean_squared_error: 1.3116\n",
      "Epoch 221/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4167 - mean_squared_error: 1.2099\n",
      "Epoch 222/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.4617 - mean_squared_error: 1.3513\n",
      "Epoch 223/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.4224 - mean_squared_error: 1.1065\n",
      "Epoch 224/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.4344 - mean_squared_error: 1.1428\n",
      "Epoch 225/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.4707 - mean_squared_error: 1.2625\n",
      "Epoch 226/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.5241 - mean_squared_error: 1.7559\n",
      "Epoch 227/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4184 - mean_squared_error: 1.2492\n",
      "Epoch 228/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.3965 - mean_squared_error: 1.0922\n",
      "Epoch 229/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4195 - mean_squared_error: 1.2124\n",
      "Epoch 230/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.4534 - mean_squared_error: 1.4426\n",
      "Epoch 231/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.4109 - mean_squared_error: 1.1189\n",
      "Epoch 232/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.3880 - mean_squared_error: 1.0780\n",
      "Epoch 233/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.5507 - mean_squared_error: 1.8758\n",
      "Epoch 234/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.4022 - mean_squared_error: 1.1433\n",
      "Epoch 235/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4015 - mean_squared_error: 1.1104\n",
      "Epoch 236/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.3895 - mean_squared_error: 1.0926\n",
      "Epoch 237/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.4563 - mean_squared_error: 1.2510\n",
      "Epoch 238/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.3970 - mean_squared_error: 1.0517\n",
      "Epoch 239/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.4101 - mean_squared_error: 1.1726\n",
      "Epoch 240/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4023 - mean_squared_error: 1.1090\n",
      "Epoch 241/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.4366 - mean_squared_error: 1.2950\n",
      "Epoch 242/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.4099 - mean_squared_error: 1.2399\n",
      "Epoch 243/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4028 - mean_squared_error: 1.0196\n",
      "Epoch 244/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.4210 - mean_squared_error: 1.1387\n",
      "Epoch 245/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.3943 - mean_squared_error: 0.9938\n",
      "Epoch 246/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.6721 - mean_squared_error: 3.3343\n",
      "Epoch 247/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.3771 - mean_squared_error: 0.9765\n",
      "Epoch 248/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.4229 - mean_squared_error: 1.1061\n",
      "Epoch 249/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.4868 - mean_squared_error: 1.4842\n",
      "Epoch 250/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.3619 - mean_squared_error: 0.9842\n",
      "Epoch 251/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.4585 - mean_squared_error: 1.4496\n",
      "Epoch 252/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.3971 - mean_squared_error: 1.1291\n",
      "Epoch 253/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4439 - mean_squared_error: 1.2730\n",
      "Epoch 254/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.4036 - mean_squared_error: 1.1107\n",
      "Epoch 255/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.3722 - mean_squared_error: 1.0412\n",
      "Epoch 256/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4769 - mean_squared_error: 1.8370\n",
      "Epoch 257/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.3854 - mean_squared_error: 1.0268\n",
      "Epoch 258/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.3990 - mean_squared_error: 1.1103\n",
      "Epoch 259/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.3794 - mean_squared_error: 1.0297\n",
      "Epoch 260/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.3945 - mean_squared_error: 0.9848\n",
      "Epoch 261/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.3596 - mean_squared_error: 0.9779\n",
      "Epoch 262/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.3642 - mean_squared_error: 0.8677\n",
      "Epoch 263/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4002 - mean_squared_error: 1.2800\n",
      "Epoch 264/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.3896 - mean_squared_error: 0.9745\n",
      "Epoch 265/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.3642 - mean_squared_error: 0.9535\n",
      "Epoch 266/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.3477 - mean_squared_error: 0.9296\n",
      "Epoch 267/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.3630 - mean_squared_error: 0.9659\n",
      "Epoch 268/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.3705 - mean_squared_error: 1.0167\n",
      "Epoch 269/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.3932 - mean_squared_error: 1.0686\n",
      "Epoch 270/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4163 - mean_squared_error: 1.3569\n",
      "Epoch 271/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.3957 - mean_squared_error: 1.0860\n",
      "Epoch 272/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4091 - mean_squared_error: 1.3491\n",
      "Epoch 273/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.3743 - mean_squared_error: 1.0256\n",
      "Epoch 274/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.4791 - mean_squared_error: 1.4554\n",
      "Epoch 275/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.3395 - mean_squared_error: 1.0115\n",
      "Epoch 276/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.3718 - mean_squared_error: 0.9150\n",
      "Epoch 277/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.3671 - mean_squared_error: 0.9428\n",
      "Epoch 278/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.4542 - mean_squared_error: 1.8163\n",
      "Epoch 279/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.4041 - mean_squared_error: 1.1464\n",
      "Epoch 280/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.3658 - mean_squared_error: 0.8864\n",
      "Epoch 281/400\n",
      "402/402 [==============================] - 0s 79us/step - loss: 0.3606 - mean_squared_error: 0.9664\n",
      "Epoch 282/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.3962 - mean_squared_error: 0.8860\n",
      "Epoch 283/400\n",
      "402/402 [==============================] - 0s 72us/step - loss: 0.3781 - mean_squared_error: 0.9000\n",
      "Epoch 284/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.3466 - mean_squared_error: 1.0217\n",
      "Epoch 285/400\n",
      "402/402 [==============================] - 0s 84us/step - loss: 0.3364 - mean_squared_error: 0.9554\n",
      "Epoch 286/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 0s 69us/step - loss: 0.3564 - mean_squared_error: 0.8732\n",
      "Epoch 287/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.3911 - mean_squared_error: 0.9901\n",
      "Epoch 288/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.3503 - mean_squared_error: 0.9571\n",
      "Epoch 289/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.3294 - mean_squared_error: 0.9105\n",
      "Epoch 290/400\n",
      "402/402 [==============================] - 0s 89us/step - loss: 0.3689 - mean_squared_error: 0.7942\n",
      "Epoch 291/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.3262 - mean_squared_error: 0.8982\n",
      "Epoch 292/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.3331 - mean_squared_error: 0.7857\n",
      "Epoch 293/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.4334 - mean_squared_error: 1.1916\n",
      "Epoch 294/400\n",
      "402/402 [==============================] - 0s 74us/step - loss: 0.3329 - mean_squared_error: 0.9107\n",
      "Epoch 295/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.3606 - mean_squared_error: 0.8443\n",
      "Epoch 296/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.3271 - mean_squared_error: 0.7348\n",
      "Epoch 297/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.3520 - mean_squared_error: 0.8144\n",
      "Epoch 298/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.3510 - mean_squared_error: 0.9058\n",
      "Epoch 299/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.3604 - mean_squared_error: 0.9403\n",
      "Epoch 300/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.3687 - mean_squared_error: 0.9009\n",
      "Epoch 301/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.3427 - mean_squared_error: 0.8368\n",
      "Epoch 302/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.3768 - mean_squared_error: 1.0416\n",
      "Epoch 303/400\n",
      "402/402 [==============================] - 0s 84us/step - loss: 0.3794 - mean_squared_error: 1.1115\n",
      "Epoch 304/400\n",
      "402/402 [==============================] - ETA: 0s - loss: 0.4953 - mean_squared_error: 0.52 - 0s 72us/step - loss: 0.3531 - mean_squared_error: 0.8728\n",
      "Epoch 305/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.3475 - mean_squared_error: 0.7870\n",
      "Epoch 306/400\n",
      "402/402 [==============================] - 0s 74us/step - loss: 0.4907 - mean_squared_error: 1.6309\n",
      "Epoch 307/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.3464 - mean_squared_error: 1.0027\n",
      "Epoch 308/400\n",
      "402/402 [==============================] - 0s 72us/step - loss: 0.3998 - mean_squared_error: 1.0289\n",
      "Epoch 309/400\n",
      "402/402 [==============================] - 0s 72us/step - loss: 0.3826 - mean_squared_error: 1.0034\n",
      "Epoch 310/400\n",
      "402/402 [==============================] - 0s 74us/step - loss: 0.3283 - mean_squared_error: 0.6905\n",
      "Epoch 311/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.3742 - mean_squared_error: 0.8777\n",
      "Epoch 312/400\n",
      "402/402 [==============================] - 0s 74us/step - loss: 0.3507 - mean_squared_error: 0.8054\n",
      "Epoch 313/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.3839 - mean_squared_error: 1.0334\n",
      "Epoch 314/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.3313 - mean_squared_error: 0.6991\n",
      "Epoch 315/400\n",
      "402/402 [==============================] - 0s 72us/step - loss: 0.3674 - mean_squared_error: 0.7845\n",
      "Epoch 316/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.3228 - mean_squared_error: 0.8052\n",
      "Epoch 317/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.3145 - mean_squared_error: 0.8498\n",
      "Epoch 318/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.3799 - mean_squared_error: 1.0500\n",
      "Epoch 319/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.3215 - mean_squared_error: 0.7149\n",
      "Epoch 320/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.4582 - mean_squared_error: 1.7704\n",
      "Epoch 321/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.3361 - mean_squared_error: 1.0747\n",
      "Epoch 322/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.4071 - mean_squared_error: 1.2565\n",
      "Epoch 323/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.3658 - mean_squared_error: 0.8981\n",
      "Epoch 324/400\n",
      "402/402 [==============================] - 0s 79us/step - loss: 0.3479 - mean_squared_error: 0.7715\n",
      "Epoch 325/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.3402 - mean_squared_error: 0.8783\n",
      "Epoch 326/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.3920 - mean_squared_error: 0.9039\n",
      "Epoch 327/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.3634 - mean_squared_error: 0.8706\n",
      "Epoch 328/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.3546 - mean_squared_error: 0.7064\n",
      "Epoch 329/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.3534 - mean_squared_error: 0.8519\n",
      "Epoch 330/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.3417 - mean_squared_error: 0.7641\n",
      "Epoch 331/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.3333 - mean_squared_error: 0.7582\n",
      "Epoch 332/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.3114 - mean_squared_error: 0.7720\n",
      "Epoch 333/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4247 - mean_squared_error: 1.5061\n",
      "Epoch 334/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.4138 - mean_squared_error: 1.1763\n",
      "Epoch 335/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.4198 - mean_squared_error: 1.4361\n",
      "Epoch 336/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.3502 - mean_squared_error: 0.8011\n",
      "Epoch 337/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.3305 - mean_squared_error: 0.6719\n",
      "Epoch 338/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.3483 - mean_squared_error: 0.7522\n",
      "Epoch 339/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.2993 - mean_squared_error: 0.6733\n",
      "Epoch 340/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.2700 - mean_squared_error: 0.6838\n",
      "Epoch 341/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.3119 - mean_squared_error: 0.7255\n",
      "Epoch 342/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.3399 - mean_squared_error: 0.7663\n",
      "Epoch 343/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4763 - mean_squared_error: 1.6629\n",
      "Epoch 344/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.3018 - mean_squared_error: 0.6758\n",
      "Epoch 345/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.3407 - mean_squared_error: 0.7789\n",
      "Epoch 346/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.2930 - mean_squared_error: 0.6913\n",
      "Epoch 347/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.3363 - mean_squared_error: 0.8076\n",
      "Epoch 348/400\n",
      "402/402 [==============================] - 0s 52us/step - loss: 0.3303 - mean_squared_error: 0.8775\n",
      "Epoch 349/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.3661 - mean_squared_error: 0.8010\n",
      "Epoch 350/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.3283 - mean_squared_error: 0.7645\n",
      "Epoch 351/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.3321 - mean_squared_error: 0.7059\n",
      "Epoch 352/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.3464 - mean_squared_error: 0.6892\n",
      "Epoch 353/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.2965 - mean_squared_error: 0.6641\n",
      "Epoch 354/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.3328 - mean_squared_error: 0.8034\n",
      "Epoch 355/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.4221 - mean_squared_error: 1.3353\n",
      "Epoch 356/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.3780 - mean_squared_error: 0.7497\n",
      "Epoch 357/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 0s 57us/step - loss: 0.3056 - mean_squared_error: 0.6926\n",
      "Epoch 358/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.3433 - mean_squared_error: 0.7541\n",
      "Epoch 359/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.3297 - mean_squared_error: 0.7524\n",
      "Epoch 360/400\n",
      "402/402 [==============================] - 0s 69us/step - loss: 0.3087 - mean_squared_error: 0.6751\n",
      "Epoch 361/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.3287 - mean_squared_error: 0.6266\n",
      "Epoch 362/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.3567 - mean_squared_error: 0.8633\n",
      "Epoch 363/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.4060 - mean_squared_error: 1.3527\n",
      "Epoch 364/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.4238 - mean_squared_error: 1.7456\n",
      "Epoch 365/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.3221 - mean_squared_error: 0.6054\n",
      "Epoch 366/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.3296 - mean_squared_error: 0.7324\n",
      "Epoch 367/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.2837 - mean_squared_error: 0.5791\n",
      "Epoch 368/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.3045 - mean_squared_error: 0.7174\n",
      "Epoch 369/400\n",
      "402/402 [==============================] - 0s 67us/step - loss: 0.3889 - mean_squared_error: 0.9363\n",
      "Epoch 370/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4307 - mean_squared_error: 1.5461\n",
      "Epoch 371/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.3134 - mean_squared_error: 0.7603\n",
      "Epoch 372/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.3211 - mean_squared_error: 0.7486\n",
      "Epoch 373/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.3565 - mean_squared_error: 0.7319\n",
      "Epoch 374/400\n",
      "402/402 [==============================] - ETA: 0s - loss: 0.1975 - mean_squared_error: 0.12 - 0s 65us/step - loss: 0.2974 - mean_squared_error: 0.7006\n",
      "Epoch 375/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.3393 - mean_squared_error: 0.8211\n",
      "Epoch 376/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.2898 - mean_squared_error: 0.7585\n",
      "Epoch 377/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.3692 - mean_squared_error: 0.8765\n",
      "Epoch 378/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.3307 - mean_squared_error: 0.7625\n",
      "Epoch 379/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.3160 - mean_squared_error: 0.7029\n",
      "Epoch 380/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.3319 - mean_squared_error: 0.7046\n",
      "Epoch 381/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.3081 - mean_squared_error: 0.6060\n",
      "Epoch 382/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.4424 - mean_squared_error: 1.2009\n",
      "Epoch 383/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.3140 - mean_squared_error: 0.7552\n",
      "Epoch 384/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.3998 - mean_squared_error: 0.9078\n",
      "Epoch 385/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.2963 - mean_squared_error: 0.5908\n",
      "Epoch 386/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.2787 - mean_squared_error: 0.4557\n",
      "Epoch 387/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.3135 - mean_squared_error: 0.6821\n",
      "Epoch 388/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.3226 - mean_squared_error: 0.5851\n",
      "Epoch 389/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.3514 - mean_squared_error: 0.8713\n",
      "Epoch 390/400\n",
      "402/402 [==============================] - 0s 65us/step - loss: 0.3326 - mean_squared_error: 0.7464\n",
      "Epoch 391/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.3162 - mean_squared_error: 0.6791\n",
      "Epoch 392/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.3291 - mean_squared_error: 0.7703\n",
      "Epoch 393/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.3294 - mean_squared_error: 0.6654\n",
      "Epoch 394/400\n",
      "402/402 [==============================] - 0s 62us/step - loss: 0.3173 - mean_squared_error: 0.7238\n",
      "Epoch 395/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.3272 - mean_squared_error: 0.6853\n",
      "Epoch 396/400\n",
      "402/402 [==============================] - 0s 57us/step - loss: 0.2828 - mean_squared_error: 0.6463\n",
      "Epoch 397/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.3121 - mean_squared_error: 0.5788\n",
      "Epoch 398/400\n",
      "402/402 [==============================] - 0s 60us/step - loss: 0.3358 - mean_squared_error: 0.7173\n",
      "Epoch 399/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.2832 - mean_squared_error: 0.5830\n",
      "Epoch 400/400\n",
      "402/402 [==============================] - 0s 55us/step - loss: 0.3274 - mean_squared_error: 0.6839\n",
      "402/402 [==============================] - 0s 191us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2607479913910823, 0.5989475855186804]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 1: build the model\n",
    "model = Sequential()\n",
    "#input layer\n",
    "model.add(Dense(10, input_dim = 22, activation = 'sigmoid'))\n",
    "#hidden layers\n",
    "\n",
    "model.add(Dense(6, activation = 'relu'))\n",
    "model.add(Dense(3, activation = 'relu'))\n",
    "#output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "#step 2: build the computational graph - compile\n",
    "model.compile(loss = 'mae', optimizer = 'sgd', metrics = ['mse'])\n",
    "\n",
    "#step 3: train the model\n",
    "model.fit(X_train, y_train, epochs = 400, batch_size= 20)\n",
    "\n",
    "#step 4: evaluate\n",
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.9917413244507147\n",
      "Test score:  0.9715929365359686\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('Train score: ', r2_score(y_train, y_train_pred))\n",
    "print('Test score: ', r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
